{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个简单的Agents\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模块\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "# 加载 API key\n",
    "load_dotenv(find_dotenv())\n",
    "api_key = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "\n",
    "# 首先依旧导入模块\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "\n",
    "llm = ChatTongyi(\n",
    "    dashscope_api_key = api_key,\n",
    "    model = \"Qwen-max\",\n",
    "    temperature = 0\n",
    ")\n",
    "\n",
    "# 搭建工具\n",
    "# 我们使用一个工具,serpai是一个聚合搜索引擎,需要安装谷歌搜索包和申请apikey\n",
    "# https://serpapi.com/dashboard\n",
    "# llm-math 是一个封装好的数学计算链\n",
    "# 首先我们需要安装谷歌搜索包\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m我需要知道前任女王的名字和年龄，然后用计算器计算她年龄的平方。\n",
      "Action: Search\n",
      "Action Input: \"英国前任女王名字 年龄\"\n",
      "Observation:\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['伊丽莎白二世（英语：Elizabeth II；1926年4月21日—2022年9月8日），全名伊丽莎白·亚历山德拉·玛丽（英语：Elizabeth Alexandra Mary），是1952年至2022年间英国暨其他英 ...', '到了18岁成年之际，随着英国议会修改法律，伊丽莎白公主跻身五名英国国务顾问之一，可在其父无法履职或身在国外之时，代行王室职责。1945年，她说服乔治六 ...', '伊莉莎白二世（英語：Elizabeth II；1926年4月21日—2022年9月8日），全名伊莉莎白·亞歷山德拉·瑪麗（英語：Elizabeth Alexandra Mary），是1952年至2022年間英國暨其他大 ...', '... ，是日本漫画《名侦探柯南》及其衍生作品中的角色。是一名律师，拥有“律政界女王 ... 生日. 10月10日. 年龄. 37岁（初登场）→38岁. 毕业院校. 帝丹高中 ...', '楼主的话：. 当地时间9月8日，英国女王伊丽莎白二世去世，终年96岁。从1952年登基至今，伊丽莎白二世在位70年，是英国历史上在位时间最长的君主。', '国内时间9月9日，据英国媒体报道，现任英国女王伊丽莎白二世于英国时间9月8日因身体原因不幸逝世，享年96岁，此消息公布后，瞬间引起了全世界网友的 ...', '英国女王即英国女性君主。英国君主是英国及英国海外领地的国家元首，现在的男性君主称为国王（King），女性君主称为女王（Queen）。1953年6月2日，伊丽莎白二世正式 ...', '英国女王伊丽莎白二世9月8日下午6时30分离开了钟爱她的臣民，也为一个时代画上了句号。史上年龄最大的王储查尔斯王子也终于顺位成为国王，他做的第一 ...', 'https://vimeo.com/manage/videos/968601255']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m我现在知道了前任女王的名字是伊丽莎白二世，以及她的年龄是96岁，现在我可以使用计算器来算出她年龄的平方了。\n",
      "Action: Calculator\n",
      "Action Input: 96*96\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 9216\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m我现在知道最终答案了\n",
      "Final Answer: 英国前任女王的名字是伊丽莎白二世，她去世时的年龄为96岁，年龄的平方是9216。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'英国前任女王的名字是伊丽莎白二世，她去世时的年龄为96岁，年龄的平方是9216。'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入模块\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "# 加载 API key\n",
    "load_dotenv(find_dotenv())\n",
    "dashscope_api_key = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "serpapi_api_key = os.getenv(\"SERPAPI_API_KEY\")\n",
    "\n",
    "# 首先依旧导入模块\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "\n",
    "llm = ChatTongyi(\n",
    "    dashscope_api_key = dashscope_api_key,\n",
    "    model = \"qwen-vl-max\",\n",
    "    temperature = 0\n",
    ")\n",
    "\n",
    "from langchain.agents import load_tools\n",
    "# 搭建工具\n",
    "tools = load_tools(\n",
    "    [\"serpapi\", \"llm-math\"],\n",
    "    llm=llm,\n",
    "    serpapi_api_key=serpapi_api_key\n",
    ")\n",
    "\n",
    "# 定义agents使用小样本增强\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "# 定义工具\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,# 这里有不同的类型\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent.run(\"英国前任女王的名字叫什么,她的年龄的平方是多少?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "几种内置的主要agent类型\n",
    "- openai_functions OpenAI函数调用型\n",
    "- zero_short_react_description 零样本增强生成型\n",
    "- chat_zero_shot_react_description 零样本增强对话型\n",
    "- conversational_react_description 对话增强生成型\n",
    "- chat_conversational_react_description 对话增强结构化\n",
    "- structued_chat_zero_short_react_description 零样本增强结构化对话型\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "零样本实现\n",
    "零样本增强生成,既在没有示例的情况下,可以自主进行对话的类型[零样本,单样本,少样本]\n",
    "https://blog.csdn.net/zcyzcyjava/article/details/127006287"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m 新西兰是君主立宪制国家，其国家元首是英国女王。因此，上一任新西兰女王就是指的是英国的前一位君主。目前英国的君主是伊丽莎白二世，但她在2022年9月8日去世，随后由她的儿子查尔斯三世继位。我会计算查尔斯三世现在的年龄除以2。\n",
      "Action: Calculator\n",
      "Action Input: 74 / 2\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 37.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m我找到了答案。\n",
      "Final Answer: 上一任新西兰女王是查尔斯三世，他的年龄除以2是37。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'上一任新西兰女王是查尔斯三世，他的年龄除以2是37。'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import Tongyi\n",
    "from langchain.agents import (\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType\n",
    ")\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "# 加载 API key\n",
    "load_dotenv(find_dotenv())\n",
    "dashscope_api_key = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "serpapi_api_key = os.getenv(\"SERPAPI_API_KEY\")\n",
    "\n",
    "llm = Tongyi(\n",
    "    dashscope_api_key = dashscope_api_key,\n",
    "    model = 'Qwen-max',\n",
    "    temperature =0\n",
    ")\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm, serpapi_api_key=serpapi_api_key)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent.run('上一任新西兰女王是谁?她年龄除以2是多少?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chat_zero_short_react_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The third pole of the world refers to the Qinghai-Tibet Plateau. It's also known as the \"Third Pole of the Earth\", which means it is the third highest elevation region on earth after the South Pole and the North Pole. The average altitude of the Qinghai-Tibet Plateau is more than 4000 meters, so its height multiplied by 2 will be greater than 8000 meters. I need to use the calculator to perform this calculation.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"4000 * 2\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 8000\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: The height of the Qinghai-Tibet Plateau multiplied by 2 is 8000 meters.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The height of the Qinghai-Tibet Plateau multiplied by 2 is 8000 meters.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.llms import Tongyi\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "from langchain.agents import (\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType\n",
    ")\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "# 加载 API key\n",
    "load_dotenv(find_dotenv())\n",
    "dashscope_api_key = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "serpapi_api_key = os.getenv(\"SERPAPI_API_KEY\")\n",
    "\n",
    "llm = ChatTongyi(\n",
    "    dashscope_api_key = dashscope_api_key,\n",
    "    model_name = 'qwen-vl-max',\n",
    "    temperature =0\n",
    ")\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm, serpapi_api_key=serpapi_api_key)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent.run('世界第三极是什么?它的高度乘2是多少?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conversational_react_description 一个对话型的agent,这个agent要求与memory一起使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=ConversationBufferMemory(memory_key='chat_history') verbose=True tags=['conversational-react-description'] agent=ConversationalAgent(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input'], template='Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nTOOLS:\\n------\\n\\nAssistant has access to the following tools:\\n\\n> Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\\n> Calculator: Useful for when you need to answer questions about math.\\n\\nTo use a tool, please use the following format:\\n\\n```\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [Search, Calculator]\\nAction Input: the input to the action\\nObservation: the result of the action\\n```\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n```\\nThought: Do I need to use a tool? No\\nAI: [your response here]\\n```\\n\\nBegin!\\n\\nPrevious conversation history:\\n{chat_history}\\n\\nNew input: {input}\\n{agent_scratchpad}'), llm=Tongyi(client=<class 'dashscope.aigc.generation.Generation'>, dashscope_api_key='sk-2a9e44d9621f4fd1b5f9f2c081779215')), output_parser=ConvoOutputParser(), allowed_tools=['Search', 'Calculator'], ai_prefix='AI') tools=[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>), Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=Tongyi(client=<class 'dashscope.aigc.generation.Generation'>, dashscope_api_key='sk-2a9e44d9621f4fd1b5f9f2c081779215')))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=Tongyi(client=<class 'dashscope.aigc.generation.Generation'>, dashscope_api_key='sk-2a9e44d9621f4fd1b5f9f2c081779215')))>)]\n",
      "Assistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
      "\n",
      "TOOLS:\n",
      "------\n",
      "\n",
      "Assistant has access to the following tools:\n",
      "\n",
      "> Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
      "> Calculator: Useful for when you need to answer questions about math.\n",
      "\n",
      "To use a tool, please use the following format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: the action to take, should be one of [Search, Calculator]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "```\n",
      "\n",
      "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: [your response here]\n",
      "```\n",
      "\n",
      "Begin!\n",
      "\n",
      "Previous conversation history:\n",
      "{chat_history}\n",
      "\n",
      "New input: {input}\n",
      "{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Tongyi\n",
    "from langchain.agents import(\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "# 加载 API key\n",
    "load_dotenv(find_dotenv())\n",
    "dashscope_api_key = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "serpapi_api_key = os.getenv(\"SERPAPI_API_KEY\")\n",
    "\n",
    "# 记忆组件\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\"\n",
    ")\n",
    "\n",
    "llm = Tongyi(\n",
    "    dashscope_api_key = dashscope_api_key,\n",
    "    model = \"Qwen-max\",\n",
    "    temperature = 0,\n",
    ")\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm, serpapi_api_key=serpapi_api_key)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    memory=memory # 记忆组件\n",
    ")\n",
    "\n",
    "print(agent)\n",
    "# 看下模版\n",
    "print(agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: Hello SouthAki, nice to meet you! I'm Assistant, a language model here to help with any questions or conversations you have. How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello SouthAki, nice to meet you! I'm Assistant, a language model here to help with any questions or conversations you have. How can I assist you today?\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"hi, i am SouthAki,what is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Search\n",
      "Action Input: 香港 旅游景点\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'position': 1, 'block_position': 'top', 'title': '4-Hour Private Hong Kong Layover Tour', 'price': '$527', 'extracted_price': 527, 'link': 'https://www.viator.com/en-us/hong-kong-sar', 'source': 'Viator', 'rating': 5.0, 'reviews': 24, 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT151NAaULmr_pNlSKOzEFK9MOPPSeAej8NskqIVEhZS8Im&s=4', 'extensions': ['Free cancellation']}, {'position': 2, 'block_position': 'top', 'title': '6-Hour Private Hong Kong Layover Tour', 'price': '$792', 'extracted_price': 792, 'link': 'https://www.viator.com/en-us/hong-kong-sar', 'source': 'Viator', 'rating': 5.0, 'reviews': 14, 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRQ1yvAujHf4ttk8ZACiZ72lC8dxkaPZqPMEiTC93gouGpG&s=4', 'extensions': ['Free cancellation']}, {'position': 3, 'block_position': 'top', 'title': 'Victoria Harbour Day or Sunset Cruise', 'price': '$20', 'extracted_price': 20, 'link': 'https://www.getyourguide.com/', 'source': 'GetYourGuide', 'rating': 4.4, 'reviews': 90, 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ3FnrvqM7sLsolWBPOluVaJhybQ7M3BSe9-piPOAoTqRc9&s=4', 'extensions': ['Kid-friendly']}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "AI: 香港有很多好玩的地方！例如，你可以考虑参加一个私人香港过境游，比如4小时或6小时的行程，这将带你游览城市的著名景点。此外，维多利亚港的日间或日落巡游也是一个不错的选择，你可以在游船上欣赏到香港壮观的天际线。这些都是游客们非常喜欢的活动。如果你对具体的景点或者信息有兴趣，可以告诉我，我会提供更多的帮助。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'香港有很多好玩的地方！例如，你可以考虑参加一个私人香港过境游，比如4小时或6小时的行程，这将带你游览城市的著名景点。此外，维多利亚港的日间或日落巡游也是一个不错的选择，你可以在游船上欣赏到香港壮观的天际线。这些都是游客们非常喜欢的活动。如果你对具体的景点或者信息有兴趣，可以告诉我，我会提供更多的帮助。'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"香港有哪里比较好玩的吗?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: 当然，你的名字是SouthAki，所以你的名字的最后三个字母是\"ki\"。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'当然，你的名字是SouthAki，所以你的名字的最后三个字母是\"ki\"。'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"我还没玩过,你知道我名字后三个字母是什么吗?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Search\n",
      "Action Input: Current temperature in Guangzhou, Guangdong Province, China\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'weather_result', 'temperature': '91', 'unit': 'Fahrenheit', 'precipitation': '7%', 'humidity': '63%', 'wind': '13 mph', 'location': 'Guangzhou, Guangdong Province, China', 'date': 'Sunday 5:00 PM', 'weather': 'Partly cloudy'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: 目前，中国广东省广州市的气温是91华氏度（约32.8摄氏度），天气部分多云，有7%的降水概率，湿度为63%，风速为13英里/小时。请注意，天气情况可能会变化，请随时查看最新的预报。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'目前，中国广东省广州市的气温是91华氏度（约32.8摄氏度），天气部分多云，有7%的降水概率，湿度为63%，风速为13英里/小时。请注意，天气情况可能会变化，请随时查看最新的预报。'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"中国广东省广州市现在的气温是多少来着?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: So far, we have asked five questions in this conversation.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'So far, we have asked five questions in this conversation.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"截止到现在我们问了多少问题?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chat_convasational_react_description 使用了chatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatTongyi\n",
    "from langchain.agents import(\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "# 加载 API key\n",
    "load_dotenv(find_dotenv())\n",
    "dashscope_api_key = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "serpapi_api_key = os.getenv(\"SERPAPI_API_KEY\")\n",
    "\n",
    "# 记忆组件\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages= True\n",
    ")\n",
    "\n",
    "llm = ChatTongyi(\n",
    "    dashscope_api_key = dashscope_api_key,\n",
    "    model_name = \"qwen-vl-max\",\n",
    "    temperature = 0,\n",
    ")\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm, serpapi_api_key=serpapi_api_key)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    memory=memory # 记忆组件\n",
    ")\n",
    "\n",
    "print(agent)\n",
    "# 看下模版\n",
    "print(agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: Hi 南秋SouthAki, nice to meet you! I'm Assistant, a language model here to assist you with any questions or discussions. How can I help you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hi 南秋SouthAki, nice to meet you! I'm Assistant, a language model here to assist you with any questions or discussions. How can I help you today?\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"hi, i am 南秋SouthAki,what is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Search\n",
      "Action Input: \"Hong Kong famous foods\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m19 Must-eat Foods in Hong Kong\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: 香港的美食非常丰富多样！以下是一些香港著名的美食，你可以尝试一下：\n",
      "\n",
      "1. 港式早茶：包括点心如虾饺、肠粉和烧卖。\n",
      "2. 烧鹅：香脆的外皮和嫩滑的肉质非常美味。\n",
      "3. 云吞面：鲜美的馄饨搭配弹牙的面条。\n",
      "4. 寿司和刺身：香港有众多优质的日本餐厅。\n",
      "5. 蛇羹：一种传统的汤，由蛇肉和其他配料制成。\n",
      "6. 柠檬茶和鸳鸯：经典的港式饮品。\n",
      "7. 奶茶和菠萝油：奶茶醇厚，菠萝油酥软可口。\n",
      "8. 煲仔饭：在小砂锅中烹煮的米饭，通常配有肉类和蔬菜。\n",
      "9. 西多士：法式吐司蘸蛋液炸制，常配以炼乳或花生酱。\n",
      "10. 冰室的甜品：如芒果糯米糍、杨枝甘露等。\n",
      "\n",
      "这些都是香港非常受欢迎的美食，你一定不能错过。如果你有特别的口味或者想知道更多，也可以告诉我哦！\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'香港的美食非常丰富多样！以下是一些香港著名的美食，你可以尝试一下：\\n\\n1. 港式早茶：包括点心如虾饺、肠粉和烧卖。\\n2. 烧鹅：香脆的外皮和嫩滑的肉质非常美味。\\n3. 云吞面：鲜美的馄饨搭配弹牙的面条。\\n4. 寿司和刺身：香港有众多优质的日本餐厅。\\n5. 蛇羹：一种传统的汤，由蛇肉和其他配料制成。\\n6. 柠檬茶和鸳鸯：经典的港式饮品。\\n7. 奶茶和菠萝油：奶茶醇厚，菠萝油酥软可口。\\n8. 煲仔饭：在小砂锅中烹煮的米饭，通常配有肉类和蔬菜。\\n9. 西多士：法式吐司蘸蛋液炸制，常配以炼乳或花生酱。\\n10. 冰室的甜品：如芒果糯米糍、杨枝甘露等。\\n\\n这些都是香港非常受欢迎的美食，你一定不能错过。如果你有特别的口味或者想知道更多，也可以告诉我哦！'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"香港有什么比较好吃的美食?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Calculator\n",
      "Action Input: Not needed, as the task is not related to calculations.\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: Search\n",
      "Action Input: \"current weather Macau\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer:  The current weather in Macau is [insert current weather details here, such as sunny, cloudy, temperature, humidity, etc.]. Please note that this information may not be real-time and it's recommended to check a weather service for the most up-to-date conditions.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: 对不起，我无法提供实时的天气信息，但通常来说，你可以检查天气预报服务来获取澳门当前的准确天气。不过，如果你想知道我是否还记得你名字的最后一个字母，那当然是\"A\"。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'对不起，我无法提供实时的天气信息，但通常来说，你可以检查天气预报服务来获取澳门当前的准确天气。不过，如果你想知道我是否还记得你名字的最后一个字母，那当然是\"A\"。'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"我还没吃过,不过你还知道我名字的最后一个字母是什么吗?中国澳门现在的气温是多少来着?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: In this conversation, we have now asked seven questions.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In this conversation, we have now asked seven questions.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"截止到现在我们问了多少问题?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来,我们来讲一下openai_functions 使用到了openai的函数调用来实现的,只支持OpenAI模型\n",
    "所以下面的演示,我直接以代码的形式讲解,不会去运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模块\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import(\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"\"\n",
    "\n",
    "# 记忆组件\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature = 0,\n",
    "    model = 'gpt-4-0613'\n",
    ")\n",
    "tools = load_tools(\n",
    "    [\"serpapi\", \"llm-math\"],\n",
    "    llm = llm\n",
    ")\n",
    "agent = initialize_agent(\n",
    "    tools = tools,\n",
    "    llm = llm,\n",
    "    agent = AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose = True,\n",
    "    memory = memory\n",
    ")\n",
    "print(agent)\n",
    "print(agent.agent.prompt.messages)\n",
    "\n",
    "# 然后后续只需要运行agent.run(input = \"\"),就行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "structured_chat_zero_shot_reace_description 对输出的结构化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=ConversationBufferMemory(return_messages=True, memory_key='chat_history') verbose=True tags=['structured-chat-zero-shot-react-description'] agent=StructuredChatAgent(llm_chain=LLMChain(prompt=ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nSearch: A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {{\\'tool_input\\': {{\\'type\\': \\'string\\'}}}}\\nCalculator: Useful for when you need to answer questions about math., args: {{\\'tool_input\\': {{\\'type\\': \\'string\\'}}}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or Search, Calculator\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], template='{input}\\n\\n{agent_scratchpad}'))]), llm=ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********'))), output_parser=StructuredChatOutputParserWithRetries(output_fixing_parser=OutputFixingParser(parser=StructuredChatOutputParser(), retry_chain=PromptTemplate(input_variables=['completion', 'error', 'instructions'], template='Instructions:\\n--------------\\n{instructions}\\n--------------\\nCompletion:\\n--------------\\n{completion}\\n--------------\\n\\nAbove, the Completion did not satisfy the constraints given in the Instructions.\\nError:\\n--------------\\n{error}\\n--------------\\n\\nPlease try again. Please only respond with an answer that satisfies the constraints laid out in the Instructions:')\n",
      "| ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********')))), allowed_tools=['Search', 'Calculator']) tools=[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>), Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********'))))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********'))))>)]\n",
      "Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
      "\n",
      "Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {{'tool_input': {{'type': 'string'}}}}\n",
      "Calculator: Useful for when you need to answer questions about math., args: {{'tool_input': {{'type': 'string'}}}}\n",
      "\n",
      "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
      "\n",
      "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
      "\n",
      "Provide only ONE action per $JSON_BLOB, as shown:\n",
      "\n",
      "```\n",
      "{{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}}\n",
      "```\n",
      "\n",
      "Follow this format:\n",
      "\n",
      "Question: input question to answer\n",
      "Thought: consider previous and subsequent steps\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: action result\n",
      "... (repeat Thought/Action/Observation N times)\n",
      "Thought: I know what to respond\n",
      "Action:\n",
      "```\n",
      "{{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Final response to human\"\n",
      "}}\n",
      "```\n",
      "\n",
      "Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\n",
      "Thought:\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatTongyi\n",
    "from langchain.agents import(\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "# 加载 API key\n",
    "load_dotenv(find_dotenv())\n",
    "dashscope_api_key = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "serpapi_api_key = os.getenv(\"SERPAPI_API_KEY\")\n",
    "\n",
    "# 记忆组件\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages= True\n",
    ")\n",
    "\n",
    "llm = ChatTongyi(\n",
    "    dashscope_api_key = dashscope_api_key,\n",
    "    model_name = \"qwen-vl-max\",\n",
    "    temperature = 0,\n",
    ")\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm, serpapi_api_key=serpapi_api_key)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    memory=memory # 记忆组件\n",
    ")\n",
    "\n",
    "print(agent)\n",
    "# 看下模版\n",
    "print(agent.agent.llm_chain.prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看上面的提示词模版基本上是一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I can use the search engine to find information on LangChain.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search\",\n",
      "  \"action_input\": \"What is LangChain?\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[\"LangChain is a framework designed to simplify the creation of applications using large language models. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\", 'LangChain entity_type: kp3_verticals.', 'LangChain kgmid: /g/11kjpl7_60.', 'LangChain initial_release_date: October 2022.', 'LangChain developer_s: Harrison Chase.', 'LangChain license: MIT License.', 'LangChain repository: github.com/langchain-ai/langchain.', 'LangChain stable_release: 0.1.16 / 11 April 2024; 2 months ago.', 'LangChain written_in: Python and JavaScript.', 'LangChain provides AI developers with tools to connect language models with external data sources. It is open-source and supported by an active community.', 'LangChain is a framework to build with LLMs by chaining interoperable components. LangGraph is the framework for building controllable agentic workflows.', \"LangChain uses the power of AI large language models combined with data sources to create quite powerful apps. Read how it works and how it's used.\", 'LangChain is essentially a library of abstractions for Python and Javascript, representing common steps and concepts necessary to work with language models.', 'LangChain is a framework for developing applications powered by large language models (LLMs). LangChain simplifies every stage of the LLM application lifecycle:.', 'LangChain is a sophisticated framework comprising several key components that work in synergy to enhance natural language processing tasks.', 'Langchain makes creating agents using large language models simple through their agents API. Developers can use OpenAI functions or other means ...', 'LangChain is an open-source framework designed to simplify the creation of applications using large language models (LLMs).', 'LangChain is a framework for developing applications powered by large language models (LLMs). For these applications, LangChain simplifies the entire ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI know what to respond\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"LangChain is an open-source framework designed to simplify the creation of applications using large language models (LLMs). It simplifies every stage of the LLM application lifecycle and includes a library of abstractions for Python and JavaScript, representing common steps and concepts necessary to work with language models.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is langchain?',\n",
       " 'chat_history': [HumanMessage(content='what is langchain?'),\n",
       "  AIMessage(content='LangChain is an open-source framework designed to simplify the creation of applications using large language models (LLMs). It simplifies every stage of the LLM application lifecycle and includes a library of abstractions for Python and JavaScript, representing common steps and concepts necessary to work with language models.')],\n",
       " 'output': 'LangChain is an open-source framework designed to simplify the creation of applications using large language models (LLMs). It simplifies every stage of the LLM application lifecycle and includes a library of abstractions for Python and JavaScript, representing common steps and concepts necessary to work with language models.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\"input\":\"what is langchain?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将memory插入提示词模版里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>), Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********'))))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********'))))>)]\n"
     ]
    }
   ],
   "source": [
    "# 导入模块\n",
    "from langchain.agents import (\n",
    "    load_agent,\n",
    "    initialize_agent,\n",
    "    AgentType,\n",
    "    Tool,\n",
    "    load_tools\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.chains import LLMMathChain\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "# 加载 API key\n",
    "load_dotenv(find_dotenv())\n",
    "dashscope_api_key = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "serpapi_api_key = os.getenv(\"SERPAPI_API_KEY\")\n",
    "\n",
    "# 定义大模型\n",
    "llm = ChatTongyi(\n",
    "    model_name= 'qwen-vl-max',\n",
    "    temperature= 0,\n",
    "    dashscope_api_key = dashscope_api_key\n",
    ")\n",
    "# 加载工具\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm, serpapi_api_key=serpapi_api_key)\n",
    "print(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加memory组件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent = AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose = True,\n",
    "    memory = memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印一下这个agent_chain是什么内容看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=ConversationBufferMemory(return_messages=True, memory_key='chat_history') verbose=True tags=['chat-conversational-react-description'] agent=ConversationalChatAgent(llm_chain=LLMChain(prompt=ChatPromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\\n> Calculator: Useful for when you need to answer questions about math.\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": string, \\\\\\\\ The action to take. Must be one of Search, Calculator\\n    \"action_input\": string \\\\\\\\ The input to the action\\n}}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"action_input\": string \\\\\\\\ You should put what you want to return to use here\\n}}\\n```\\n\\nUSER\\'S INPUT\\n--------------------\\nHere is the user\\'s input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\n{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')]), llm=ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********'))), output_parser=ConvoOutputParser(), allowed_tools=['Search', 'Calculator'], template_tool_response=\"TOOL RESPONSE: \\n---------------------\\n{observation}\\n\\nUSER'S INPUT\\n--------------------\\n\\nOkay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.\") tools=[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>), Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********'))))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********'))))>)]\n"
     ]
    }
   ],
   "source": [
    "print(agent_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比如我们想看到模版的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nSearch: A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {{\\'tool_input\\': {{\\'type\\': \\'string\\'}}}}\\nCalculator: Useful for when you need to answer questions about math., args: {{\\'tool_input\\': {{\\'type\\': \\'string\\'}}}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or Search, Calculator\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], template='{input}\\n\\n{agent_scratchpad}'))]\n"
     ]
    }
   ],
   "source": [
    "print(agent_chain.agent.llm_chain.prompt.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尝试运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I know what to respond\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Hello SouthAki, how can I assist you today?\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: 我需要使用搜索工具来了解广播剧的相关信息。\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search\",\n",
      "  \"action_input\": \"What is a radio drama?\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['Radio drama is a dramatized, purely acoustic performance. With no visual component, radio drama depends on dialogue, music and sound effects to help the listener imagine the characters and story: \"It is auditory in the physical dimension but equally powerful as a visual force in the psychological dimension.\"', 'Radio drama entity_type: kp3_verticals.', 'Radio drama kgmid: /m/0f9vg.', 'Radio drama is a dramatized, purely acoustic performance. With no visual component, radio drama depends on dialogue, music and sound effects to help the ...', 'Radio drama (or audio drama, audio play, radio play, radio theatre) is a dramatised, purely acoustic performance, broadcast on radio or published on audio ...', 'The basic premise is that the actors you see on stage are “radio actors” who portray the characters in each story using their voice and facial ...', \"Radio plays are dramatized, purely auditory performances that are specifically designed to focus on painting a picture in the listeners mind's ...\", 'Radio plays, or radio dramas, are dramatized, acoustic-only performances. They are typically listened to in the ear, rather than watched upon a stage, as they ...', 'In 1921, the KDKA radio station in Pittsburgh aired a brief sketch called A Rural Line on Education, becoming the first “play” written specifically for radio ...', 'An audio drama is a fictional story presented through an audio-only medium, performed for the listener. An audio book is generally a written ...', 'Radio drama (or audio drama, audio play, radio play, radio theatre, or audio theatre) is a dramatized, purely acoustic performance without visual elements.', 'Audio Theater – Term used for multi-cast narrative stories that follow a dramatic script, uses narration, sound FX libraries, and music.']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI can now understand what a radio drama is.\n",
      "\n",
      "Thought: I can give my response.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Yes, I enjoy listening to radio dramas too! They're a great way to get lost in a story without needing to rely on visuals.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: 我知道答案。\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"你的名字是无法确定的，因为我是作为一个人工智能助手被调用的。你可能需要询问该用户的姓名。\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你的名字是无法确定的，因为我是作为一个人工智能助手被调用的。你可能需要询问该用户的姓名。'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(\"我叫SouthAki\")\n",
    "agent_chain.run(\"我喜欢听广播剧,你喜欢听吗?\")\n",
    "agent_chain.run(\"我叫什么名字?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到我们的memory没有起作用,所以这里要加入一个参数\n",
    "agent_kwargs传递参数,把memory key传入到提示词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent = AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose = True,\n",
    "    agent_kwargs={\n",
    "        \"extra_prom_messages\":[\n",
    "            MessagesPlaceholder(variable_name= \"chat_history\"),\n",
    "            MessagesPlaceholder(variable_name= \"agent_scratchpad\")\n",
    "        ]\n",
    "    },\n",
    "    memory = memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I know what to respond\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Hello SouthAki, how can I assist you today?\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: 我需要使用搜索工具来了解广播剧的相关信息。\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search\",\n",
      "  \"action_input\": \"What is a radio drama?\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['Radio drama is a dramatized, purely acoustic performance. With no visual component, radio drama depends on dialogue, music and sound effects to help the listener imagine the characters and story: \"It is auditory in the physical dimension but equally powerful as a visual force in the psychological dimension.\"', 'Radio drama entity_type: kp3_verticals.', 'Radio drama kgmid: /m/0f9vg.', 'Radio drama is a dramatized, purely acoustic performance. With no visual component, radio drama depends on dialogue, music and sound effects to help the ...', 'Radio drama (or audio drama, audio play, radio play, radio theatre) is a dramatised, purely acoustic performance, broadcast on radio or published on audio ...', 'The basic premise is that the actors you see on stage are “radio actors” who portray the characters in each story using their voice and facial ...', \"Radio plays are dramatized, purely auditory performances that are specifically designed to focus on painting a picture in the listeners mind's ...\", 'Radio plays, or radio dramas, are dramatized, acoustic-only performances. They are typically listened to in the ear, rather than watched upon a stage, as they ...', 'In 1921, the KDKA radio station in Pittsburgh aired a brief sketch called A Rural Line on Education, becoming the first “play” written specifically for radio ...', 'An audio drama is a fictional story presented through an audio-only medium, performed for the listener. An audio book is generally a written ...', 'Radio drama (or audio drama, audio play, radio play, radio theatre, or audio theatre) is a dramatized, purely acoustic performance without visual elements.', 'Audio Theater – Term used for multi-cast narrative stories that follow a dramatic script, uses narration, sound FX libraries, and music.']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI can now understand what a radio drama is.\n",
      "\n",
      "Thought: I can give my response.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Yes, I enjoy listening to radio dramas too! They're a great way to get lost in a story without needing to rely on visuals.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: 我知道答案。\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"你的名字是无法确定的，因为我是作为一个人工智能助手被调用的。你可能需要询问该用户的姓名。\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你的名字是无法确定的，因为我是作为一个人工智能助手被调用的。你可能需要询问该用户的姓名。'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(\"我叫SouthAki\")\n",
    "agent_chain.run(\"我喜欢听广播剧,你喜欢听吗?\")\n",
    "agent_chain.run(\"我叫什么名字?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在agent和tools之间共享记忆\n",
    "- 自定义一个工具用来LLMChain来总结内容\n",
    "- 使用readonlymemory来共享记忆\n",
    "- 观察共享和不共享的区别\n",
    "我们来实现一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "# 加载 API key\n",
    "load_dotenv(find_dotenv())\n",
    "dashscope_api_key = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "serpapi_api_key = os.getenv(\"SERPAPI_API_KEY\")\n",
    "\n",
    "# 导入模块\n",
    "from langchain.agents import (\n",
    "    load_agent,\n",
    "    initialize_agent,\n",
    "    AgentType,\n",
    "    Tool\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory,ReadOnlySharedMemory\n",
    "from langchain.llms import Tongyi\n",
    "from langchain.chains import LLMChain\n",
    "from  langchain.prompts import PromptTemplate,MessagesPlaceholder\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "\n",
    "# 创建llm\n",
    "llm= Tongyi(\n",
    "    dashscope_api_key= dashscope_api_key,\n",
    "    model= \"Qwen-max\",\n",
    "    temperature = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一条链来总结对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiele\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# 问题\n",
    "template= \"\"\"\n",
    "    以下是一段AI机器人和人类的对话:\n",
    "    {chat_history}\n",
    "    根据输入和上面的对话记录写一份对话总结.\n",
    "    输入:{input}\n",
    "\"\"\"\n",
    "# 提示词模版\n",
    "prompt = PromptTemplate(\n",
    "    # 输入验证器\n",
    "    input_variables=[\"chat_history\", \"input\"],\n",
    "    template=template,\n",
    ")\n",
    "# 创建记忆\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages= True    \n",
    ")\n",
    "\n",
    "# 关键一步,如何让我们的Agent和Tool共享记忆\n",
    "readonlymemory = ReadOnlySharedMemory(memory= memory)\n",
    "\n",
    "# 构建chain\n",
    "summary_chain = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt= prompt,\n",
    "    verbose= True,\n",
    "    memory= readonlymemory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来构建工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tool(name='Search', description='当需要了解实时信息或者你不知道的事情的时候才可以使用搜索工具', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>), Tool(name='Summary', description='当你被要求总结一段对话的时候才可以使用这个工具,工具输入必须为字符串,只在必要的时候使用', func=<function SummaryChainFun at 0x0000020DF5BFE3E0>)]\n"
     ]
    }
   ],
   "source": [
    "# 搜索工具\n",
    "search = SerpAPIWrapper(\n",
    "    serpapi_api_key= serpapi_api_key,\n",
    "    params={\n",
    "        \"engine\": \"google\"\n",
    "    }\n",
    ")\n",
    "# 总结工具(自定义)\n",
    "def SummaryChainFun(history):\n",
    "    print(\"\\n====================总结chain开始运行==========================\")\n",
    "    print(\"输入历史:\",history)\n",
    "    summary_chain.run(history)\n",
    "\n",
    "tools= [\n",
    "    Tool(\n",
    "        name= \"Search\",\n",
    "        func= search.run,\n",
    "        description= \"当需要了解实时信息或者你不知道的事情的时候才可以使用搜索工具\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name= \"Summary\",\n",
    "        func= SummaryChainFun,\n",
    "        description= \"当你被要求总结一段对话的时候才可以使用这个工具,工具输入必须为字符串,只在必要的时候使用\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# 我们看下内容\n",
    "print(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来,我们创建Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Search(query: str, **kwargs: Any) -> str - 当需要了解实时信息或者你不知道的事情的时候才可以使用搜索工具\n",
      "Summary(history) - 当你被要求总结一段对话的时候才可以使用这个工具,工具输入必须为字符串,只在必要的时候使用\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Search, Summary]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiele\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "agent_chain = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    memory = memory\n",
    ")\n",
    "# 验证一下\n",
    "print(agent_chain.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok,这里可以看到我们的模版,但是不知道大家有没有发现,就是上面的内容中,并没有我们关于记忆的部分,也就是我们定义的chat_history\n",
    "那么怎么办呢\n",
    "这里可以看一下上面的部分,就是上面部分我们可以分成三个部分\n",
    "分别是: 前缀,内容,后缀\n",
    "其中前缀后缀都是可以由我们自定义,那么我们可以修改上面的前后缀,加入我们的记忆chat_history,来实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\n",
      "    Search: Use this tool to search for information.\n",
      "    Summary: Use this tool to summarize conversations.\n",
      "\n",
      "\n",
      "Search(query: str, **kwargs: Any) -> str - 当需要了解实时信息或者你不知道的事情的时候才可以使用搜索工具\n",
      "Summary(history) - 当你被要求总结一段对话的时候才可以使用这个工具,工具输入必须为字符串,只在必要的时候使用\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Search, Summary]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "\n",
      "    Begin!\"\n",
      "    {chat_history}\n",
      "    Question: {input}\n",
      "    {agent_scratchpad}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 修改代码\n",
    "prefix = \"\"\"\n",
    "    Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\n",
    "    Search: Use this tool to search for information.\n",
    "    Summary: Use this tool to summarize conversations.\n",
    "\"\"\"\n",
    "suffix = \"\"\"\n",
    "    Begin!\"\n",
    "    {chat_history}\n",
    "    Question: {input}\n",
    "    {agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "agent_chain = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors= True,\n",
    "    agent_kwargs={\n",
    "        \"prefix\": prefix,\n",
    "        \"suffix\": suffix,\n",
    "        \"agent_scratchpad\": MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "        \"chat_history\": MessagesPlaceholder(\"chat_history\"),\n",
    "        \"input\": MessagesPlaceholder(\"input\")\n",
    "    },\n",
    "    memory = memory\n",
    ")\n",
    "# 来看下我们修改后的结果\n",
    "print(agent_chain.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok,我们看到我们修改了前后缀已经成功了,来试试看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiele\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: 这是一个关于历史知识的问题，不需要使用搜索工具。\n",
      "Final Answer: 美国的第45任总统是唐纳德·特朗普（Donald Trump）。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'美国的第45任总统是唐纳德·特朗普（Donald Trump）。'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input = \"美国第45任总统是谁?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: 我知道答案，不需要使用工具。\n",
      "Final Answer: 唐纳德·特朗普的夫人叫梅拉尼娅·特朗普（Melania Trump）。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'唐纳德·特朗普的夫人叫梅拉尼娅·特朗普（Melania Trump）。'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input = \"他的夫人叫什么名字?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='美国第45任总统是谁?'), AIMessage(content='美国的第45任总统是唐纳德·特朗普（Donald Trump）。'), HumanMessage(content='他的夫人叫什么名字?'), AIMessage(content='唐纳德·特朗普的夫人叫梅拉尼娅·特朗普（Melania Trump）。')]\n"
     ]
    }
   ],
   "source": [
    "# 我们看下对话的记忆的\n",
    "print(agent_chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: 我应该使用Summary工具来总结我们的对话内容。\n",
      "Action: Summary\n",
      "Action Input: \"[HumanMessage(content='美国第45任总统是谁?'), AIMessage(content='美国的第45任总统是唐纳德·特朗普（Donald Trump）。'), HumanMessage(content='他的夫人叫什么名字?'), AIMessage(content='唐纳德·特朗普的夫人叫梅拉尼娅·特朗普（Melania Trump）。')]\"\n",
      "\u001b[0m\n",
      "====================总结chain开始运行==========================\n",
      "输入历史: [HumanMessage(content='美国第45任总统是谁?'), AIMessage(content='美国的第45任总统是唐纳德·特朗普（Donald Trump）。'), HumanMessage(content='他的夫人叫什么名字?'), AIMessage(content='唐纳德·特朗普的夫人叫梅拉尼娅·特朗普（Melania Trump）。')]\"\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    以下是一段AI机器人和人类的对话:\n",
      "    [HumanMessage(content='美国第45任总统是谁?'), AIMessage(content='美国的第45任总统是唐纳德·特朗普（Donald Trump）。'), HumanMessage(content='他的夫人叫什么名字?'), AIMessage(content='唐纳德·特朗普的夫人叫梅拉尼娅·特朗普（Melania Trump）。')]\n",
      "    根据输入和上面的对话记录写一份对话总结.\n",
      "    输入:[HumanMessage(content='美国第45任总统是谁?'), AIMessage(content='美国的第45任总统是唐纳德·特朗普（Donald Trump）。'), HumanMessage(content='他的夫人叫什么名字?'), AIMessage(content='唐纳德·特朗普的夫人叫梅拉尼娅·特朗普（Melania Trump）。')]\"\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mNone\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 我现在可以作总结了。\n",
      "Final Answer: 我们聊到了美国的第45任总统是唐纳德·特朗普，以及他的夫人名叫梅拉尼娅·特朗普。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'我们聊到了美国的第45任总统是唐纳德·特朗普，以及他的夫人名叫梅拉尼娅·特朗普。'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input= \"我们都聊了什么?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: 需要搜索相关信息来获取答案。\n",
      "Action: Search\n",
      "Action Input: 中国最新南极科考站 开站时间\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['【环球时报报道记者樊巍刘扬】2月7日，中国南极秦岭站正式开站，这是继长城站、中山站、昆仑站、泰山站之后，我国建设的第五座南极考察站，也是第三座常年 ...', '中国在南极的科考站从无到有，长城站、中山站、昆仑站、泰山站，已先后相继矗立在南极陆地或南极冰盖上，而极地科学家期盼已久的秦岭站也终于在第40次科考 ...', '自然资源部今天宣布我国南极秦岭站正式开站这是我国在南极建设的第五个科学考察站我国第五座南极科考站今天正式开站秦岭站是我国在南极继长城站、中山 ...', '【侨报网综合讯】中国第五个南极考察站秦岭站于7日正式开站。中国国家海洋局极地考察办公室副主任龙威介绍，秦岭是横贯中国中部的古老山脉，是地理上 ...', '央视网消息：今天（1月31日），正在建设中的我国第五座南极科考站——罗斯海新站的停机坪正式开工建设。来看总台央视记者从罗斯海发回的报道。', '世界尽头南极，又添了一个新地标。2月7日，位于西南极罗斯海恩克斯堡岛的中国秦岭站开站。这是中国第五个南极科考站，第三个南极常年考察站，也是我国首个 ...', '作为新时代我国建立的第1个常年科考站，中国南极秦岭站填补了我国在南极罗斯海区域的考察空白。作为在秦岭站里中国科考队的“得力助手”，联想ThinkPad将 ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 我现在知道中国最新的南极科考站是秦岭站，它在2023年2月7日正式开站。\n",
      "Final Answer: 中国最新的南极科考站是秦岭站，该站在2023年2月7日开站并展开科学考察活动。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'中国最新的南极科考站是秦岭站，该站在2023年2月7日开站并展开科学考察活动。'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input= \"中国最新的南极科考站是什么?哪一年开站展开科学考察?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: 我需要总结当前的对话内容，使其适合一个5岁孩子理解。\n",
      "Action: Summary\n",
      "Action Input: 我们谈论了美国的第45任总统是唐纳德·特朗普，他的妻子叫梅拉尼娅·特朗普。还有，中国有一个新的南极科考站叫秦岭站，它在2023年开始工作。\n",
      "\u001b[0m\n",
      "====================总结chain开始运行==========================\n",
      "输入历史: 我们谈论了美国的第45任总统是唐纳德·特朗普，他的妻子叫梅拉尼娅·特朗普。还有，中国有一个新的南极科考站叫秦岭站，它在2023年开始工作。\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    以下是一段AI机器人和人类的对话:\n",
      "    [HumanMessage(content='美国第45任总统是谁?'), AIMessage(content='美国的第45任总统是唐纳德·特朗普（Donald Trump）。'), HumanMessage(content='他的夫人叫什么名字?'), AIMessage(content='唐纳德·特朗普的夫人叫梅拉尼娅·特朗普（Melania Trump）。'), HumanMessage(content='我们都聊了什么?'), AIMessage(content='我们聊到了美国的第45任总统是唐纳德·特朗普，以及他的夫人名叫梅拉尼娅·特朗普。'), HumanMessage(content='中国最新的南极科考站是什么?哪一年开站展开科学考察?'), AIMessage(content='中国最新的南极科考站是秦岭站，该站在2023年2月7日开站并展开科学考察活动。')]\n",
      "    根据输入和上面的对话记录写一份对话总结.\n",
      "    输入:我们谈论了美国的第45任总统是唐纳德·特朗普，他的妻子叫梅拉尼娅·特朗普。还有，中国有一个新的南极科考站叫秦岭站，它在2023年开始工作。\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mNone\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 我现在可以给出总结了，内容已经简化适合5岁的孩子理解\n",
      "Final Answer: 我们聊到美国有一位叫唐纳德·特朗普的先生，他是第45任总统，他的太太叫梅拉尼娅。还有一个叫秦岭的新冰冻土地站，它在中国的南极，2023年开始科学家在那里做研究哦。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'我们聊到美国有一位叫唐纳德·特朗普的先生，他是第45任总统，他的太太叫梅拉尼娅。还有一个叫秦岭的新冰冻土地站，它在中国的南极，2023年开始科学家在那里做研究哦。'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"帮我总结下目前的对话内容，给我5岁的儿子看看\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
