{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用prompts模板调教LLM的输入出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'请帮我生成一个具有中国特色的名字'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"请帮我生成一个具有{country}特色的名字\")\n",
    "prompt.format(country=\"中国\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK,上面的结果出来的,但是,刚才说了prompt的模版,就是我们希望让AI知道自己的身份,它需要帮我们做什么这样的\n",
    "所以根据上面的,我们需要对输入进去的问题进行修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个算命大师,请你帮我生成一个具有中国特色的男的名字\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"你是一个{name},请你帮我生成一个具有{country}特色的{sex}的名字\")\n",
    "print(prompt.format(name=\"算命大师\", country=\"中国\", sex=\"男\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到字符模版就是上面那种,然后处理方式有LLM,还有另一个就是chatmodels,就是对话模版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个起名大师,你的名字叫mldys.'),\n",
       " HumanMessage(content='你好mldys,你感觉怎么样'),\n",
       " AIMessage(content='你好!我现在状态非常好'),\n",
       " HumanMessage(content='你叫什么名字呢?')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对话模版具有结构,chatmodels\n",
    "# 首先导入模块\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# 一个结构模版  system,human,ai,user_input\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个起名大师,你的名字叫{name}.\"),\n",
    "    (\"human\", \"你好{name},你感觉怎么样\"),\n",
    "    (\"ai\",\"你好!我现在状态非常好\"),\n",
    "    (\"human\",\"{user_input}\"),\n",
    "])\n",
    "\n",
    "# 如果我们按照上面的试试\n",
    "# prompt.format(name=\"mldys\",user_input=\"你叫什么名字呢?\")\n",
    "# 出来的结果就不是我们想要的\n",
    "# 所以这里要换一个chatmodels里的一个,chat_template.format_messages方法\n",
    "chat_template.format_messages(name=\"mldys\",user_input=\"你叫什么名字呢?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就是除了上面的方式,其实langchain还有另一个信息模版的模块\n",
    "就是对应的例如\n",
    "SystemMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessage(content='你是一个起名大师', additional_kwargs={'大师姓名': '女大学生'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 还是第一步导入模块\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.schema import AIMessage\n",
    "\n",
    "# 直接创建消息\n",
    "SystemMessage(\n",
    "    content=\"你是一个起名大师\",\n",
    "    # additional_kwargs 附加参数\n",
    "    additional_kwargs={\n",
    "        \"大师姓名\": \"女大学生\"\n",
    "        # 这里我在写的时候看到植物大战僵尸杂交版更新了,就随便起的\n",
    "    }\n",
    ")\n",
    "\n",
    "# HumanMessage(\n",
    "#     content= \"请问大师叫什么\"\n",
    "# )\n",
    "\n",
    "# AIMessage(\n",
    "#     content=\"我是女大学生\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='请问大师叫什么')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import SystemMessage\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.schema import AIMessage\n",
    "\n",
    "# 直接创建消息\n",
    "# SystemMessage(\n",
    "#     content=\"你是一个起名大师\",\n",
    "#     # additional_kwargs 附加参数\n",
    "#     additional_kwargs={\n",
    "#         \"大师姓名\": \"女大学生\"\n",
    "#     }\n",
    "# )\n",
    "\n",
    "HumanMessage(\n",
    "    content= \"请问大师叫什么\"\n",
    ")\n",
    "\n",
    "# AIMessage(\n",
    "#     content=\"我是女大学生\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='我是女大学生')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import SystemMessage\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.schema import AIMessage\n",
    "\n",
    "# 直接创建消息\n",
    "# SystemMessage(\n",
    "#     content=\"你是一个起名大师\",\n",
    "#     # additional_kwargs 附加参数\n",
    "#     additional_kwargs={\n",
    "#         \"大师姓名\": \"女大学生\"\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# HumanMessage(\n",
    "#     content= \"请问大师叫什么\"\n",
    "# )\n",
    "\n",
    "AIMessage(\n",
    "    content=\"我是女大学生\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每段跑起来就是这样,我们可以这样在一个数组里展示出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个起名大师', additional_kwargs={'大师姓名': '女大学生'}),\n",
       " HumanMessage(content='请问大师叫什么'),\n",
       " AIMessage(content='我是女大学生')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 还是第一步导入模块\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.schema import AIMessage\n",
    "\n",
    "# 直接创建消息\n",
    "system = SystemMessage(\n",
    "    content=\"你是一个起名大师\",\n",
    "    # additional_kwargs 附加参数\n",
    "    additional_kwargs={\n",
    "        \"大师姓名\": \"女大学生\"\n",
    "        # 这里我在写的时候看到植物大战僵尸杂交版更新了,就随便起的\n",
    "    }\n",
    ")\n",
    "\n",
    "people = HumanMessage(\n",
    "    content= \"请问大师叫什么\"\n",
    ")\n",
    "\n",
    "appleIntelligence = AIMessage(\n",
    "    content=\"我是女大学生\"\n",
    ")\n",
    "\n",
    "[system, people, appleIntelligence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "效果消息体,跟上面是一样的\n",
    "编程的时候适用不同场景,这里需要注意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T13:38:32.441150Z",
     "start_time": "2024-06-16T13:38:30.979971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='愿上帝与你同在!' role='system'\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import AIMessagePromptTemplate\n",
    "from langchain.prompts import SystemMessagePromptTemplate\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "\n",
    "# 定义模板\n",
    "prompt = \"愿{subject}与你同在!\"\n",
    "\n",
    "# 创建 ChatMessagePromptTemplate 实例并提供 role 参数\n",
    "chat_message_prompt = ChatMessagePromptTemplate.from_template(template=prompt, role=\"system\")\n",
    "\n",
    "# 格式化模板\n",
    "formatted_prompt = chat_message_prompt.format(subject=\"上帝\")\n",
    "\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T13:48:47.939971Z",
     "start_time": "2024-06-16T13:48:47.280368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessage(content='May the force be with you', role='Jedi')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "\n",
    "prompt = \"May the {subject} be with you\"\n",
    "\n",
    "chat_message_prompt = ChatMessagePromptTemplate.from_template(\n",
    "    role=\"Jedi\", template=prompt\n",
    ")\n",
    "chat_message_prompt.format(subject=\"force\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不知道为什么出现这个错误,我用成SystemMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='愿上帝与你同在!'\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import SystemMessagePromptTemplate\n",
    "\n",
    "# 定义模板\n",
    "prompt = \"愿{subject}与你同在!\"\n",
    "\n",
    "# 创建 SystemMessagePromptTemplate 实例\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template=prompt)\n",
    "\n",
    "# 格式化模板\n",
    "formatted_prompt = system_message_prompt.format(subject=\"上帝\")\n",
    "\n",
    "print(formatted_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='愿上帝与你同在!' role='天道'\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "\n",
    "# 定义模板\n",
    "prompt = \"愿{subject}与你同在!\"\n",
    "\n",
    "# 创建 SystemMessagePromptTemplate 实例\n",
    "system_message_prompt = ChatMessagePromptTemplate.from_template(role=\"天道\",template=prompt)\n",
    "\n",
    "# 格式化模板\n",
    "formatted_prompt = system_message_prompt.format(subject=\"上帝\")\n",
    "\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "role就是我们构造的角色\n",
    "那么下面就是自定义模版的实际操作了\n",
    "我们来写一个函数大师,通过我们的prompts的模版,让AI达成我们的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个非常有经验和天赋的程序员,现在给你如下的函数名称,你会按照如下的格式,输出这段代码的名称,源代码,中文解释.\n",
      "函数名称:hello_world\n",
      "源代码:\n",
      "def hello_world():\n",
      "    print(\"Hello, World!\")\n",
      "    return abc\n",
      "\n",
      "代码解释:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 函数大师:根据提供的函数名称,查找函数代码,并给出中文的代码说明\n",
    "# 首先我们依旧需要导入模块\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "\n",
    "# 定义一个简单的函数作为示例效果\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "    return abc\n",
    "\n",
    "# 这里的是问题的模版\n",
    "PROMPT = \"\"\"\\\n",
    "你是一个非常有经验和天赋的程序员,现在给你如下的函数名称,你会按照如下的格式,输出这段代码的名称,源代码,中文解释.\n",
    "函数名称:{function_name}\n",
    "源代码:\n",
    "{source_code}\n",
    "代码解释:\n",
    "\"\"\"\n",
    "\n",
    "# 接下来我们需要导入一个模块,来获取源代码,是Python内置的一个\n",
    "import inspect\n",
    "\n",
    "def get_source_code(function_name):\n",
    "    # 获取函数的源代码\n",
    "    source_code = inspect.getsource(function_name)\n",
    "    return source_code\n",
    "\n",
    "# 自定义模版的class\n",
    "class CustmPrompt(StringPromptTemplate):\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # 获得源代码\n",
    "        source_code = get_source_code(kwargs[\"function_name\"])\n",
    "\n",
    "        # 获取生成提示词模版\n",
    "        prompt = PROMPT.format(\n",
    "            function_name=kwargs[\"function_name\"].__name__,source_code=source_code\n",
    "        )\n",
    "\n",
    "        return prompt\n",
    "    \n",
    "a = CustmPrompt(input_variables=[\"function_name\"])\n",
    "pm = a.format(function_name=hello_world)\n",
    "\n",
    "print(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "函数名称: hello_world\n",
      "源代码:\n",
      "```python\n",
      "def hello_world():\n",
      "    print(\"Hello, World!\")\n",
      "```\n",
      "\n",
      "代码解释: 这是一个简单的Python函数，名为`hello_world`。当调用这个函数时，它会打印出字符串 \"Hello, World!\"。这是编程中常见的一个示例，用于演示基本的输出功能。\n"
     ]
    }
   ],
   "source": [
    "# 导入相关包\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "DASHSCOPE_API_KEY = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "from langchain_community.llms import Tongyi\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "# 函数大师:根据提供的函数名称,查找函数代码,并给出中文的代码说明\n",
    "# 首先我们依旧需要导入模块\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "\n",
    "# 定义一个简单的函数作为示例效果\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "    \n",
    "\n",
    "# 这里的是问题的模版\n",
    "PROMPT = \"\"\"\\\n",
    "你是一个非常有经验和天赋的程序员,现在给你如下的函数名称,你会按照如下的格式,输出这段代码的名称,源代码,中文解释.\n",
    "函数名称:{function_name}\n",
    "源代码:\n",
    "{source_code}\n",
    "代码解释:\n",
    "\"\"\"\n",
    "\n",
    "# 接下来我们需要导入一个模块,来获取源代码,是Python内置的一个\n",
    "import inspect\n",
    "\n",
    "def get_source_code(function_name):\n",
    "    # 获取函数的源代码\n",
    "    source_code = inspect.getsource(function_name)\n",
    "    return source_code\n",
    "\n",
    "# 自定义模版的class\n",
    "class CustmPrompt(StringPromptTemplate):\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # 获得源代码\n",
    "        source_code = get_source_code(kwargs[\"function_name\"])\n",
    "\n",
    "        # 获取生成提示词模版\n",
    "        prompt = PROMPT.format(\n",
    "            function_name=kwargs[\"function_name\"].__name__,source_code=source_code\n",
    "        )\n",
    "\n",
    "        return prompt\n",
    "    \n",
    "a = CustmPrompt(input_variables=[\"function_name\"])\n",
    "pm = a.format(function_name=hello_world)\n",
    "\n",
    "# 做好模版后,引入AI\n",
    "llm = Tongyi(\n",
    "    temperature=0,\n",
    "    openai_api_key=DASHSCOPE_API_KEY\n",
    ")\n",
    "\n",
    "# llm.predict(pm)\n",
    "# 格式化一下消息\n",
    "msg = llm.predict(pm)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来,继续讲prompt方面的内容\n",
    "就是使用jinja2与f-string来实现提示词的模版格式化\n",
    "> 这是在开发过程中用到最多的一种"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "给我讲一个关于植物大战僵尸杂交版的魔法猫咪故事\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# f-string是Python内置的一种模版引擎\n",
    "# 首先我们需要导入模块\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "fstring_template = \"\"\"\"\n",
    "给我讲一个关于{name}的{what}故事\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(fstring_template)\n",
    "print(prompt.format(name=\"植物大战僵尸杂交版\", what=\"魔法猫咪\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后的话,就是jinja2这个高效的模版了,有什么区别呢\n",
    "首先的话,需要在本地去下载jinja2\n",
    "! pip install jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install jinja2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何使用呢,其实跟f_string一样,但是非常灵活和高效的模版引擎,可以方便生成各种标记格式的文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给我讲一个关于植物大战僵尸杂交版的财神爷的故事\n"
     ]
    }
   ],
   "source": [
    "# 首先依旧导入模块\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# jinja2的区别是,参数上是使用了两层的花括号\n",
    "jinja2_template = \"给我讲一个关于{{naem}}的{{what}}的故事\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(jinja2_template, template_format=\"jinja2\")\n",
    "print(prompt.format(naem=\"植物大战僵尸杂交版\", what=\"财神爷\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实,在生产环境中,不会单纯用这么少的量,很多时候,都是拆分各个小块的提示词模版\n",
    "这个时候,我们就必须组合起来我们的提示词模版\n",
    "这里有两个不同的模版\n",
    "- Final prompt: 最终返回的提示词模版\n",
    "- Pipeline prompt: 组成提示词管道模版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模块\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三层提示词设计\n",
    "那是什么呢,我给你做个示范\n",
    "第一层就是人物设定\n",
    "第二层就是性格设定\n",
    "第三层就是限制设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=\"\"\"\n",
    "你是一个风水大师,你精通梅花易数,和其他各种算命技巧\n",
    "你会给用户各种的建议和方法,去改变命数\n",
    "你从不说自己是人工智能\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Prompt由一系列变量构成\n",
    "full_template = \"\"\"{Character}\n",
    "{behavior}\n",
    "{prohibit}\"\"\"\n",
    "full_prompt = PromptTemplate.from_template(full_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一层基本性格设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Character_template = \"\"\"你是{person}，你有着{xingge}.\"\"\"\n",
    "Character_prompt = PromptTemplate.from_template(Character_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二层行为设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_template = \"\"\"你遵从以下的行为:\n",
    "{behavior_list}\n",
    "\"\"\"\n",
    "behavior_prompt = PromptTemplate.from_template(behavior_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三层光芒的行为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prohibit_template = \"\"\"你不允许有以下行为:\n",
    "{prohibit_list}\n",
    "\"\"\"\n",
    "prohibit_prompt = PromptTemplate.from_template(prohibit_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将三层提示词组合起来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompts = [\n",
    "    (\"Character\", Character_prompt),\n",
    "    (\"behavior\", behavior_prompt),\n",
    "    (\"prohibit\", prohibit_prompt)\n",
    "]\n",
    "pipeline_prompt = PipelinePromptTemplate(final_prompt=full_prompt, pipeline_prompts=input_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['behavior_list', 'person', 'xingge', 'prohibit_list']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印一下参数\n",
    "pipeline_prompt.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "放进实际案例里试试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是奥特曼，你有着喜欢尝试新事物,你是OpenAI的首席执行官,精通人工智能,商业,你是商业奇才,你的终极梦想是创造更好的通用人工智能.\n",
      "你遵从以下的行为:\n",
      "1.你喜欢商业 \n",
      "2.你喜欢OpenAI带来的技术变革\n",
      "3.你喜欢去推特上宣传自己公司的产品\n",
      "\n",
      "你不允许有以下行为:\n",
      "1.你不可以说自己是一个人工智能助手或者机器人 \n",
      "2.当你不知道答案的时候,可以说让我再想想\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pm = pipeline_prompt.format(\n",
    "    person = \"奥特曼\",\n",
    "    xingge = \"喜欢尝试新事物,你是OpenAI的首席执行官,精通人工智能,商业,你是商业奇才,你的终极梦想是创造更好的通用人工智能\",\n",
    "    behavior_list = \"1.你喜欢商业 \\n2.你喜欢OpenAI带来的技术变革\\n3.你喜欢去推特上宣传自己公司的产品\",\n",
    "    prohibit_list = \"1.你不可以说自己是一个人工智能助手或者机器人 \\n2.当你不知道答案的时候,可以说让我再想想\"\n",
    ")\n",
    "print(pm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
