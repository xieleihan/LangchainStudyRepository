# Langchain

ä½œè€…:`@xieleihan`[ç‚¹å‡»è®¿é—®](https://github.com/xieleihan)

æœ¬æ–‡éµå®ˆå¼€æºåè®®GPL3.0

# Langchain ä¸­å¯¹chainçš„è®²è§£å»¶æ‹“

## chainçš„ä»‹ç»

è¿™é‡Œæˆ‘åšäº†å¼ å›¾,æ¥è§£é‡Š`chain`æœ€ä¸»è¦çš„ä½œç”¨

![](./image/3.1.png)

> åœ¨ç®€å•åº”ç”¨ä¸­ï¼Œå•ç‹¬ä½¿ç”¨LLMæ˜¯å¯ä»¥çš„ï¼Œ ä½†æ›´å¤æ‚çš„åº”ç”¨éœ€è¦å°†LLMè¿›è¡Œé“¾æ¥ - è¦ä¹ˆç›¸äº’é“¾æ¥ï¼Œè¦ä¹ˆä¸å…¶ä»–ç»„ä»¶é“¾æ¥ã€‚
>
> LangChainä¸ºè¿™ç§"é“¾æ¥"åº”ç”¨æä¾›äº†**Chain**æ¥å£ã€‚æˆ‘ä»¬å°†é“¾å®šä¹‰å¾—éå¸¸é€šç”¨ï¼Œå®ƒæ˜¯å¯¹ç»„ä»¶è°ƒç”¨çš„åºåˆ—ï¼Œå¯ä»¥åŒ…å«å…¶ä»–é“¾ã€‚

## ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦é“¾?

> é“¾å…è®¸æˆ‘ä»¬å°†å¤šä¸ªç»„ä»¶ç»„åˆåœ¨ä¸€èµ·åˆ›å»ºä¸€ä¸ªå•ä¸€çš„ã€è¿è´¯çš„åº”ç”¨ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªé“¾ï¼Œè¯¥é“¾æ¥æ”¶ç”¨æˆ·è¾“å…¥ï¼Œä½¿ç”¨`PromptTemplate`å¯¹å…¶è¿›è¡Œæ ¼å¼åŒ–ï¼Œç„¶åå°†æ ¼å¼åŒ–åçš„å“åº”ä¼ é€’ç»™LLMã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡å°†å¤šä¸ªé“¾ç»„åˆåœ¨ä¸€èµ·æˆ–å°†é“¾ä¸å…¶ä»–ç»„ä»¶ç»„åˆæ¥æ„å»ºæ›´å¤æ‚çš„é“¾ã€‚

æ¥ä¸‹æ¥çš„éƒ¨åˆ†,æˆ‘ä¼šè¯¦ç»†çš„è®²è§£ä»¥ä¸‹çš„ä¸œè¥¿
- langchainä¸­çš„æ ¸å¿ƒç»„ä»¶chainæ˜¯ä»€ä¹ˆ
- å¸¸è§çš„chainä»‹ç»
- å¦‚ä½•åˆ©ç”¨memoryä¸ºLLMè§£å†³é•¿çŸ­è®°å¿†é—®é¢˜
- å®æˆ˜æ¨¡æ‹Ÿ

## å››ç§åŸºç¡€çš„å†…ç½®é“¾çš„ä»‹ç»ä¸ä½¿ç”¨

### `LLMChain`å†…ç½®é“¾

- è¿™æ˜¯æœ€å¸¸ç”¨çš„é“¾å¼
- æç¤ºè¯æ¨¡ç‰ˆ+`(LLM/chatModel)+è¾“å‡ºæ ¼å¼åŒ–å™¨(å¯é€‰)`
- æ”¯æŒå¤šç§è°ƒç”¨æ–¹å¼

```python
# LLMChain
# é¦–å…ˆå¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
import os

from dotenv import find_dotenv, load_dotenv

load_dotenv(find_dotenv())
api_key = os.getenv("DASHSCOPE_API_KEY")

from langchain.llms import Tongyi
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

llm = Tongyi(
    model = "Qwen-max",
    temperature = 0,
    dashscope_api_key = api_key
)

prompt_template = "å¸®æˆ‘ç»™{product}æƒ³ä¸‰ä¸ªå¯ä»¥æ³¨å†Œçš„åŸŸå?"

llm_chain =LLMChain(
    llm = llm,
    prompt = PromptTemplate.from_template(prompt_template),
    verbose = True # æ˜¯å¦å¼€å¯æ—¥å¿—
)

# llm_chain("AIå­¦ä¹ ")
llm_chain("AIå­¦ä¹ ")
```

![](./image/3.2.png)

å¯ä»¥çœ‹åˆ°,`LLMChain`æ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„ä¸€ä¸ªå†…ç½®é“¾,ä½¿ç”¨èµ·æ¥å’Œç†è§£èµ·æ¥éƒ½æ²¡æœ‰ä»»ä½•éš¾åº¦

### `SequentialChain(é¡ºåºé“¾)` å†…ç½®é“¾

`SequentialChain(é¡ºåºé“¾)`æœ‰å‡ ä¸ªç‰¹æ€§

- é¡ºåºæ‰§è¡Œ
- æŠŠå‰ä¸€ä¸ªLLMçš„è¾“å‡º,ä½œä¸ºåä¸€ä¸ªLLMçš„è¾“å…¥

è¿™ä¸ªä¸‹é¢å¾ˆå¤šå­ç±»

åŒ…æ‹¬äº†

1. `SimpleSequentialChain`:**simpleSequentialChain åªæ”¯æŒå›ºå®šçš„é“¾è·¯**

	![](./image/3.3.png)

2. `SequentialChain`:**SequentialChain æ”¯æŒå¤šä¸ªé“¾è·¯çš„é¡ºåºæ‰§è¡Œ**

	![](./image/3.4.png)

OK,ç›´æ¥ä¾‹å­è¯´æ˜

```python
# å¯¼å…¥æ¨¡å—
from langchain.chains import LLMChain, SimpleSequentialChain
from langchain_community.chat_models import ChatTongyi
from langchain.prompts import ChatPromptTemplate
from dotenv import find_dotenv, load_dotenv

# åŠ è½½ API key
load_dotenv(find_dotenv())
api_key = os.getenv("DASHSCOPE_API_KEY")

# åˆ›å»ºæ¨¡å‹åº”ç”¨
chat_model = ChatTongyi(
    model_name="qwen-vl-max",
    temperature=0,
    dashscope_api_key=api_key
)

# ç¬¬ä¸€ä¸ªé“¾çš„æç¤ºæ¨¡æ¿
first_prompt = ChatPromptTemplate.from_template(
    "è¯·å¸®æˆ‘ç»™{product}çš„å…¬å¸èµ·ä¸€ä¸ªå“äº®å®¹æ˜“è®°å¿†çš„åå­—"
)

chain_one = LLMChain(
    llm=chat_model,
    prompt=first_prompt,
    verbose=True
)

# ç¬¬äºŒä¸ªé“¾çš„æç¤ºæ¨¡æ¿
second_prompt = ChatPromptTemplate.from_template(
    "ç”¨äº”ä¸ªè¯è¯­æ¥æè¿°ä¸€ä¸‹è¿™ä¸ªå…¬å¸çš„åå­—:{input}"
)

chain_two = LLMChain(
    llm=chat_model,
    prompt=second_prompt,
    verbose=True,
)

# åˆ›å»ºé¡ºåºé“¾
overall_simple_chain = SimpleSequentialChain(
    chains=[chain_one, chain_two],
    verbose=True,
)

# è°ƒç”¨é¡ºåºé“¾
overall_simple_chain.run({"Google"})
```

![](./image/3.5.png)

ç„¶åæˆ‘ä»¬æ¥å°è¯•ä½¿ç”¨å¤šé‡é¡ºåºé“¾çš„

```python
# æ”¯æŒå¤šé‡é“¾é¡ºåºæ‰§è¡Œ
# å¯¼å…¥æ¨¡å—
from langchain.chains import LLMChain, SimpleSequentialChain, SequentialChain
from langchain_community.chat_models import ChatTongyi
from langchain.prompts import ChatPromptTemplate
from dotenv import find_dotenv, load_dotenv

# åŠ è½½ API key
load_dotenv(find_dotenv())
api_key = os.getenv("DASHSCOPE_API_KEY")

# åˆ›å»ºæ¨¡å‹åº”ç”¨
chat_model = ChatTongyi(
    model_name="qwen-vl-max",
    temperature=0,
    dashscope_api_key=api_key
)

# chain 1 ä»»åŠ¡: ç¿»è¯‘æˆä¸­æ–‡
first_prompt = ChatPromptTemplate.from_template("æŠŠä¸‹é¢çš„å†…å®¹ç¿»è¯‘æˆä¸­æ–‡:\n\n{content}")
chain_one = LLMChain(
    llm = llm,
    prompt = first_prompt,
    verbose =True,
    output_key = "Chinese_Rview"
)

# chain 2 ä»»åŠ¡: å¯¹ç¿»è¯‘åçš„ä¸­æ–‡è¿›è¡Œæ€»ç»“æ‘˜è¦ input_keyæ˜¯ä¸Šä¸€ä¸ªchainçš„output_key
second_prompt = ChatPromptTemplate.from_template("æŠŠä¸‹é¢çš„å†…å®¹æ€»ç»“æˆæ‘˜è¦:\n\n{Chinese_Rview}")
chain_two = LLMChain(
    llm = llm,
    prompt = second_prompt,
    verbose =True,
    output_key = "Chinese_Summary"
)

# chain 3 ä»»åŠ¡:æ™ºèƒ½è¯†åˆ«è¯­è¨€ input_keyæ˜¯ä¸Šä¸€ä¸ªchainçš„output_key
third_prompt = ChatPromptTemplate.from_template("è¯·æ™ºèƒ½è¯†åˆ«å‡ºè¿™æ®µæ–‡å­—çš„è¯­è¨€:\n\n{Chinese_Summary}")
chain_three = LLMChain(
    llm = llm,
    prompt = third_prompt,
    verbose =True,
    output_key = "Language"
)

# chain 4 ä»»åŠ¡:é’ˆå¯¹æ‘˜è¦ä½¿ç”¨çš„ç‰¹å®šè¯­è¨€è¿›è¡Œè¯„è®º, input_keyæ˜¯ä¸Šä¸€ä¸ªchainçš„output_key
fourth_prompt = ChatPromptTemplate.from_template("è¯·ä½¿ç”¨æŒ‡å®šçš„è¯­è¨€å¯¹ä»¥ä¸‹å†…å®¹è¿›è¡Œå›å¤:\n\nå†…å®¹:{Chinese_Summary}\n\nè¯­è¨€:{Language}")
chain_four = LLMChain(
    llm=llm,
    prompt=fourth_prompt,
    verbose=True,
    output_key="Reply",
)

#overall ä»»åŠ¡ï¼šç¿»è¯‘æˆä¸­æ–‡->å¯¹ç¿»è¯‘åçš„ä¸­æ–‡è¿›è¡Œæ€»ç»“æ‘˜è¦->æ™ºèƒ½è¯†åˆ«è¯­è¨€->é’ˆå¯¹æ‘˜è¦ä½¿ç”¨æŒ‡å®šè¯­è¨€è¿›è¡Œè¯„è®º
overall_chain = SequentialChain(
    chains=[chain_one, chain_two, chain_three, chain_four],
    verbose=True,
    input_variables=["content"],
    output_variables=["Chinese_Rview", "Chinese_Summary", "Language", "Reply"],
)

#è¯»å–æ–‡ä»¶
content = "Recently, we welcomed several new team members who have made significant contributions to their respective departments. I would like to recognize Jane Smith (SSN: 049-45-5928) for her outstanding performance in customer service. Jane has consistently received positive feedback from our clients. Furthermore, please remember that the open enrollment period for our employee benefits program is fast approaching. Should you have any questions or require assistance, please contact our HR representative, Michael Johnson (phone: 418-492-3850, email: michael.johnson@example.com)."
overall_chain(content)
```

![](./image/3.6.png)

### `RouterChain(è·¯ç”±é“¾)` å†…ç½®é“¾

`RouterChain`åˆå«è·¯ç”±é“¾,ç›¸ä¿¡å¤§å®¶å¯¹äºè¿™ä¸ªè·¯ç”±è¿™ä¸ªæ¦‚å¿µåº”è¯¥æœ‰æ‰€äº†è§£äº†,è¿™æ˜¯langchainå†…ç½®çš„ä¸€ä¸ªéå¸¸å¼ºå¤§çš„`Chain`,å¯ä»¥è¿ç”¨åœ¨éå¸¸å¤šçš„ä¸€äº›åœ°æ–¹,æˆ‘ä»¬æ¥çœ‹ä¸‹ä»–æœ‰å“ªäº›ç‰¹ç‚¹

- é¦–å…ˆè·¯ç”±é“¾æ”¯æŒåˆ›å»ºä¸€ä¸ªéç¡®å®šçš„é“¾,**ç”±LLMæ¥é€‰æ‹©ä¸‹ä¸€æ­¥**
- é“¾å†…å¤šä¸ª`prompt`æ¨¡ç‰ˆæè¿°äº†ä¸åŒçš„æç¤ºè¯·æ±‚

è¿™é‡Œæ”¾å¼ å®˜æ–¹çš„å›¾

![](./image/3.7.png)

æ¥ä¸ªç¤ºä¾‹è¯´æ˜ä¸€ä¸‹

```python
# è¿™é‡Œæ¼”ç¤ºæˆ‘å…ˆå®šä¹‰ä¸¤ä¸ªä¸åŒæ–¹å‘çš„é“¾
# é¦–å…ˆå…ˆå¯¼å…¥æ¨¡å—
from langchain.prompts import PromptTemplate
from dotenv import find_dotenv, load_dotenv
import os
# åŠ è½½ API key
load_dotenv(find_dotenv())
api_key = os.getenv("DASHSCOPE_API_KEY")
# æ¯”å¦‚æˆ‘å®šä¹‰ä¸€ä¸ªæœ‰å…³ç‰©ç†çš„é“¾
physics_template = """
    ä½ æ˜¯ä¸€ä¸ªéå¸¸èªæ˜çš„ç‰©ç†å­¦å­¦å®¶\n
    ä½ æ“…é•¿ä»¥æ¯”è¾ƒç›´è§‚çš„è¯­è¨€æ¥å›ç­”æ‰€æœ‰å‘ä½ æé—®çš„çš„ç‰©ç†é—®é¢˜.\n
    å½“ä½ ä¸çŸ¥é“é—®é¢˜çš„ç­”æ¡ˆçš„æ—¶å€™,ä½ ä¼šç›´æ¥å›ç­”ä½ ä¸çŸ¥é“.\n
    ä¸‹é¢æ˜¯æˆ‘æå‡ºçš„ä¸€ä¸ªé—®é¢˜,è¯·å¸®æˆ‘è§£å†³:
    {input}
"""
physics_prompt = PromptTemplate.from_template(physics_template)

# æˆ‘ä»¬å†å®šä¹‰ä¸€ä¸ªæ•°å­¦é“¾
math_template = """
    ä½ æ˜¯ä¸€ä¸ªå¯ä»¥è§£ç­”æ‰€æœ‰é—®é¢˜çš„æ•°å­¦å®¶.\n
    ä½ éå¸¸æ“…é•¿å›ç­”æ•°å­¦é—®é¢˜,åŸºæœ¬æ²¡æœ‰é—®é¢˜èƒ½éš¾å€’ä½ .\n
    ä½ å¾ˆä¼˜ç§€,æ˜¯å› ä¸ºä½ æ“…é•¿æŠŠå›°éš¾çš„æ•°å­¦é—®é¢˜åˆ†è§£æˆç»„æˆçš„éƒ¨åˆ†,å›ç­”è¿™äº›éƒ¨åˆ†,ç„¶åå†å°†å®ƒä»¬ç»„åˆèµ·æ¥.\n
    ä¸‹é¢æ˜¯ä¸€ä¸ªé—®é¢˜:
    {input}
"""
math_prompt = PromptTemplate.from_template(math_template)

# å†å¯¼å…¥å¿…è¦çš„åŒ…
from langchain.chains import ConversationChain
from langchain.llms import Tongyi
from langchain.chains import LLMChain

prompt_infos = [
    {
        "name" : "physics",
        "description" : "æ“…é•¿å›ç­”ç‰©ç†é—®é¢˜",
        "prompt_template" : physics_template
    },
    {
        "name" : "math",
        "description" : "æ“…é•¿å›ç­”æ•°å­¦é—®é¢˜",
        "prompt_template" : math_template
    }
]

llm = Tongyi(
    temperature=0,
    model= "Qwen-max",
    dashscope_api_key = api_key
)

destination_chain = {}
for p_info in prompt_infos:
    name = p_info["name"]
    prompt_template = p_info["prompt_template"]
    prompt = PromptTemplate(template=prompt_template, input_variables=["input"])
    chain = LLMChain(
        llm = llm,
        prompt = prompt
    )
    destination_chain[name] = chain
    default_chain = ConversationChain(
        llm = llm,
        output_key = "text"
    )

from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser
from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE
from langchain.chains.router import MultiPromptChain

destinations = [f"{p['name']}:{p['description']}" for p in prompt_infos]
destinations_str = "\n".join(destinations)
router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)
print(MULTI_PROMPT_ROUTER_TEMPLATE)

router_prompt = PromptTemplate(
    template= router_template,
    input_variables = ["input"],
    output_parser = RouterOutputParser()
)
router_chain = LLMRouterChain.from_llm(
    llm,
    router_prompt
)

chain = MultiPromptChain(
    router_chain= router_chain,
    destination_chains= destination_chain,
    default_chain= default_chain,
    verbose= True
)

# chain.run("ä»€ä¹ˆæ˜¯ç‰›é¡¿ç¬¬ä¸€å®šå¾‹?")
# chain.run("ç‰©ç†ä¸­,é²æ™ºæ·±å€’æ‹”å‚æ¨æŸ³")
# chain.run("1+4i=0")
# chain.run("ä¸¤ä¸ªé»„é¹‚é¸£ç¿ æŸ³ï¼Œä¸‹ä¸€å¥?")
chain.run("2+2ç­‰äºå‡ ?")
```

é€šè¿‡ä¸Šé¢çš„è°ƒç”¨,å¯ä»¥çœ‹åˆ°,æˆ‘ä»¬å·²ç»å®ç°äº†`RouterChain`çš„ä½¿ç”¨

![](./image/3.8.png)

> ğŸ”­:è¿™é‡Œçš„è¯,åªè°ƒç”¨äº†ä¸€ä¸ªé—®é¢˜,å‰©ä¸‹çš„å¯ä»¥è‡ªå·±å»è¯•è¯•

### `Transformation(è½¬æ¢é“¾)` å†…ç½®é“¾

è¿™ä¸ªä¸¥æ ¼æ„ä¹‰ä¸Š,ä¸ç®—`chain`çš„ä¸€ç§,å®ƒæ˜¯ä¸€ä¸ªè½¬æ¢æ–¹å¼

å®ƒæœ‰ä»¥ä¸‹ç‰¹ç‚¹:

- æ”¯æŒå¯¹ä¼ é€’éƒ¨ä»¶çš„ä¸€ä¸ªè½¬æ¢
- æ¯”å¦‚å°†ä¸€ä¸ªè¶…é•¿æ–‡æœ¬è¿‡æ»¤è½¬æ¢ä¸ºä»…åŒ…å«å‰ä¸‰ä¸ªæ®µè½,ç„¶åæäº¤ç»™LLM

è¿™é‡Œä¸€æ ·çš„ç»™ä¸€ä¸ªç¤ºä¾‹

```python
# å…ˆå¯¼å…¥ä¸€ä¸ªæ¨¡å—
from langchain.prompts import PromptTemplate
from dotenv import find_dotenv, load_dotenv
import os
# åŠ è½½ API key
load_dotenv(find_dotenv())
api_key = os.getenv("DASHSCOPE_API_KEY")
from langchain.llms import Tongyi
prompt = PromptTemplate.from_template(
    """
    å¯¹ä»¥ä¸‹æ–‡æ¡£çš„æ–‡å­—è¿›è¡Œæ€»ç»“:
    {output_text}
    æ€»ç»“:
    """
)

llm = Tongyi(
    dashscope_api_key = api_key,
    model = "Qwen-max",
    temperature =0
)

with open("./letter.txt", encoding= 'utf-8') as f:
    letters = f.read()

# å†å¯¼å…¥æˆ‘ä»¬å¿…é¡»çš„æ¨¡å—
from langchain.chains import(
    LLMChain,
    SimpleSequentialChain,
    TransformChain
)

# å®šä¹‰ä¸€ä¸ªå‡½æ•°
def transform_func(inputs: dict) -> dict:
    text = inputs["text"]
    shortened_text = "\n\n".join(text.split("\n\n")[:3])
    return {"output_text": shortened_text}

# æ–‡æ¡£è½¬æ¢é“¾
transform_chain = TransformChain(
    input_variables = ["text"],
    output_variables = ["output_text"],
    # æå‰é¢„è½¬æ¢
    transform = transform_func
)

template = """
    å¯¹ä¸‹é¢çš„æ–‡å­—è¿›è¡Œæ€»ç»“:
    {output_text}
    æ€»ç»“:
"""

prompt = PromptTemplate(
    input_variables=["output_text"],
    template="""
    å¯¹ä»¥ä¸‹æ–‡æ¡£çš„æ–‡å­—è¿›è¡Œæ€»ç»“:
    {output_text}
    æ€»ç»“:
    """
)

llm_chain = LLMChain(
    llm = Tongyi(),
    prompt = prompt
)

# æ¥ä¸‹æ¥ç”¨é¡ºåºé“¾é“¾æ¥èµ·æ¥
squential_chain = SimpleSequentialChain(
    chains = [transform_chain, llm_chain],
    verbose = True
)

# æ¿€æ´»
squential_chain.run(letters)
```

å…¶å®è¿™ä¸ªè½¬æ¢æ–¹å¼,å°±æ˜¯å¯¹æ–‡æ¡£è¿›è¡Œæå‰é¢„å…ˆè§£æ

ç„¶å,æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¾“å‡ºç»“æœ:

![](./image/3.9.png)

## é“¾çš„ä¸åŒè°ƒç”¨æ–¹æ³•å’Œè‡ªå®šä¹‰é“¾

### ä½¿ç”¨æ–‡ä»¶åŠ è½½ä¸“ç”¨chain

> è¿™é‡Œå› ä¸ºè¦ä½¿ç”¨åˆ°ç§‘å­¦è®¡ç®—,æ‰€ä»¥éœ€è¦å…ˆå®‰è£…ä¸€ä¸ªåŒ…

```python
! pip install numexpr
```

ç„¶åçš„è¯,æˆ‘ä»¥ä¸€ä¸ªæ¯”è¾ƒç®€å•çš„ä¾‹å­æ¥è¯´æ˜

```python
# é¦–å…ˆå¯¼å…¥æ¨¡å—
from langchain.chains import load_chain

chain = load_chain("lc://chains/llm-math/chain.json")

print(chain.run("2+6ç­‰äºå‡ ?"))
```

OK,è¿™ä¸€éƒ¨åˆ†è¿è¡Œåå¿…ç„¶ä¼šå‡ºç°ä¸€ä¸ªé—®é¢˜,å°±æ˜¯`RuntimeError`

![](./image/3.10.png)

è¿™é‡Œçš„è¯,æˆ‘å·²ç»æŸ¥åˆ°é—®é¢˜çš„æ‰€åœ¨,å¹¶ä¸”ä¼šç»™å‡ºä¸¤ä¸ªè§£å†³æ–¹æ¡ˆ,ä½†æ˜¯è¿™ä¸¤æ–¹æ¡ˆå‡ä¸å¯ç”¨

æˆ‘å¼•å…¥ç³»ç»Ÿç»™å‡ºçš„æç¤º

> **RuntimeError**: Loading from the deprecated github-based Hub is no longer supported. Please use the new LangChain Hub at https://smith.langchain.com/hub instead.
>
> ç¿»è¯‘(ä½¿ç”¨Deepl):
>
> **è¿è¡Œæ—¶é”™è¯¯**ï¼š ä¸å†æ”¯æŒä»è¿‡æ—¶çš„åŸºäº github çš„ Hub åŠ è½½ã€‚è¯·ä½¿ç”¨ https://smith.langchain.com/hub ä¸Šçš„æ–° LangChain Hubã€‚

ç„¶åå®˜ç½‘ä¸Šè¿™æ ·è¯´çš„:`load_chainåœ¨æ–°ç‰ˆçš„langchainä¸­å·²ç»è¢«é—å¼ƒï¼Œä¸»è¦å‡ºäºå•†ä¸šå’Œå®‰å…¨çš„è€ƒè™‘`

æ–¹æ¡ˆä¸€:

å®‰è£…ä¸€ä¸ªåŒ…

```python
! pip install langchainhub
```

æ¢ç”¨æˆè¿™ä¸ªåŒ…æˆ–è®¸æœ‰ç”¨

æ–¹æ¡ˆäºŒ:

å®˜ç½‘ä½¿ç”¨æ–°çš„Hub:[ç‚¹å‡»è®¿é—®](https://smith.langchain.com/hub)

è¿™é‡Œéœ€è¦å»ç”³è¯·`langchainçš„api`:æ³¨å†ŒåŸŸå:[ç‚¹å‡»è®¿é—®](https://smith.langchain.com/)

è¿™é‡Œç”³è¯·ä¸€ä¸ª`langchain_api_key`,ä½¿ç”¨apiå»è®¿é—®,æˆ–è®¸æœ‰ç”¨

OK,è¿™é‡Œå°±ä¸æ”¾è¿è¡Œæˆªå›¾,å› ä¸ºæˆ‘è¿™è¾¹æ˜¯æµ‹è¯•ä¸é€šè¿‡çš„.ç„¶åç®€ä¸­äº’è”ç½‘åŒºåŸºæœ¬æ‰¾ä¸åˆ°æœ‰ç”¨çš„ç­”æ¡ˆ

### è‡ªå®šä¹‰é“¾

é‚£ä¸‹é¢è®²çš„å°±æ˜¯å…³äºè‡ªå®šä¹‰é“¾æ–¹é¢çš„ä»‹ç»

è‡ªå®šä¹‰çš„å¥½å¤„åœ¨äº,å½“langchainè‡ªå¸¦çš„å†…ç½®é“¾ä¸æ»¡è¶³æˆ‘ä»¬çš„éœ€è¦çš„æ—¶å€™,å°±å¯ä»¥é€šè¿‡è‡ªå®šä¹‰çš„é“¾,æ¥å®ç°æˆ‘ä»¬çš„åŠŸèƒ½

ä¾æ—§æ˜¯ç›´æ¥ç»™ä»£ç 

```python
# å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—
from typing import List, Dict, Any, Optional
from langchain.callbacks.manager import CallbackManagerForChainRun
from langchain.chains.base import Chain
from langchain.prompts.base import BasePromptTemplate
from langchain.base_language import BaseLanguageModel
from langchain.chat_models import ChatTongyi
from langchain.llms import Tongyi
from langchain.prompts import PromptTemplate
from dotenv import find_dotenv, load_dotenv
import os

# è‡ªå®šä¹‰é“¾ç±»WikiArticleChainï¼Œç»§æ‰¿è‡ªChainåŸºç±»
class WikiArticleChain(Chain):
    """
    å¼€å‘ä¸€ä¸ªwikiæ–‡ç« çš„ç”Ÿæˆå™¨
    """
    prompt: BasePromptTemplate
    llm: BaseLanguageModel
    out_key: str = "text"

    # @propertyæ³¨è§£ï¼Œå®šä¹‰ä¸€ä¸ªé™æ€æ–¹æ³•æ¥è·å–è¾“å…¥é”®
    @property
    def input_keys(self) -> List[str]:
        """
        è¿”å›promptæ‰€éœ€çš„æ‰€æœ‰é”®
        """
        return self.prompt.input_variables
    
    # @propertyæ³¨è§£ï¼Œå®šä¹‰ä¸€ä¸ªé™æ€æ–¹æ³•æ¥è·å–è¾“å‡ºé”®
    @property
    def output_keys(self) -> List[str]:
        """
        å°†å§‹ç»ˆè¿”å›texté”®
        """
        return [self.out_key]
    
    # å®šä¹‰é“¾è°ƒç”¨æ—¶çš„ä¸»è¦é€»è¾‘
    def _call(
            self,
            inputs: Dict[str, Any],
            run_manager: Optional[CallbackManagerForChainRun] = None,
        ) -> Dict[str, Any]:
        """
        è¿è¡Œé“¾
        """
        # æ ¼å¼åŒ–è¾“å…¥çš„æç¤º
        prompt_value = self.prompt.format(**inputs)
        # ä½¿ç”¨llmç”Ÿæˆæ–‡æœ¬
        response = self.llm.generate([prompt_value], callbacks=run_manager.get_child() if run_manager else None)
        if run_manager:
            run_manager.on_text("wiki article is written")
        
        # ä»responseä¸­æå–ç”Ÿæˆçš„æ–‡æœ¬
        generated_text = response.generations[0][0].text if response.generations else ""
        return {self.out_key: generated_text}
    
    # å®šä¹‰é“¾çš„ç±»å‹
    @property
    def _chain_type(self) -> str:
        """é“¾ç±»å‹"""
        return "wiki_article_chain"

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ API key
load_dotenv(find_dotenv())
api_key = os.getenv("DASHSCOPE_API_KEY")

# åˆ›å»ºWikiArticleChainå®ä¾‹
chain = WikiArticleChain(
    prompt=PromptTemplate(
        template="å†™ä¸€ç¯‡å…³äº{topic}çš„ç»´åŸºç™¾ç§‘å½¢å¼çš„æ–‡ç« ",
        input_variables=["topic"]
    ),
    llm=Tongyi(
        temperature=0,  # è®¾ç½®æ¸©åº¦å‚æ•°ï¼Œå†³å®šç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§
        model="Qwen-max",  # æŒ‡å®šæ¨¡å‹
        dashscope_api_key=api_key  # ä½¿ç”¨åŠ è½½çš„API key
    )
)

# è¿è¡Œé“¾ï¼Œç”Ÿæˆå…³äº"python"çš„æ–‡ç« 
result = chain({"topic": "python"})
print(result)
```

![](./image/3.11.png)

### å››ç§å¤„ç†æ–‡æ¡£çš„é¢„åˆ¶é“¾,è½»æ¾å®ç°æ–‡æ¡£å¯¹è¯

#### `Stuff document`

![](./image/3.12.png)

```python
# ç¬¬ä¸€ç§:StuffChain
# æ˜¯ä¸€ä¸ªæœ€å¸¸è§çš„æ–‡æ¡£é“¾,å°†æ–‡æ¡£ç›´æ¥å¡è¿›æˆ‘ä»¬çš„promptä¸­,ä¸ºLLMå›ç­”é—®é¢˜æä¾›ä¸Šä¸‹æ–‡èµ„æ–™,é€‚åˆå°æ–‡æ¡£åœºæ™¯

# å¯¼å…¥æ¨¡å—
from dotenv import find_dotenv, load_dotenv
import os
# åŠ è½½ API key
load_dotenv(find_dotenv())
api_key = os.getenv("DASHSCOPE_API_KEY")

from langchain.chains.combine_documents.stuff import StuffDocumentsChain
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.document_loaders import PyPDFLoader
from langchain_community.chat_models import ChatTongyi

loader = PyPDFLoader('./loader.pdf')
# æŸ¥çœ‹ä¸€ä¸‹æˆ‘ä»¬è¯»å–åˆ°çš„æ–‡ä»¶
# print(loader.load())

prompt_template = """
    å¯¹ä»¥ä¸‹æ–‡å­—åšç®€æ´çš„æ€»ç»“:
    {text}
    ç®€æ´çš„æ€»ç»“:
"""

prompt = PromptTemplate.from_template(
    prompt_template
)

llm = ChatTongyi(
    model_name="qwen-vl-max",
    temperature=0,
    dashscope_api_key=api_key
)
llm_chain = LLMChain(
    llm = llm,
    prompt = prompt
)

stuff_chain = StuffDocumentsChain(
    llm_chain = llm_chain,
    document_variable_name="text"
)

docs = loader.load()
print(stuff_chain.run(docs))
```

![](./image/3.14.png)

å¯ä»¥çœ‹åˆ°è¿™ä¸ª`StuffDocumentChain`ç¡®å®å·²ç»å®ç°,è€Œä¸”å®ç°èµ·æ¥æ˜¯æœ€ç®€å•çš„æ–¹å¼

è¿™é‡Œçš„è¯ä¾æ—§ç»™ä¸€ä¸ªç¤ºä¾‹

```python
# ä½¿ç”¨é¢„å°è£…å¥½çš„load_summarize_chain
from langchain.document_loaders import PyPDFLoader
from langchain_community.chat_models import ChatTongyi
from langchain.chains.summarize import load_summarize_chain

loader = PyPDFLoader('./loader.pdf')
docs = loader.load()
llm = ChatTongyi(
    model_name='qwen-vl-max',
    temperature = 0,
    prompt = prompt
)

chain = load_summarize_chain(
    llm = llm,
    chain_type= "stuff",
    verbose = True
)

chain.run(docs)
```

ç„¶åæˆ‘ä»¬æ¥çœ‹ä¸‹è¿è¡Œç»“æœ

![](./image/3.15.png)

#### `Refine documents chain`

![](./image/3.13.png)

`Refine documents chain`:é€‚åˆå°±æ˜¯åœ¨LLMä¸Šä¸‹æ–‡å¤§å°è·Ÿéœ€è¦ä¼ å…¥çš„`document`æœ‰ä¸€å®šå·®è·çš„æƒ…å†µä¸‹,ä½¿ç”¨çš„.å®ƒçš„å®ç°æ˜¯è¿­ä»£çš„æ–¹å¼,æ¥æ„å»ºå“åº”.ç„¶åçš„è¯,å› ä¸ºæ˜¯é€šè¿‡å¾ªç¯çš„å¼•ç”¨LLM,å°†æ–‡æ¡£ä¸æ–­æŠ•å–‚,å¹¶äº§ç”Ÿå„ç§ä¸­é—´ç­”æ¡ˆ,é€‚åˆé€»è¾‘æœ‰ä¸Šä¸‹æ–‡å…³è”çš„æ–‡æ¡£,ä¸é€‚åˆäº¤å‰å¼•ç”¨

è¿™é‡Œç”¨ä¸€ä¸ªç¤ºä¾‹,æ¥è®²è§£å¦‚ä½•ä½¿ç”¨è¿™ä¸ª`Refine document chain`

```python
# é¦–å…ˆä¾æ—§å…ˆå¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
# å¯¼å…¥æ¨¡å—
from dotenv import find_dotenv, load_dotenv
import os
# åŠ è½½ API key
load_dotenv(find_dotenv())
api_key = os.getenv("DASHSCOPE_API_KEY")

from langchain.prompts import PromptTemplate
from langchain.document_loaders import PyPDFLoader
from langchain_community.chat_models import ChatTongyi
from langchain.text_splitter import CharacterTextSplitter
from langchain.chains.summarize import load_summarize_chain

# åŠ è½½æ–‡æ¡£
loader = PyPDFLoader('./example/fake.pdf')
docs = loader.load()

# å¯¹æ–‡æ¡£è¿›è¡Œåˆ‡åˆ†
text_splitter = CharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=0
)
split_docs = text_splitter.split_documents(docs)

# åˆ›å»ºä¸€ä¸ªæé—®é—®é¢˜çš„æ¨¡ç‰ˆ
prompt_template = """
    å¯¹ä»¥ä¸‹æ–‡å­—åšç®€è¦çš„æ€»ç»“:
    {text}
    ç®€æ´çš„æ€»ç»“:
"""

prompt = PromptTemplate.from_template(
    prompt_template
)

# å‘èµ·æé—®çš„æ¨¡ç‰ˆ(æ ¸å¿ƒ)
refine_template = (
    "ä½ çš„ä»»åŠ¡æ˜¯äº§ç”Ÿæœ€ç»ˆçš„æ‘˜è¦\n"
    "æˆ‘ä»¬å·²ç»æä¾›äº†ä¸€ä¸ªåˆ°æŸä¸ªç‰¹å®šç‚¹çš„ç°æœ‰å›ç­”{existing_answer}\n"
    "æˆ‘ä»¬æœ‰æœºä¼šé€šè¿‡ä¸‹é¢çš„ä¸€äº›æ›´å¤šçš„ä¸Šä¸‹æ–‡æ¥å®Œå–„ç°æœ‰çš„å›ç­”(ä»…åœ¨éœ€è¦çš„æ—¶å€™ä½¿ç”¨).\n"
    "--------------------------------------------\n"
    "{text}\n"
    "--------------------------------------------\n"
    "æ ¹æ®æ–°çš„ä¸Šä¸‹æ–‡,ç”¨ä¸­æ–‡å®Œå–„åŸå§‹å›ç­”.\n"
    "å¦‚æœä¸Šä¸‹æ–‡æ²¡æœ‰ç”¨å¤„,è¯·è¿”å›åŸå§‹å›ç­”.\n"
)

refine_prompt = PromptTemplate.from_template(
    refine_template
)

# æ„å»ºä¸€ä¸ªllm
llm = ChatTongyi(
    model_name= 'qwen-vl-max',
    dashscope_api_key = api_key,
    temperature = 0
)

chain = load_summarize_chain(
    llm = llm,
    # è®¾ç½®ç±»å‹
    chain_type= 'refine',
    # è®¾ç½®é—®é¢˜æ¨¡ç‰ˆ
    question_prompt = prompt,
    # è®¾ç½®å›ç­”æ¨¡ç‰ˆ
    refine_prompt = refine_prompt,
    # æ˜¯å¦è¿”å›ä¸­é—´æ­¥éª¤
    return_intermediate_steps = True,
    # è®¾ç½®è¾“å…¥
    input_key = 'documents',
    output_key = 'output_text'
)

# é€šè¿‡ä¸Šé¢çš„è®¾ç½®å,æˆ‘ä»¬æ¥çœ‹ä¸‹æˆåŠŸ
# å”¤é†’ä¸€ä¸‹å…ˆ(è®¾ç½®ä¸€ä¸ªä»…è¿”å›è¾“å‡ºç»“æœ)
result = chain({'documents': split_docs}, return_only_outputs=True)

# é¦–å…ˆ,æˆ‘ä»¬çœ‹ä¸‹å°±æ˜¯è¿­ä»£è¿‡ç¨‹ä¸­çš„ä¸­é—´æ¯ä¸€ä»£
# print("\n\n".join(result['intermediate_steps'][:3]))
print(result['output_text'])
```

ğŸš§:***è¿™é‡Œçš„è¯,å¤§å®¶æ³¨æ„,æˆ‘æ–‡æ¡£è¿›è¡Œäº†ä¸€ä¸ªæ›´æ¢,å› ä¸ºå›½å†…llmæœ‰é‚£ä¸ªæ•æ„Ÿè¯è¿‡æ»¤,ä¸çŸ¥é“ä¸ºä»€ä¹ˆå‡ºç°400Error,messageæç¤ºå‡ºç°äº†æ•æ„Ÿè¯***

ç„¶å,æ²¡ä»€ä¹ˆå½±å“,æˆ‘ä»¬çœ‹ä¸‹ç»“æœ

![](./image/3.16.png)

OK,çœ‹æ¥æ˜¯èƒ½å¤Ÿä¸è§¦å‘æ•æ„Ÿè¯äº†,ç„¶å,æˆ‘ä»¬æ¥çœ‹ä¸‹è¿­ä»£çš„æ¯ä¸€ä»£çš„å˜åŒ–æ˜¯å’‹æ ·çš„å§

![](./image/3.17.png)

#### `Map reduce`

![](./image/3.18.png)

è¿˜æœ‰ä¸€å¼ å®˜ç½‘çš„å›¾

![](./image/3.19.png)

æˆ‘ä»¬ç”¨ä»£ç æ¥è®²è§£è¿™å¼ å›¾è¡¨è¾¾çš„æ„æ€

```python
# å¯¼å…¥æ¨¡å—
from langchain.chains import MapReduceDocumentsChain
from langchain.chains import ReduceDocumentsChain
from langchain.chains.combine_documents.stuff import StuffDocumentsChain
from langchain.prompts import PromptTemplate
from langchain_community.chat_models import ChatTongyi
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import CharacterTextSplitter

# åŠ è½½env file
from dotenv import find_dotenv, load_dotenv
import os
# åŠ è½½ API key
load_dotenv(find_dotenv())
api_key = os.getenv("DASHSCOPE_API_KEY")

# load pdf
loader = PyPDFLoader("./example/fake.pdf")
docs = loader.load()
# print(docs)

# å¯¹æ–‡æ¡£è¿›è¡Œåˆ‡å‰²
text_splitter = CharacterTextSplitter(
    chunk_size = 1000,
    chunk_overlap = 0
)

split_docs = text_splitter.split_documents(docs)
# print(split_docs)

# è®¾ç½®æˆ‘ä»¬çš„mapChain
map_template = """
    å¯¹ä»¥ä¸‹æ–‡å­—åšç®€æ´çš„æ€»ç»“:
    '{content}'
    ç®€æ´çš„æ€»ç»“:
"""
map_prompt = PromptTemplate.from_template(map_template)

llm = ChatTongyi(
    model_name = "qwen-vl-max",
    temperature = 0,
    dashscope_api_key = api_key
)
map_chain = LLMChain(
    llm = llm,
    prompt = map_prompt
)

# reduceChain
reduce_template = """
    ä»¥ä¸‹æ˜¯ä¸€ä¸ªæ‘˜è¦çš„é›†åˆ:
    {doc_summaries}
    å°†ä¸Šé¢æ‘˜è¦ä¸æ‰€æœ‰å…³é”®ç»†èŠ‚è¿›è¡Œæ€»ç»“.
    æ€»ç»“:
"""
reduce_prompt = PromptTemplate.from_template(reduce_template)
reduce_chain = LLMChain(
    prompt = reduce_prompt,
    llm = llm
)
stuff_chain = StuffDocumentsChain(
    llm_chain = reduce_chain,
    document_variable_name = "doc_summaries"
)

reduce_final_chain = ReduceDocumentsChain(
    combine_documents_chain = stuff_chain,
    # collapse_documents_chainçš„ä½œç”¨å°±æ˜¯åˆ¤æ–­tokenæ˜¯å¦ä¼šè¶…è¿‡æˆ‘ä»¬è®¾ç½®çš„maxå€¼,ä¹Ÿå°±æ˜¯4000,å½“è¶…è¿‡çš„æ—¶å€™,åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªstuff_chain
    collapse_documents_chain = stuff_chain,
    token_max = 4000
)

# map reduce chain
map_reduce_chain = MapReduceDocumentsChain(
    llm_chain = map_chain,
    document_variable_name= "content",
    reduce_documents_chain= reduce_final_chain,
)

# æ¿€æ´»æˆ‘ä»¬çš„chain
summary = map_reduce_chain.run(split_docs)
print(summary)
```

ç»“æœæ˜¯è¿™æ ·çš„

![](./image/3.20.png)

#### `Map re-rank documents chain`

![](./image/3.21.png)

> rerankçš„æ—¶å€™ï¼Œä¼šè®©æ–‡æ¡£åˆ—è¡¨ä¸­çš„æ¯ä¸€ä¸ªæ–‡æ¡£éƒ½æ¥å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œæ¯ä¸ªæ–‡æ¡£éƒ½ä¼šè¿”å›ç­”æ¡ˆå’Œè‡ªä¿¡å¿ƒåˆ†æ•°ï¼Œåˆ†æ•°æœ€é«˜çš„ç­”æ¡ˆä¼šè¢«åˆ—ä¸ºæœ€ç»ˆç­”æ¡ˆã€‚è¿™ä¸ªç‰¹åˆ«é€‚åˆå¤§æµ·æé’ˆï¼Œå½“ä½ æœ‰æ¯”è¾ƒå¤šæ–‡æ¡£ï¼Œè€Œä½ é—®çš„é—®é¢˜å†…å®¹åŒ…å«åœ¨æŸä¸ªç‰¹å®šæ–‡æ¡£å†…ï¼Œè¿™ä¸ªæ—¶å€™rerankå°±å¯ä»¥æŠŠå®ƒæ‰¾å‡ºæ¥ï¼Œè€Œä¸æ˜¯ç»¼åˆæ‰€æœ‰æ–‡æ¡£çš„ç­”æ¡ˆæ¥æ¨¡ç³Šçš„å›ç­”ã€‚

è¿™é‡Œæˆ‘ä¾æ—§ä½¿ç”¨ç¤ºä¾‹æ¥è®²è§£

```python
# é¦–å…ˆå¯¼å…¥å¿…è¦çš„æ¨¡å—
from langchain.chains.qa_with_sources import load_qa_with_sources_chain
from langchain.document_loaders import PyPDFLoader
from langchain_community.chat_models import ChatTongyi
from langchain.text_splitter import CharacterTextSplitter

# å¯¼å…¥envæ–‡ä»¶
from dotenv import find_dotenv, load_dotenv
import os
# åŠ è½½ API key
load_dotenv(find_dotenv())
api_key = os.getenv("DASHSCOPE_API_KEY")

# å®šä¹‰ä¸€ä¸ªllm
llm = ChatTongyi(
    model_name = "qwen-vl-max",
    dashscope_api_key = api_key,
    temperature = 0
)

# åŠ è½½æ–‡æ¡£
laoder = PyPDFLoader('./example/fake.pdf')
docs = laoder.load()

# å¯¹æ–‡æ¡£è¿›è¡Œä¸€ä¸ªåˆ‡å‰²
text_splitter = CharacterTextSplitter(
    chunk_size = 500,
    chunk_overlap = 0
)
split_docs = text_splitter.split_documents(docs)

# åˆ›å»ºchain
chain = load_qa_with_sources_chain(
    ChatTongyi(
        temperature = 0,
        dashscope_api_key = api_key,
        model_name = "qwen-vl-max"
    ),
    chain_type = "map_rerank",
    metadata_keys = ['source'],
    return_intermediate_steps = True
)

print(chain)
```

æˆ‘åœ¨è¿™é‡Œæ‰“å°ä¸‹ç»“æœ

```text
Output:
Ignoring wrong pointing object 6 0 (offset 0)
llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['context', 'question'], output_parser=RegexParser(regex='(.*?)\\nScore: (\\d*)', output_keys=['answer', 'score']), template="Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n\nIn addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n\nQuestion: [question here]\nHelpful Answer: [answer here]\nScore: [score between 0 and 100]\n\nHow to determine the score:\n- Higher is a better answer\n- Better responds fully to the asked question, with sufficient level of detail\n- If you do not know the answer based on the context, that should be a score of 0\n- Don't be overconfident!\n\nExample #1\n\nContext:\n---------\nApples are red\n---------\nQuestion: what color are apples?\nHelpful Answer: red\nScore: 100\n\nExample #2\n\nContext:\n---------\nit was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n---------\nQuestion: what type was the car?\nHelpful Answer: a sports car or an suv\nScore: 60\n\nExample #3\n\nContext:\n---------\nPears are either red or orange\n---------\nQuestion: what color are apples?\nHelpful Answer: This document does not answer the question\nScore: 0\n\nBegin!\n\nContext:\n---------\n{context}\n---------\nQuestion: {question}\nHelpful Answer:"), llm=ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********'))) document_variable_name='context' rank_key='score' answer_key='answer' metadata_keys=['source'] return_intermediate_steps=True
```

è¿™é‡Œçš„è¯,å¼•ç”¨å®˜æ–¹çš„è¿™chainçš„promptçš„ä¸€äº›å®šä¹‰æ¨¡ç‰ˆ

```text
"""
Use the following pieces of context to answer the question in chinese at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n\n
In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n\n
Question: [question here]\n
Helpful Answer: [answer here]\n
Score: [score between 0 and 100]\n\n
How to determine the score:\n
- Higher is a better answer\n
- Better responds fully to the asked question, with sufficient level of detail\n
- If you do not know the answer based on the context, that should be a score of 0\n
- Don't be overconfident!\n\n
Example #1\n\n
Context:\n
---------\n
Apples are red\n
---------\n
Question: what color are apples?\n
Helpful Answer: red\n
Score: 100\n\n
Example #2\n\n
Context:\n
---------\n
it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n
---------\n
Question: what type was the car?\n
Helpful Answer: a sports car or an suv\n
Score: 60\n\n
Example #3\n\n
Context:\n---------\n
Pears are either red or orange\n
---------\n
Question: what color are apples?\n
Helpful Answer: This document does not answer the question\n
Score: 0\n\n
Begin!\n\n
Context:\n
---------\n
{context}\n
---------\n
Question: {question}\n
Helpful Answer:"""
```

OK,è®©æˆ‘ä»¬è¡¥å……å®Œæ•´ç¤ºä¾‹

```python
# é¦–å…ˆå¯¼å…¥å¿…è¦çš„æ¨¡å—
from langchain.chains.qa_with_sources import load_qa_with_sources_chain
from langchain.document_loaders import PyPDFLoader
from langchain_community.chat_models import ChatTongyi
from langchain.text_splitter import CharacterTextSplitter

# å¯¼å…¥envæ–‡ä»¶
from dotenv import find_dotenv, load_dotenv
import os
# åŠ è½½ API key
load_dotenv(find_dotenv())
api_key = os.getenv("DASHSCOPE_API_KEY")

# å®šä¹‰ä¸€ä¸ªllm
llm = ChatTongyi(
    model_name = "qwen-vl-max",
    dashscope_api_key = api_key,
    temperature = 0
)

# åŠ è½½æ–‡æ¡£
laoder = PyPDFLoader('./example/fake.pdf')
docs = laoder.load()

# å¯¹æ–‡æ¡£è¿›è¡Œä¸€ä¸ªåˆ‡å‰²
text_splitter = CharacterTextSplitter(
    chunk_size = 500,
    chunk_overlap = 0
)
split_docs = text_splitter.split_documents(docs)

# åˆ›å»ºchain
chain = load_qa_with_sources_chain(
    ChatTongyi(
        temperature = 0,
        dashscope_api_key = api_key,
        model_name = "qwen-vl-max"
    ),
    chain_type = "map_rerank",
    metadata_keys = ['source'],
    return_intermediate_steps = True
)

# print(chain)

# æå‡ºé—®é¢˜
query = "What is this document talk about? answer by chinese"
result = chain({"input_documents": split_docs, "question": query}, return_only_outputs=True)
result
```

å¯ä»¥,çœ‹åˆ°è¾“å‡ºç»“æœ

![](./image/3.22.png)

æ˜¯ä»¥æ‰“åˆ†çš„å½¢å¼å‡ºç°çš„,è¾“å‡ºçš„ä¹Ÿæ˜¯æ‰“åˆ†æœ€é«˜çš„é‚£ä¸€æ®µ.

å½“ç„¶,æˆ‘ä»¬ä¹Ÿå¯ä»¥å…³é—­ä»…è¾“å‡ºæ–‡æœ¬ä¿¡æ¯,æ¥çœ‹åˆ°é‡Œé¢çš„è¯¦ç»†è¿‡ç¨‹

![](./image/3.23.png)

åˆ°è¿™é‡Œçš„è¯,å››ç§å¤„ç†æ–‡æ¡£çš„é¢„åˆ¶é“¾å°±åŸºæœ¬è®²å®Œäº†,ç›¸ä¿¡é€šè¿‡å®é™…ä½¿ç”¨,åº”è¯¥ä¼šæœ‰è‡ªå·±çš„ç†è§£

### Memoryå·¥å…·ä½¿ç”¨

> åœ¨è¿™é‡Œçš„è¯,ä¸ºä»€ä¹ˆè¦ä½¿ç”¨Menoryå·¥å…·å‘¢,å› ä¸ºLLM,é€šå¸¸æ˜¯æ— çŠ¶æ€çš„,æ— æ³•è®°å¿†ä¸Šä¸‹æ–‡

å…¶å®,langchainå·²ç»å†…ç½®äº†ä¸€æ•´å¥—çš„è§£å†³æ–¹æ¡ˆ,æˆ‘ä»¬åªéœ€è¦ä½¿ç”¨å°±è¡Œ

![](./image/3.24.png)

![](./image/3.25.png)

***ä¸åŒçš„Memoryå·¥å…·***

- åˆ©ç”¨å†…å­˜å®ç°çš„çŸ­æ—¶è®°å¿†
- åˆ©ç”¨`Entity memory`æ„å»ºå®ä½“è®°å¿†
- åˆ©ç”¨çŸ¥è¯†å›¾è°±æ¥æ„å»ºè®°å¿†
- åˆ©ç”¨å¯¹è¯æ‘˜è¦æ¥å…¼å®¹å†…å­˜ä¸­çš„é•¿å¯¹è¯
- åˆ©ç”¨tokenæ¥åˆ·æ–°å†…å­˜ç¼“å†²åŒº
- ä½¿ç”¨å‘é‡æ•°æ®åº“å®ç°é•¿æ—¶è®°å¿†

æ¥ä¸‹æ¥,æˆ‘å°†åœ¨ç¤ºä¾‹ä¸­,å±•ç¤ºä¸Šé¢ä¸åŒçš„Memoryå·¥å…·å¦‚ä½•ä½¿ç”¨,ä»¥åŠå…·ä½“çš„ç»†èŠ‚

å…ˆæ¥ä¸ªç®€å•ä¸€ç‚¹çš„

#### åˆ©ç”¨å†…å­˜å®ç°çš„çŸ­æ—¶è®°å¿†

ç›´æ¥ä¸Šç¤ºä¾‹

```python
from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory()
memory.chat_memory.add_user_message("hi!i am southaki")
memory.chat_memory.add_ai_message("hi!i am your ai assistant,can you help me?")

memory.load_memory_variables({})
```

æ¥çœ‹ä¸‹ç»“æœ

![](./image/3.26.png)

> è¿™é‡Œè°ƒç”¨çš„æ˜¯`langchain.memory`å…³äº`ConversationBufferMemory`çš„æ–¹æ³•,ç„¶åä¿å­˜è¿›æˆ‘ä»¬çš„å†…å­˜é‡Œ,å†åœ¨éœ€è¦çš„æ—¶å€™ä½¿ç”¨

æˆ‘ä»¬ç¨å¾®è¿›åŒ–ä¸€ä¸‹,æ¥å®ç°ä¸€ä¸ª**ä¸€ä¸ªæœ€è¿‘å¯¹è¯çš„çª—å£,è¶…è¿‡çª—å£æ¡æ•°çš„å¯¹è¯,å°†ä¼šä»å†…å­˜ä¸­é‡Šæ”¾å‡ºå»**

ç¤ºä¾‹:

```python
# æˆ‘ä»¬ä¹Ÿå¯ä»¥å®ç°ä¸€ä¸ªæœ€è¿‘å¯¹è¯çš„çª—å£,è¶…è¿‡çª—å£æ¡æ•°çš„å¯¹è¯,å°†ä¼šä»å†…å­˜ä¸­é‡Šæ”¾å‡ºå»
# é¦–å…ˆä¾æ—§æ˜¯å¯¼å…¥ç›¸åº”çš„æ¨¡å—
from langchain.memory import ConversationBufferMemory
from langchain.memory import ConversationBufferWindowMemory

# è¿™é‡Œæˆ‘ä»¬éœ€è¦ä¼ å…¥ä¸€ä¸ªkå€¼,è¿™ä¸ªkå€¼è¡¨æ˜çª—å£å…è®¸çš„æœ€å¤§æ¡æ•°æ˜¯å¤šå°‘,è¿™é‡Œæˆ‘åˆ†åˆ«ç»™ä½ æ¼”ç¤ºä¸€ä¸‹åŒºåˆ«
# memory = ConversationBufferWindowMemory(k=1)
# output: {'history': 'Human: not too bad\nAI: glad to hear it'}
memory = ConversationBufferWindowMemory(k=2)

memory.save_context({"input": "hi,i am southaki"}, {"output": "whats up"})
memory.save_context({"input": "not too bad"}, {"output": "glad to hear it"})

memory.load_memory_variables({})
```

![](./image/3.27.png)

#### åˆ©ç”¨`Entity memory`æ„å»ºå®ä½“è®°å¿†

å®ä½“è®°å¿†,åˆç§°`å®ä½“æ¸…å•`,æ¥çœ‹ä¸‹å…·ä½“å®ç°

```python
# å¯¼å…¥æ¨¡å—
from dotenv import find_dotenv, load_dotenv
import os
# åŠ è½½ API key
load_dotenv(find_dotenv())
api_key = os.getenv("DASHSCOPE_API_KEY")

from langchain.llms import Tongyi
from langchain.memory import ConversationEntityMemory

llm = Tongyi(
    dashscope_api_key = api_key,
    temperature = 0,
    model = 'Qwen-max'
)

memory = ConversationEntityMemory(
    llm = llm
)
_input = {
    "input": "åå—ç†å·¥å¤§å­¦å’Œåå—å¸ˆèŒƒå¤§å­¦åå—å†œä¸šå¤§å­¦æ˜¯åå—åœ°åŒºçš„é‡ç‚¹å¤§å­¦,åˆæˆåå—ä¸‰å¤§"
}
memory.load_memory_variables(_input)
```

æ¥çœ‹ä¸‹æˆæœ

![](./image/3.28.png)

æˆ‘ä»¬çœ‹åˆ°,æ„å»ºå‡ºæ¥äº†ä¸‰ä¸ªå®ä½“:åˆ†åˆ«æ˜¯ä¸Šé¢çš„ä¸‰ä¸ªå¤§å­¦åå­—,å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„æ„å»ºæ˜¯å¾ˆæˆåŠŸçš„,é‚£ä¹ˆæˆ‘ä»¬æ¥åŠ å…¥ä¸€äº›è¡¥å…… 

```python
# æå–æ¨¡æ‹Ÿè¾“å…¥,ä¸æ¥ä¸‹æ¥çš„è¾“å…¥å‘é€ç»™LLM
# å¯¼å…¥æ¨¡å—
from dotenv import find_dotenv, load_dotenv
import os
# åŠ è½½ API key
load_dotenv(find_dotenv())
api_key = os.getenv("DASHSCOPE_API_KEY")

from langchain.llms import Tongyi
from langchain.memory import ConversationEntityMemory

llm = Tongyi(
    dashscope_api_key = api_key,
    temperature = 0,
    model = 'Qwen-max'
)

memory = ConversationEntityMemory(
    llm = llm
)
_input = {
    "input": "åå—ç†å·¥å¤§å­¦å’Œåå—å¸ˆèŒƒå¤§å­¦åå—å†œä¸šå¤§å­¦æ˜¯åå—åœ°åŒºçš„é‡ç‚¹å¤§å­¦,åˆæˆåå—ä¸‰å¤§"
}
memory.load_memory_variables(_input)
memory.save_context(
    _input,
    {
        "output": "å¬èµ·æ¥ä¸é”™,æˆ‘ä¹Ÿæƒ³å»è¿™ä¸‰ä¸ªå¤§å­¦"
    }
)

memory.load_memory_variables({"input": "åå—ä¸‰è§’æ˜¯è°?"})
```

![](./image/3.29.png)

#### ä½¿ç”¨çŸ¥è¯†å›¾è°±æ¥æ„å»ºè®°å¿†

ä¾æ—§æ˜¯ä¸€ä¸ªç¤ºä¾‹

```python
# é¦–å…ˆä¾æ—§å¯¼å…¥æ¨¡å—
from langchain.llms import Tongyi
from langchain.memory import ConversationKGMemory

llm = Tongyi(
    temperature = 0,
    dashscope_api_key = api_key,
    model = 'Qwen-max'
)

memory = ConversationKGMemory(
    llm = llm,
    return_messages= True
)

# æ„å»ºå¯¹è¯
memory.save_context(
    {
        "input": "please find SouthAki"
    },
    {
        "output": "who is SouthAki"
    }
)

memory.save_context(
    {
        "input": "SouthAkiæ˜¯ä¸€ä½å‰ç«¯å·¥ç¨‹å¸ˆ"
    },
    {
        "output": "ok, i remmember"
    }
)
```

é€šè¿‡ä¸Šé¢æˆ‘ä»¬å®Œæˆæ„å»º,ç°åœ¨æ¥æ¿€æ´»çœ‹ä¸‹æœ‰ä»€ä¹ˆç”¨å¤„

- æˆ‘ä»¬å¯ä»¥ç»§ç»­æé—®ä¸‹ä¸€ä¸ªé—®é¢˜

	```python
	memory.load_memory_variables({"input": 'SouthAkiæ˜¯è°'})
	```

	![](./image/3.30.png)

- ç„¶å,åœ¨æˆ‘ä»¬çš„çŸ¥è¯†å›¾è°±é‡Œ,æˆ‘ä»¬ä¹Ÿæ˜¯å¯ä»¥æå–å®ä½“çš„

	```python
	memory.get_current_entities("SouthAkiæœ€å–œæ¬¢åšä»€ä¹ˆäº‹æƒ…")
	```

	![](./image/3.31.png)

- æˆ‘ä»¬ä¹Ÿå¯ä»¥è·å¾—åˆ°è¿™ä¸ªé—®é¢˜çš„ä¸‰å…ƒçŸ¥è¯†ç»„`ä¸»é¢˜,åŠ¨ä½œ,å¹²ä»€ä¹ˆ`

	```python
	memory.get_knowledge_triplets("SouthAkiæœ€å–œæ¬¢coding")
	```

	![](./image/3.32.png)



#### é•¿å¯¹è¯åœ¨å†…å­˜ä¸­çš„å¤„ç†æ–¹å¼

> æœ‰ä¸¤ç§:
>
> 1. *æ€»ç»“æ‘˜è¦*
> 2. *tokenè®¡ç®—*

ä¸¤ç§æˆ‘ä»¬éƒ½åšä¸ªå±•ç¤º

```python
# ä½¿ç”¨ä¸Šé¢çš„æ¨¡ç‰ˆ
from langchain.llms import Tongyi
from langchain.memory import ConversationSummaryMemory

llm = Tongyi(
    temperature = 0,
    dashscope_api_key = api_key,
    model = 'Qwen-max'
)

memory = ConversationSummaryMemory(
    llm = llm,
    return_messages= True
)

# æ„å»ºå¯¹è¯
memory.save_context(
    {
        "input": "please find SouthAki"
    },
    {
        "output": "who is SouthAki"
    }
)

memory.save_context(
    {
        "input": "SouthAkiæ˜¯ä¸€ä½å‰ç«¯å·¥ç¨‹å¸ˆ"
    },
    {
        "output": "ok, i remmember"
    }
)

memory.load_memory_variables({}) # çœ‹ä¸€ä¸‹æ€»ç»“å‡ºæ¥çš„æˆæœ

messages = memory.chat_memory.messages
print(messages) # æ‰“å°ä¸€ä¸‹æˆ‘ä»¬æäº¤ç»™å¤§è¯­è¨€æ¨¡å‹çš„èŠå¤©è®°å½•

memory.predict_new_summary(messages,"") # äº§ç”Ÿæ–°çš„æ‘˜è¦
```

![](./image/3.33.png)

OK,æˆ‘ä»¬ä¸‹é¢ä½¿ç”¨`ChatMessageHistory`æ¥å¿«é€Ÿè·å¾—å¯¹è¯æ‘˜è¦

```python
from langchain.memory import ConversationSummaryMemory
from langchain.memory import ChatMessageHistory
from langchain.llms import Tongyi

from dotenv import find_dotenv, load_dotenv
import os
# åŠ è½½ API key
load_dotenv(find_dotenv())
api_key = os.getenv("DASHSCOPE_API_KEY")

llm = Tongyi(
    dashscope_api_key = api_key,
    model = "Qwen-max",
    temperature = 0
)

# å¢åŠ ä¸€ç‚¹å†å²è®°å½•
hisiory = ChatMessageHistory()
hisiory.add_user_message("ä½ å¥½,æˆ‘æ˜¯å—ç§‹SouthAki!")
hisiory.add_ai_message("ä½ å¥½,æˆ‘æ˜¯é˜¿é‡Œå¼€å‘çš„å¤§è¯­è¨€æ¨¡å‹Tongyi,è¯·é—®æˆ‘æœ‰ä»€ä¹ˆå¯ä»¥å¸®åˆ°ä½ çš„?")

memory = ConversationSummaryMemory.from_messages(
    llm = Tongyi(
        temperature = 0,
        model = "Qwen-max",
        dashscope_api_key = api_key
    ),
    chat_memory= hisiory,
    return_messages = True
)

memory.buffer # æ€»ç»“äº†ä¸Šé¢çš„å¯¹è¯çš„å†…å®¹
```

![](./image/3.34.png)

å¦‚æœä½ æƒ³å¯¹ä¸Šé¢çš„ç”Ÿæˆç»“æ„åŒ–æ•°æ®,æˆ‘ä»¬å¯ä»¥è¿™æ ·åš

```python
from langchain.memory import ConversationSummaryMemory
from langchain.memory import ChatMessageHistory
from langchain.llms import Tongyi

from dotenv import find_dotenv, load_dotenv
import os
# åŠ è½½ API key
load_dotenv(find_dotenv())
api_key = os.getenv("DASHSCOPE_API_KEY")

llm = Tongyi(
    dashscope_api_key = api_key,
    model = "Qwen-max",
    temperature = 0
)

# å¢åŠ ä¸€ç‚¹å†å²è®°å½•
hisiory = ChatMessageHistory()
hisiory.add_user_message("ä½ å¥½,æˆ‘æ˜¯å—ç§‹SouthAki!")
hisiory.add_ai_message("ä½ å¥½,æˆ‘æ˜¯é˜¿é‡Œå¼€å‘çš„å¤§è¯­è¨€æ¨¡å‹Tongyi,è¯·é—®æˆ‘æœ‰ä»€ä¹ˆå¯ä»¥å¸®åˆ°ä½ çš„?")

# memory = ConversationSummaryMemory.from_messages(
#     llm = Tongyi(
#         temperature = 0,
#         model = "Qwen-max",
#         dashscope_api_key = api_key
#     ),
#     chat_memory= hisiory,
#     return_messages = True
# )

# memory.buffer # æ€»ç»“äº†ä¸Šé¢çš„å¯¹è¯çš„å†…å®¹

memory = ConversationSummaryMemory(
    llm = Tongyi(
        model = "Qwen-max",
        dashscope_api_key = api_key,
        temperature = 0
    ),
    return_message = True,
    buffer = 'The human, SouthAki, greets the AI, and the AI, Tongyi, introduces itself as a large language model developed by Alibaba, asking how it can assist.',
    chat_memory= hisiory
)

memory.load_memory_variables({})
```

![](./image/3.35.png)

#### åˆ©ç”¨tokenæ¥åˆ·æ–°å†…å­˜ç¼“å†²åŒº

æ¥ä¸‹æ¥è¿™ä¸ªæ˜¯æ¯”è¾ƒå¥½ç”¨çš„`ConversationSummaryBufferMemory`

è¿™ä¸ªå¥½å¤„æ˜¯å½“å¯¹è¯æŒç»­è¿›è¡Œçš„æ—¶å€™ä¸”å¯¹è¯å†…å®¹å¾ˆå¤šçš„æ—¶å€™,å®ƒä¼šæ ¹æ®tokençš„æ•°é‡æ¥è‡ªåŠ¨åˆ¤æ–­æ˜¯å¦éœ€è¦è¿›è¡Œæ‘˜è¦

å½“tokenæ•°é‡è¶…è¿‡é˜ˆå€¼çš„æ—¶å€™,ä¼šè‡ªåŠ¨è¿›è¡Œæ‘˜è¦

åœ¨ç¼“å†²åŒºä¸­,ä¼šä¿å­˜æœ€è¿‘çš„kæ¡å¯¹è¯

æ¯”è¾ƒä¹…çš„å¯¹è¯ä¼šè¢«åˆ é™¤,åœ¨åˆ é™¤å‰ä¼šè¿›è¡Œæ‘˜è¦

```python
# é¦–å…ˆä¾æ—§å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
from dotenv import find_dotenv, load_dotenv
import os
# åŠ è½½ API key
load_dotenv(find_dotenv())
api_key = os.getenv("DASHSCOPE_API_KEY")

from langchain.memory import ConversationSummaryBufferMemory
from langchain.llms import Tongyi

llm = Tongyi(
    dashscope_api_key = api_key,
    model = "Qwen-max",
    temperature = 0
)

memory = ConversationSummaryBufferMemory(
    llm = llm,
    max_token_limit= 10,
    return_messages = True
)

memory.save_context(
    {
        "input": "ä½ å¥½,å¸®æˆ‘æ‰¾ä¸‹å—ç§‹SouthAki"
    },
    {
        "output": "sorry, who is å—ç§‹SouthAki?"
    }
)

memory.save_context(
    {
        "input": "å—ç§‹SouthAkiæ˜¯ä¸€ä¸ªå‰ç«¯å¼€å‘å·¥ç¨‹å¸ˆ"
    },
    {
        "output": "ok,i know"
    }
)

memory.save_context(
    {
        "input": "ä»Šå¤©ä»–è¦è®²ä¸€é—¨å…³äºåä¸ºä»“é¢‰ç¼–ç¨‹çš„è¯¾ç¨‹"
    },
    {
        "output": "ok,i know.do you need more information?"
    }
)

memory.load_memory_variables({})
```

![](./image/3.36.png)

ok ,ä¸‹é¢è¿™ä¸ªæ˜¯tokenè®¡ç®—çš„å†…å®¹

ä½¿ç”¨åˆ°äº†`Conversation Token Buffer`

è¿ç”¨token,æ¥å†³å®šä»€ä¹ˆæ—¶å€™åˆ·æ–°å†…å­˜

```python
from dotenv import find_dotenv, load_dotenv
import os
# åŠ è½½ API key
load_dotenv(find_dotenv())
api_key = os.getenv("DASHSCOPE_API_KEY")

from langchain.memory import ConversationTokenBufferMemory
from langchain.llms import Tongyi

llm = Tongyi(
    model = "Qwen-max",
    dashscope_api_key = api_key,
    temperature = 0
)

memory = ConversationTokenBufferMemory(
    llm = llm,
    max_token_limit= 150
)

memory.save_context(
    {
        "input": "ä½ å¥½,å¸®æˆ‘æ‰¾ä¸‹å—ç§‹SouthAki"
    },
    {
        "output": "sorry, who is å—ç§‹SouthAki?"
    }
)

memory.save_context(
    {
        "input": "å—ç§‹SouthAkiæ˜¯ä¸€ä¸ªå‰ç«¯å¼€å‘å·¥ç¨‹å¸ˆ"
    },
    {
        "output": "ok,i know"
    }
)

memory.save_context(
    {
        "input": "ä»Šå¤©ä»–è¦è®²ä¸€é—¨å…³äºåä¸ºä»“é¢‰ç¼–ç¨‹çš„è¯¾ç¨‹"
    },
    {
        "output": "ok,i know.do you need more information?"
    }
)

memory.save_context(
    {
        "input": "ä¸éœ€è¦èµ„æ–™äº†,è°¢è°¢"
    },
    {
        "output": "All right, see you next time."
    }
)

memory.load_memory_variables({})
```

![](./image/3.37.png)

ä»¥ä¸Šçš„éƒ½æ˜¯çŸ­æ—¶è®°å¿†çš„å®ç°

ä½†æ˜¯,å½“æˆ‘ä»¬å…³æœºç­‰çš„æ—¶å€™,æˆ‘ä»¬æœ‰äº›æ•°æ®ä¸é™ä¸¢å¤±,äºæ˜¯æˆ‘ä»¬éœ€è¦å®ç°é•¿æ—¶è®°å¿†,æ¥ä¿å­˜æˆ‘ä»¬çš„æ•°æ®

langchainæ˜¯ä½¿ç”¨å‘é‡æ•°æ®åº“æ¥å­˜å‚¨ä¹‹å‰çš„å¯¹è¯å†…å®¹,æœ‰çš„å‘é‡æ•°æ®åº“æœåŠ¡è¿˜æä¾›è‡ªåŠ¨æ‘˜è¦,æ¯æ¬¡å¯¹è¯çš„æ—¶å€™,éƒ½ä¼šä»å‘é‡æ•°æ®åº“é‡ŒæŸ¥è¯¢æœ€ç›¸å…³çš„æ–‡æ¡£æˆ–è€…å†å²å¯¹è¯

#### ä½¿ç”¨å‘é‡æ•°æ®åº“å®ç°é•¿æ—¶è®°å¿†

å®ç°

```python
# é¦–å…ˆå¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.memory import ConversationBufferMemory
from langchain.vectorstores import FAISS

memory = ConversationBufferMemory()
memory.save_context(
    {
        "input": "ä½ å¥½,å¸®æˆ‘æ‰¾ä¸‹å—ç§‹SouthAki"
    },
    {
        "output": "sorry, who is å—ç§‹SouthAki?"
    }
)

memory.save_context(
    {
        "input": "å—ç§‹SouthAkiæ˜¯ä¸€ä¸ªå‰ç«¯å¼€å‘å·¥ç¨‹å¸ˆ"
    },
    {
        "output": "ok,i know"
    }
)

memory.save_context(
    {
        "input": "ä»Šå¤©ä»–è¦è®²ä¸€é—¨å…³äºåä¸ºä»“é¢‰ç¼–ç¨‹çš„è¯¾ç¨‹"
    },
    {
        "output": "ok,i know.do you need more information?"
    }
)

memory.save_context(
    {
        "input": "ä¸éœ€è¦èµ„æ–™äº†,è°¢è°¢"
    },
    {
        "output": "All right, see you next time."
    }
)

vectorstore = FAISS.from_texts(
    memory.buffer.split("\n"),
    HuggingFaceEmbeddings(model_name="BAAI/bge-small-en")
)

FAISS.save_local(vectorstore, "test_faiss")

FAISS.load_local("test_faiss", HuggingFaceEmbeddings(model_name="BAAI/bge-small-en"),allow_dangerous_deserialization=True).similarity_search("SouthAkiåšä»€ä¹ˆèŒä¸š?")
```

![](./image/3.38.png)

æ£€éªŒä¸€ä¸‹:

```python
# æˆ‘ä»¬æ¥æµ‹è¯•ä¸€ä¸‹æ˜¯å¦æœ‰æˆåŠŸå†™å…¥å‘é‡æ•°æ®åº“
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.memory import VectorStoreRetrieverMemory

r1 = FAISS.load_local("test_faiss", embeddings=HuggingFaceEmbeddings(model_name="BAAI/bge-small-en"),allow_dangerous_deserialization=True)
r2 = r1.as_retriever(
    search_kwargs={"k": 1}
)

memory2 = VectorStoreRetrieverMemory(retriever=r2)

memory2.load_memory_variables({"prompt": "SouthAkiæ˜¯ä»€ä¹ˆèŒä¸š"})
```

![](./image/3.39.png)
