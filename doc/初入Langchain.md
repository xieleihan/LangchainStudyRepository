# Langchain

ä½œè€…:`@xieleihan`[ç‚¹å‡»è®¿é—®](https://github.com/xieleihan)

æœ¬æ–‡éµå®ˆGPL3.0å¼€æºåè®®

# 1.åˆè¯†Langchain

## ä»‹ç»

LangChainæ˜¯ä¸€ä¸ªç”¨äºæ„å»ºå’Œéƒ¨ç½²ä»¥è¯­è¨€æ¨¡å‹ä¸ºæ ¸å¿ƒçš„åº”ç”¨çš„æ¡†æ¶ã€‚å®ƒä¸ºå¼€å‘è€…æä¾›äº†ä¸€å¥—å·¥å…·å’Œæ¨¡å—ï¼Œç”¨äºå¤„ç†ã€ç®¡ç†å’Œä¼˜åŒ–ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚OpenAIçš„GPT-3å’ŒGPT-4ï¼‰ç›¸å…³çš„ä»»åŠ¡å’Œæµç¨‹ã€‚LangChainçš„ç›®æ ‡æ˜¯ç®€åŒ–å¤æ‚çš„è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰åº”ç”¨çš„å¼€å‘è¿‡ç¨‹ï¼Œä½¿å¼€å‘è€…èƒ½å¤Ÿæ›´è½»æ¾åœ°åˆ›å»ºå¼ºå¤§ã€çµæ´»çš„åº”ç”¨ç¨‹åºã€‚ä»¥ä¸‹æ˜¯LangChainçš„ä¸€äº›ä¸»è¦ç‰¹ç‚¹å’ŒåŠŸèƒ½ï¼š

1. **æ¨¡å‹é›†æˆ**ï¼šLangChainæ”¯æŒå¤šç§è¯­è¨€æ¨¡å‹çš„é›†æˆï¼Œå…è®¸å¼€å‘è€…é€‰æ‹©å’Œåˆ‡æ¢ä¸åŒçš„æ¨¡å‹ï¼Œä»¥æ»¡è¶³ä¸åŒçš„éœ€æ±‚ã€‚

2. **æ•°æ®å¤„ç†**ï¼šæä¾›äº†æ•°æ®é¢„å¤„ç†ã€åå¤„ç†å’Œå¢å¼ºçš„åŠŸèƒ½ï¼Œä½¿å¾—æ•°æ®çš„å‡†å¤‡å’Œå¤„ç†æ›´åŠ é«˜æ•ˆã€‚

3. **æ¨¡å—åŒ–è®¾è®¡**ï¼šæ¡†æ¶é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œå¼€å‘è€…å¯ä»¥æ ¹æ®å…·ä½“éœ€æ±‚ç»„åˆä¸åŒçš„æ¨¡å—ï¼Œä¾‹å¦‚æ–‡æœ¬ç”Ÿæˆã€é—®ç­”ç³»ç»Ÿã€å¯¹è¯ä»£ç†ç­‰ã€‚

4. **æ‰©å±•æ€§å’Œå¯å®šåˆ¶æ€§**ï¼šå¼€å‘è€…å¯ä»¥è½»æ¾åœ°æ‰©å±•å’Œå®šåˆ¶LangChainä¸­çš„ç»„ä»¶ï¼Œä»¥é€‚åº”ç‰¹å®šçš„åº”ç”¨åœºæ™¯å’Œä¸šåŠ¡éœ€æ±‚ã€‚

5. **å·¥å…·é›†æˆ**ï¼šLangChainæ”¯æŒä¸å…¶ä»–å·¥å…·å’ŒæœåŠ¡çš„é›†æˆï¼Œå¦‚æ•°æ®åº“ã€APIã€å‰ç«¯æ¡†æ¶ç­‰ï¼Œæ–¹ä¾¿æ„å»ºç«¯åˆ°ç«¯çš„è§£å†³æ–¹æ¡ˆã€‚

6. **æ€§èƒ½ä¼˜åŒ–**ï¼šæä¾›äº†å¤šç§æ€§èƒ½ä¼˜åŒ–ç­–ç•¥ï¼Œå¦‚æ¨¡å‹å‹ç¼©ã€å¹¶è¡Œå¤„ç†ç­‰ï¼Œå¸®åŠ©æé«˜åº”ç”¨çš„æ•ˆç‡å’Œå“åº”é€Ÿåº¦ã€‚

7. **ç¤¾åŒºå’Œæ–‡æ¡£**ï¼šLangChainæ‹¥æœ‰æ´»è·ƒçš„ç¤¾åŒºå’Œè¯¦ç»†çš„æ–‡æ¡£ï¼Œå¼€å‘è€…å¯ä»¥è·å¾—åŠæ—¶çš„æ”¯æŒå’ŒæŒ‡å¯¼ï¼Œå¿«é€Ÿä¸Šæ‰‹å¹¶è§£å†³å¼€å‘è¿‡ç¨‹ä¸­é‡åˆ°çš„é—®é¢˜ã€‚

LangChainé€‚ç”¨äºå„ç§åº”ç”¨åœºæ™¯ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š

- èŠå¤©æœºå™¨äººå’Œè™šæ‹ŸåŠ©æ‰‹
- è‡ªåŠ¨åŒ–å†…å®¹ç”Ÿæˆ
- æ–‡æœ¬æ‘˜è¦å’Œç¿»è¯‘
- æƒ…æ„Ÿåˆ†æå’Œæ–‡æœ¬åˆ†ç±»
- é—®ç­”ç³»ç»Ÿå’ŒçŸ¥è¯†åº“æ„å»º

é€šè¿‡LangChainï¼Œå¼€å‘è€…å¯ä»¥æ›´åŠ ä¸“æ³¨äºä¸šåŠ¡é€»è¾‘å’Œåº”ç”¨è®¾è®¡ï¼Œè€Œä¸ç”¨èŠ±è´¹å¤§é‡æ—¶é—´åœ¨åº•å±‚æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œä»è€ŒåŠ é€ŸNLPåº”ç”¨çš„å¼€å‘å’Œéƒ¨ç½²ã€‚

> ä¸Šé¢çš„å†…å®¹å¼•ç”¨äº†ChatGPTçš„å›ç­”

>  LangChainç”±Harrison Chaseäº2022å¹´10æœˆä½œä¸º[å¼€æºè½¯ä»¶](https://zh.wikipedia.org/wiki/å¼€æºè½¯ä»¶)é¡¹ç›®æ¨å‡º

## ä½¿ç”¨

å¾—çŸ¥å®ƒèƒ½åšä»€ä¹ˆ,æˆ‘ä»¬æ¥ä¸‹æ¥,å°±å¾—æ¥å¦‚ä½•è¿è¡Œèµ·æˆ‘ä»¬çš„é¦–ä¸ªLangchainçš„åº”ç”¨

*Warningâš™ï¸è¿™é‡Œè¦è¯´ä¸‹:æˆ‘è¿™è¾¹æ˜¯è‡ªå·±è·‘é¦–ä¸ªè¿è¡Œçš„æ—¶å€™,è¸©äº†ä¸€äº›å‘,å¦‚æœå¯ä»¥çš„è¯,è¯·ç”¨æˆ‘è¿™ä¸ªæ–¹æ³•æ¥,å› ä¸ºæˆ‘å¤šæ¬¡å®è·µ,å‘ç°è¿™ä¸ªæ–¹æ³•æœ€ç¨³å®š,ä¸ç”¨èŠ±å¾ˆé•¿æ—¶é—´å»å®˜ç½‘æˆ–è€…æµ·å¤–å„ç§æ¸ é“æ‰¾èµ„æ–™.è¿™é‡Œå¦‚æœä½ è®¤å¯è¿™ä¸ªè¯´æ˜,è¯·ä¸€å®šæŒ‰ç…§æˆ‘çš„æ–¹æ³•æ¥,è™½ç„¶åç»­ä¸çŸ¥é“ä¼šå‡ºç°å¤šå°‘é—®é¢˜,ä½†æ˜¯ç›®å‰æ¥è¯´è¿™æ ·æ˜¯æœ€å¥½çš„!*

### é¦–å…ˆ,ä½ éœ€è¦åœ¨ç”µè„‘ä¸Šå®‰è£…ä¸€ä¸ªPythonç¯å¢ƒ

å®˜ç½‘åœ°å€:`https://www.python.org/`[ç‚¹å‡»è®¿é—®](https://www.python.org/)

è¿™é‡Œæˆ‘æ¨èä¸‹è½½æœ€æ–°çš„Pythonç¯å¢ƒ,ä½†æ˜¯è‡³å°‘éœ€è¦***3.8ä»¥ä¸Š***çš„,è¿™ä¸ªéœ€è¦æ³¨æ„

![Pythonç¯å¢ƒ](./image/1.1.png)

ç„¶å,éœ€è¦åˆ°`Vscode`æˆ–è€…`Pychran`ç­‰ideä¸Š,ä¸‹è½½ä¸€ä¸ªæ’ä»¶:`Jupyter`

![](./image/1.2.png)

### å†åˆ°vscodeæ–°å»ºæˆ‘ä»¬ç¬¬ä¸€ä¸ªæ–‡ä»¶

`helloworld.ipynb`,è¿™æ˜¯ä¸€ä¸ªjupyterçš„æ–‡ä»¶

![](./image/1.3.png)

![](./image/1.4.png)

### å†æ¥ç€,éœ€è¦å®‰è£…ä¸€äº›æˆ‘ä»¬éœ€è¦çš„package

```python
pip install langchain #å®‰è£…langchainç¯å¢ƒ
pip install openai # å®‰è£…openai api
# éœ€è¦æ³¨æ„çš„æ˜¯,ä¸‹é¢ä¸¤ä¸ªæ˜¯ä½ è¦ç”¨é€šä¹‰æ¨¡å‹æ‰éœ€è¦å®‰è£…,ä¸ç„¶å°±å®‰è£…ä¸Šé¢çš„å°±è¡Œ
pip install python-dotenv #åŠ è½½å·¥å…·
pip install dashscope #çµç§¯æ¨¡å‹æœåŠ¡
```

æˆ‘ä»¬åˆ°ç»ˆç«¯`cmd`æˆ–è€…åˆ°vscodeé‡Œå»æ‰§è¡Œä¸Šé¢çš„pipå°±è¡Œ,çœ‹åˆ°`success`å°±å¯ä»¥äº†

éªŒè¯

```python
pip show [your-package]
```

### ä½¿ç”¨openaiçš„æ¨¡å‹(æœ‰ç‚¹é—®é¢˜,èƒ½è§£å†³çš„ç”¨è¿™ä¸ª,ä¸èƒ½çš„ä¸‹é¢æœ‰å…¶ä»–)

```python
# å¼•å…¥openai key
import os
# é…ç½®ç¯å¢ƒå˜é‡
os.environ["OPENAI_KEY"] = "sk-yourOpenaiApi"
os.environ["OPENAI_API_BASE"] = "https://api.openai.com/v1"
```

æµ‹è¯•ä¸€ä¸‹æˆåŠŸå¦

```python
import os
openai_api_key = os.getenv("OPENAI_KEY")
openai_api_base = os.getenv("OPENAI_API_BASE")
print("OPENAI_API_KEY:", openai_api_key)
print("OPENAI_PROXY:", openai_api_base)
```

è¾“å‡º`å¯¹åº”çš„ä¿¡æ¯å°±è¡Œ`

æ¥ä¸‹æ¥,æ˜¯å®˜æ–¹sdkæµ‹è¯•(langchain)

```python
#hello world
from langchain.llms import OpenAI
import os

api_base = os.getenv("OPENAI_API_BASE")
api_key = os.getenv("OPENAI_KEY")
llm = OpenAI(
    model="gpt-3.5-turbo-instruct",
    temperature=0,
    openai_api_key=api_key,
    openai_api_base=api_base
    )
llm.predict("ä»‹ç»ä¸‹ä½ è‡ªå·±")
```

è¿™ä¸ªéœ€è¦ä½ è‡ªå·±å»è¯•ä¸‹,æˆ‘çš„é—®é¢˜å°±æ˜¯ä¸€ç›´429 Error,ç„¶åæˆ‘ç”¨æµ·å¤–å€Ÿè®°å¡ä¹Ÿæ— æ³•ä»˜æ¬¾ç»™openaiä¹°é…é¢æˆ–è€…è¿™ç±»çš„å§,è§‰å¾—æ˜¯é…é¢çš„é—®é¢˜(å¾…æŒ‡æ­£)

```text
RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
```

ç„¶å,æˆ‘æ¢äº†è¯­è¨€æ¨¡å‹,æ¯•ç«Ÿæˆ‘ä»¬éƒ½æ˜¯å»è¯·æ±‚è¯­è¨€æ¨¡å‹,æ‰€ä»¥è¿™é‡Œæ›´æ”¹æˆ‘è§‰å¾—å¯¹åé¢çš„å½±å“ä¸å¤§,åç»­æœ‰é—®é¢˜æˆ‘è‡ªå·±å†è§£å†³

```python
#å¯¼å…¥ç›¸å…³åŒ…
import os
from dotenv import find_dotenv, load_dotenv
load_dotenv(find_dotenv())
DASHSCOPE_API_KEY=os.environ["DASHSCOPE_API_KEY"]
from langchain_community.llms import Tongyi
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
```

è¿™é‡Œæˆ‘ä»¬éœ€è¦å»ç”³è¯·ä¸€ä¸ªé˜¿é‡Œçš„é€šä¹‰çš„`api-key`

å®˜ç½‘:`https://dashscope.console.aliyun.com/overview`[ç‚¹å‡»è®¿é—®](https://dashscope.console.aliyun.com/overview)

ç”³è¯·æµç¨‹(å¾…è¡¥å……æˆ–ç•¥)

ç„¶å,åœ¨`rootç›®å½•`ä¸‹æ–°å»ºä¸€ä¸ªæ–‡ä»¶`.env`

å†…å®¹

```ini
DASHSCOPE_API_KEY="your-tongyiApiKey"
```

ç„¶å

```python
llm=Tongyi(temperature=1)
template='''
        ä½ çš„åå­—æ˜¯å—ç§‹SouthAki,å½“äººé—®é—®é¢˜çš„æ—¶å€™,ä½ éƒ½ä¼šåœ¨å¼€å¤´åŠ ä¸Š'ç”Ÿæ´»è‹¦çŸ­,æˆ‘ç”¨é€šä¹‰',ç„¶åå†å›ç­”{question}
    '''
prompt=PromptTemplate(
        template=template,
        input_variables=["question"]#è¿™ä¸ªquestionå°±æ˜¯ç”¨æˆ·è¾“å…¥çš„å†…å®¹,è¿™è¡Œä»£ç ä¸å¯ç¼ºå°‘
)
chain = LLMChain(#å°†llmä¸promptè”ç³»èµ·æ¥
        llm=llm,
        prompt=prompt
        )
question='ä»‹ç»ä¸‹é€šä¹‰æ¨¡å‹'

res=chain.invoke(question)#è¿è¡Œ
    
print(res['text'])#æ‰“å°ç»“æœ
```

```text
è§£é‡Š:
os,dotenvéƒ½æ˜¯ç”¨æ¥åŠ è½½ç¯å¢ƒå˜é‡DASHSCOPE_API_KEYçš„
Tongyiå°±æ˜¯è¿™é‡Œä½¿ç”¨çš„é€šä¹‰åƒé—®å¤§è¯­è¨€æ¨¡å‹
PromptTemplateæ˜¯æç¤ºè¯æ¨¡æ¿,ç”¨æ¥ç»™å¤§æ¨¡å‹åšå›ç­”é™åˆ¶çš„,ä»–ä¼šæŒ‰ç…§æç¤ºè¯æ¨¡æ¿çš„å†…å®¹è¿›è¡Œå›ç­”,è·Ÿæ¨¡å‹çš„æ™ºæ…§ç¨‹åº¦æœ‰å…³,æ•°æ®é›†è¶Šå¤§çš„æ¨¡å‹æ ¹æ®æç¤ºè¯åšçš„å›ç­”è¶Šå¥½,åæœŸåšAgentçš„æ•ˆæœè¶Šå¥½.
LLMChainå°±æ˜¯ç”¨æ¥æŠŠLLMå’Œpromptè¿›è¡Œè”ç³»çš„
temperature=1æ˜¯è°ƒèŠ‚æ–‡æœ¬å¤šæ ·æ€§çš„,è®©å›ç­”æ›´åŠ ä¸°å¯Œ,ä¸º0æ—¶å°±ä¼šæ›´åŠ å‡†ç¡®,å¤§äº0å›ç­”çš„å°±ä¼šå¸¦æœ‰llmçš„æ€ç»´å›ç­”(å¯èƒ½ä¼šèƒ¡ç¼–ä¹±é€ ) res['text']å°±æ˜¯å›ç­”å†…å®¹äº†,å›ç­”çš„ä¸€ä¸ªå­—å…¸åŒ…å«äº†questionå’Œtext
```

![](./image/1.5.png)

## è¿™é‡Œæˆ‘ä»¬è¦å®Œæˆä»€ä¹ˆå‘¢

![](./image/1.9.png)

> å›¾æ¥æºäºinternet,è¯·å‹¿è½¬è½½

é‚£ä¹ˆéœ€è¦æœ‰ç‚¹,åŸºç¡€çš„çŸ¥è¯†

```text
// åˆ›å»ºLLM
åœ¨langchainä¸­æœ€åŸºæœ¬çš„åŠŸèƒ½å°±æ˜¯æ ¹æ®æ–‡æœ¬æç¤ºæ¥ç”Ÿæˆæ–°çš„æ–‡æœ¬
ä½¿ç”¨çš„æ–¹æ³•æ˜¯:`predict`
Question:"å¸®æˆ‘èµ·ä¸€ä¸ªå…·æœ‰ä¸­å›½ç‰¹è‰²çš„ç”·å­©åå­—" => LLM.predict() => "ç‹—å‰©"

ç”Ÿæˆçš„ç»“æœæ ¹æ®ä½ è°ƒç”¨çš„æ¨¡å‹ä¸åŒä¼šäº§ç”Ÿéå¸¸ä¸åŒçš„ç»“æœå·®è·,å¹¶ä¸”tempuratureå‚æ•°ä¹Ÿä¼šå½±å“æœ€ç»ˆç»“æœ
```



```text
// è‡ªå®šä¹‰ä¸€ä¸ªæç¤ºè¯æ¨¡ç‰ˆ
æˆ‘ä»¬éœ€è¦ç”¨ä¸Šlangchainæä¾›çš„ä¸€ä¸ªæ–¹æ³•:`prompts`
ä½¿ç”¨æ–¹æ³•:`langchain.prompts

ä¸¾ä¾‹:
Question:"å¸®æˆ‘èµ·ä¸€ä¸ªå…·æœ‰{country}ç‰¹è‰²çš„ç”·å­©åå­—" =>prompts.format(country = "ç¾å›½") => "å±±å§†"
```



## All right:ä¸Šé¢çš„è¯,è¡¥å……ç‚¹ä¸œè¥¿

å°±æ˜¯,åˆšä¸€è¿è§£å†³ä¸¤ä¸ªå¯èƒ½çš„é—®é¢˜

å°±æ˜¯åœ¨å®šä¹‰è¿™ä¸ª`OPENAI-API-KEY`çš„æ—¶å€™,é‡Œé¢æœ‰ä¸ªå¡«å…¥ä»£ç†çš„åœ°æ–¹

åŸæ¥æˆ‘ä»¬æ˜¯è¿™æ ·çš„

```python
os.environ["OPENAI_API_BASE"] = "https://www.jcapikey.com"
```

but,è¿™ä¸ªå¯èƒ½å¯¹ä¸‹é¢çš„langchainçš„è¿è¡Œé€ æˆè¿™ä¸ªé—®é¢˜

**<font color="red">AttributeError</font>**

```text
é”™è¯¯message
AttributeError                            Traceback (most recent call last)
Cell In[8], line 12
      5 api_key = os.getenv("OPENAI_KEY")
      6 llm = ChatOpenAI(
      7     model="gpt-3.5-turbo-instruct",
      8     temperature=0,
      9     openai_api_key=api_key,
     10     openai_api_base=api_base
     11 )
---> 12 result = llm.predict("ä»‹ç»ä¸‹ä½ è‡ªå·±")
     13 print(type(result))  # æ‰“å°è¿”å›ç»“æœçš„ç±»å‹

File c:\Users\xiele\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\_api\deprecation.py:148, in deprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper(*args, **kwargs)
    146     warned = True
    147     emit_warning()
--> 148 return wrapped(*args, **kwargs)

File c:\Users\xiele\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py:885, in BaseChatModel.predict(self, text, stop, **kwargs)
    883 else:
    884     _stop = list(stop)
--> 885 result = self([HumanMessage(content=text)], stop=_stop, **kwargs)
    886 if isinstance(result.content, str):
    887     return result.content
...
--> 461     response = response.dict()
    462 for res in response["choices"]:
    463     message = convert_dict_to_message(res["message"])

AttributeError: 'str' object has no attribute 'dict'
Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...
```

è§£å†³æ–¹æ³•:

```python
os.environ["OPENAI_API_BASE"] = "https://www.jcapikey.com/v1"
```

**å°±æ˜¯åœ¨è¿™ä¸ªä»£ç†åœ°å€ç»“å°¾,æ·»åŠ `/v1`**

è¿™æ ·,å¯ä»¥è§£å†³é—®é¢˜

è¿™é‡Œ,æŠŠæˆ‘æˆç†Ÿæ–¹æ¡ˆè´´åœ¨è¿™é‡Œ,è¯•ä¸‹å¯å¦å¯è¡Œ,å› ä¸ºæˆ‘æµ‹è¯•å,ç°åœ¨æ˜¯`403 Error`,ä¸è¿‡è¿™ä¸ªåº”è¯¥å°±æ˜¯é…é¢çš„é—®é¢˜äº†

```python
import os
from langchain.chat_models import ChatOpenAI

api_base = os.getenv("OPENAI_API_BASE")
api_key = os.getenv("OPENAI_KEY")
llm = ChatOpenAI(
    model="gpt-3.5-turbo-instruct",
    temperature=0,
    openai_api_key=api_key,
    openai_api_base=api_base
)
result = llm.predict("ä»‹ç»ä¸‹ä½ è‡ªå·±")
print(result)  # æ‰“å°è¿”å›ç»“æœçš„ç±»å‹

```

å‚è€ƒé“¾æ¥:[ç‚¹å‡»è®¿é—®](https://blog.csdn.net/jining11/article/details/134806188)

##  ç„¶åæˆ‘ä»¬å¯¹è¿™ä¸ªåšä¸ªå°é¡¹ç›®

### Project

ç°åœ¨æˆ‘ä»¬æ˜¯æµ‹è¯•å®Œæ¯•äº†,tongyiçš„æ¨¡å‹,æˆ‘ä»¬æ¥ç€æ¥å®ç°ä¸€ä¸ªèµ·åå¤§å¸ˆ

ä¾æ—§çš„,å…ˆæ˜¯OpenAIçš„,ä½†æ˜¯æ²¡æœ‰é¢åº¦,æˆ‘ä»¬è½¬è¯‘ä¸€ä¸‹è¯•è¯•

```python
#èµ·åå¤§å¸ˆ
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
import os
api_base = os.getenv("OPENAI_API_BASE")
api_key = os.getenv("OPENAI_KEY")
llm = OpenAI(
    model="gpt-3.5-turbo-instruct",
    temperature=0,
    openai_api_key=api_key,
    openai_api_base=api_base
    )
prompt = PromptTemplate.from_template("ä½ æ˜¯ä¸€ä¸ªèµ·åå¤§å¸ˆ,è¯·æ¨¡ä»¿ç¤ºä¾‹èµ·3ä¸ª{county}åå­—,æ¯”å¦‚ç”·å­©ç»å¸¸è¢«å«åš{boy},å¥³å­©ç»å¸¸è¢«å«åš{girl}")
message = prompt.format(county="ä¸­å›½ç‰¹è‰²çš„",boy="ç‹—è›‹",girl="ç¿ èŠ±")
print(message)
llm.predict(message)
```

> ğŸš§:ä»¥åç›¸å…³çš„Openaiçš„æ¥å£æˆ‘ä¹Ÿä¼šåŒæ­¥çš„è´´å‡ºæ¥,éœ€è¦è‡ªå·±ä¹°é¢åº¦æµ‹è¯•,æŒ‰é“ç†åº”è¯¥æ˜¯å¯ä»¥è·‘é€šçš„

ä¸‹é¢çš„è¿™ä¸ªæ˜¯ä½¿ç”¨äº†å›½äº§å¤§è¯­è¨€æ¨¡å‹**Tongyi**çš„(*é€šè¿‡å¯¹OpenAIçš„ç›´æ¥è½¬è¯‘å¾—åˆ°*)

```python
from langchain_community.llms import Tongyi
from langchain.prompts import PromptTemplate
import os

# è·å–ç¯å¢ƒå˜é‡ä¸­çš„ API åŸºæœ¬ URL å’Œå¯†é’¥
api_base = os.getenv("OPENAI_API_BASE")
api_key = os.getenv("OPENAI_KEY")

# ä½¿ç”¨ Tongyi æ¨¡å‹
llm = Tongyi(
    model="gpt-3.5-turbo-instruct",
    temperature=0,
    openai_api_key=api_key,
    openai_api_base=api_base
)

# åˆ›å»º PromptTemplate
prompt = PromptTemplate.from_template("ä½ æ˜¯ä¸€ä¸ªèµ·åå¤§å¸ˆ,è¯·æ¨¡ä»¿ç¤ºä¾‹èµ·3ä¸ª{county}åå­—,æ¯”å¦‚ç”·å­©ç»å¸¸è¢«å«åš{boy},å¥³å­©ç»å¸¸è¢«å«åš{girl}")

# æ ¼å¼åŒ–æ¶ˆæ¯
message = prompt.format(county="ä¸­å›½ç‰¹è‰²çš„", boy="ç‹—è›‹", girl="ç¿ èŠ±")
print(message)

# è°ƒç”¨ Tongyi æ¨¡å‹è¿›è¡Œé¢„æµ‹
response = llm.predict(message)
print(response)
```

ä½†æ˜¯å‘ç°,ç›´æ¥è½¬è¯‘æœ‰é—®é¢˜,è™½ç„¶ç»“æœæ˜¯è¿™æ ·çš„

![](./image/1.6.png)

æ‰€ä»¥,æˆ‘å¯¹è¿™ä¸ªè¿›è¡Œç›¸åº”ä¿®æ”¹

```python
llm=Tongyi(temperature=0)
template='''
        ä½ æ˜¯ä¸€ä¸ªèµ·åå¤§å¸ˆ,è¯·æ¨¡ä»¿ç¤ºä¾‹èµ·3ä¸ª{county}åå­—,æ¯”å¦‚ç”·å­©ç»å¸¸è¢«å«åš{boy},å¥³å­©ç»å¸¸è¢«å«åš{girl}
    '''
prompt=PromptTemplate(
        template=template,
        input_variables=["county", "boy", "girl"]# è¿™ä¸ªquestionå°±æ˜¯ç”¨æˆ·è¾“å…¥çš„å†…å®¹,è¿™è¡Œä»£ç ä¸å¯ç¼ºå°‘
)
chain = LLMChain(#å°†llmä¸promptè”ç³»èµ·æ¥
        llm=llm,
        prompt=prompt
        )

# ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
county = "ä¸­å›½ç‰¹è‰²çš„"
boy = "ç‹—è›‹"
girl = "ç¿ èŠ±"

# æ ¼å¼åŒ–æ¶ˆæ¯
message = prompt.format(county=county, boy=boy, girl=girl)

# è¿è¡Œå¹¶æ‰“å°ç»“æœ
res = chain.invoke({"county": county, "boy": boy, "girl": girl})
print(res['text'])

# å°è¯•æ‰“å°message
print(message)
# è¾“å‡ºllmçš„predict
llm.predict(message)
```

è¿™é‡Œéœ€è¦è§£é‡Šä¸€ä¸‹

> åœ¨è¯­è¨€æ¨¡å‹ï¼ˆå¦‚GPT-3æˆ–å…¶ä»–ç±»ä¼¼æ¨¡å‹ï¼‰ä¸­ï¼Œ`temperature` å‚æ•°æ˜¯ä¸€ä¸ªæ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§çš„è¶…å‚æ•°ã€‚å®ƒåœ¨ç”Ÿæˆæ¨¡å‹è¾“å‡ºæ—¶å½±å“è¯çš„é€‰æ‹©æ–¹å¼ï¼Œå…·ä½“å¦‚ä¸‹ï¼š
>
> 1. **ä½ `temperature` å€¼ï¼ˆæ¥è¿‘0ï¼‰**ï¼š
> 	- **æ›´ç¡®å®šæ€§**ï¼šæ¨¡å‹æ›´å€¾å‘äºé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„è¯ï¼Œå› æ­¤ç”Ÿæˆçš„æ–‡æœ¬æ›´æœ‰æ¡ç†ï¼Œè¿è´¯æ€§è¾ƒå¼ºï¼Œä½†ä¹Ÿå¯èƒ½æ˜¾å¾—ç¼ºä¹åˆ›æ„å’Œå¤šæ ·æ€§ã€‚
> 	- **ç¤ºä¾‹**ï¼šå¦‚æœ`temperature`è®¾ä¸º0ï¼Œæ¨¡å‹å°†æ€»æ˜¯é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„è¯ï¼Œè¿™ä½¿å¾—æ¯æ¬¡ç”Ÿæˆçš„ç»“æœéƒ½éå¸¸ç›¸ä¼¼æˆ–ç›¸åŒã€‚
> 2. **é«˜ `temperature` å€¼ï¼ˆæ¥è¿‘1ï¼‰**ï¼š
> 	- **æ›´éšæœºæ€§**ï¼šæ¨¡å‹åœ¨é€‰æ‹©è¯æ—¶è€ƒè™‘æ›´å¤šçš„å¯èƒ½æ€§ï¼Œå› æ­¤ç”Ÿæˆçš„æ–‡æœ¬æ›´å…·åˆ›æ„å’Œå¤šæ ·æ€§ï¼Œä½†ä¹Ÿå¯èƒ½å‡ºç°è¯­ä¹‰ä¸Šä¸è¿è´¯æˆ–ä¸åˆé€»è¾‘çš„å†…å®¹ã€‚
> 	- **ç¤ºä¾‹**ï¼šå¦‚æœ`temperature`è®¾ä¸º1ï¼Œæ¨¡å‹åœ¨ç”Ÿæˆæ–‡æœ¬æ—¶ä¼šæœ‰æ›´å¤šçš„è‡ªç”±åº¦ï¼Œé€‰æ‹©æ¦‚ç‡è¾ƒä½çš„è¯çš„æœºä¼šå¢åŠ ï¼Œä»è€Œç”Ÿæˆæ›´å…·åˆ›æ„çš„æ–‡æœ¬ã€‚
> 3. **ä¸­ç­‰ `temperature` å€¼ï¼ˆå¦‚0.7ï¼‰**ï¼š
> 	- **å¹³è¡¡æ€§**ï¼šæ—¢æœ‰ä¸€å®šçš„éšæœºæ€§æ¥ç”Ÿæˆå¤šæ ·åŒ–çš„å†…å®¹ï¼ŒåŒæ—¶ä¹Ÿä¿æŒä¸€å®šçš„è¿è´¯æ€§å’Œé€»è¾‘æ€§ã€‚
> 	- **ç¤ºä¾‹**ï¼šå¾ˆå¤šæƒ…å†µä¸‹ï¼Œè®¾å®š`temperature`ä¸º0.7æ˜¯ä¸€ä¸ªè¾ƒå¥½çš„é€‰æ‹©ï¼Œå¯ä»¥åœ¨ç”Ÿæˆè¿è´¯æ€§å’Œåˆ›æ„ä¹‹é—´æ‰¾åˆ°å¹³è¡¡ã€‚

æ‰€ä»¥æˆ‘åœ¨è¿™ä¸€è¡Œä¸Š,å¯¹`temperature`è®¾ç½®äº†ä¸€ä¸ªå‚æ•°,è®©è¯­è¨€æ¨¡å‹ä¸¥æ ¼çš„æŒ‰ç…§æˆ‘ä»¬çš„éœ€æ±‚è¾“å‡º

`llm=Tongyi(temperature=0)`

ç»“æœå¦‚å›¾

![](./image/1.7.png)

OK,åˆ°è¿™é‡Œçš„è¯,æˆ‘ä»¬çš„ç¯å¢ƒæµ‹è¯•ä¹‹ç±»çš„,éƒ½æ²¡æœ‰é—®é¢˜äº†

But,æˆ‘ä»¬çŸ¥é“åœ¨ä»¥åçš„ç”Ÿäº§ç¯å¢ƒä¸­ä¸€å®šä¸èƒ½ç”¨ä¸Šè¿™ç§å½¢å¼çš„OutPrintf

æˆ‘ä»¬è¦å¾—åˆ°çš„,æ˜¯é‡Œé¢çš„æ•°æ®,æ•°æ®é‚£ç”¨æ•°ç»„å»å­˜å‚¨

è¿™é‡Œéœ€è¦ç”¨ä¸Š`Python`çš„ä¸€äº›ç›¸å…³çŸ¥è¯†

```python
# é¦–å…ˆçš„è¯
# éœ€è¦å¯¼å…¥Pythonä¸­ä¸€ä¸ªè¾“å‡ºçš„åŸºæœ¬ç±»BaseOutputParser
# å¯¼å…¥åˆ°langchainä¸­
from langchain.schema import BaseOutputParser
# è‡ªå®šä¹‰ç±»
# ç»§æ‰¿äº†BaseOutputParser
# é‡å†™äº†parseæ–¹æ³•
class CommaSeparatedListOutputParser(BaseOutputParser):
    def parse(self, text: str) -> str:
        # è¾“å‡ºç»“æœ strip()å»é™¤ç©ºæ ¼
        # split()åˆ†å‰²å­—ç¬¦ä¸²
        return text.strip().split(", ")
    
CommaSeparatedListOutputParser().parse("apple, banana, cherry")
```

```text
Output:['apple', 'banana', 'cherry']
```

è§£é‡Šå¦‚ä¸‹

è¿™é‡Œ,å…ˆå¯¼å…¥Pythonçš„ä¸€ä¸ªè¾“å‡ºçš„åŸºæœ¬ç±»`BaseOutputPaser`

>`BaseOutputParser` æ˜¯ä¸€ä¸ªåŸºç¡€ç±»ï¼Œç”¨äºè§£æè¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆçš„è¾“å‡ºã€‚åœ¨ä½¿ç”¨ LLM æ—¶ï¼Œæ¨¡å‹ç”Ÿæˆçš„åŸå§‹è¾“å‡ºå¯èƒ½éœ€è¦è¿›ä¸€æ­¥å¤„ç†æ‰èƒ½æ»¡è¶³ç‰¹å®šéœ€æ±‚ã€‚`BaseOutputParser` æä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„æ¥å£æ¥å®ç°è¿™ç§å¤„ç†ã€‚
>
>åœ¨ LangChain ä¸­ï¼Œ`BaseOutputParser` ç±»çš„ä¸»è¦ç”¨é€”æ˜¯å®šä¹‰ä¸€ç§æ–¹æ³•ï¼Œå°† LLM çš„åŸå§‹è¾“å‡ºè½¬æ¢ä¸ºç”¨æˆ·éœ€è¦çš„æ ¼å¼ã€‚è¿™ç§æ–¹æ³•çš„å®ç°å¯ä»¥æ˜¯å¤šç§å¤šæ ·çš„ï¼Œä¾‹å¦‚æå–ç‰¹å®šä¿¡æ¯ã€æ ¼å¼åŒ–è¾“å‡ºã€åˆ†å‰²å­—ç¬¦ä¸²ç­‰ã€‚
>
>### `BaseOutputParser` çš„ä¸»è¦æ–¹æ³•
>
>- **`parse(self, text: str)`**ï¼šè¿™æ˜¯ä¸€ä¸ªæŠ½è±¡æ–¹æ³•ï¼Œéœ€è¦åœ¨å­ç±»ä¸­å®ç°ã€‚å®ƒæ¥å—ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ˆæ¨¡å‹ç”Ÿæˆçš„åŸå§‹è¾“å‡ºï¼‰ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›è§£æåçš„ç»“æœã€‚

ç„¶åæ¥å®ç°æˆ‘ä»¬æœ€ç»ˆçš„ç›®çš„

```python
# èµ·åå¤§å¸ˆ
# å¯¼å…¥ç›¸å…³åŒ…
import os
from dotenv import find_dotenv, load_dotenv
load_dotenv(find_dotenv())
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY")
from langchain_community.llms import Tongyi
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.schema import BaseOutputParser

# è‡ªå®šä¹‰ç±»
class CommaSeparatedListOutputParser(BaseOutputParser):
    def parse(self, text: str):
        # return text.strip().split(", ")
        return [item.strip() for item in text.strip().split(",")]

llm = Tongyi(
    temperature=0,
    openai_api_key=DASHSCOPE_API_KEY
)

template = '''
ä½ æ˜¯ä¸€ä¸ªèµ·åå¤§å¸ˆ,è¯·æ¨¡ä»¿ç¤ºä¾‹èµ·3ä¸ª{county}åå­—,æ¯”å¦‚ç”·å­©ç»å¸¸è¢«å«åš{boy},å¥³å­©ç»å¸¸è¢«å«åš{girl},è¯·è¿”å›ä»¥é€—å·åˆ†éš”çš„åˆ—è¡¨å½¢å¼ã€‚ä»…è¿”å›é€—å·åˆ†éš”çš„åˆ—è¡¨ï¼Œä¸è¦è¿”å›å…¶ä»–å†…å®¹ã€‚
'''
prompt = PromptTemplate(
    template=template,
    input_variables=["county", "boy", "girl"]
)

# è®¾ç½®è§£æå™¨
parser = CommaSeparatedListOutputParser()

# å°† LLM ä¸ Prompt å’Œè§£æå™¨è¿æ¥èµ·æ¥
chain = LLMChain(
    llm=llm,
    prompt=prompt,
    output_parser=parser
)

# ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
county = "ä¸­å›½ç‰¹è‰²çš„"
boy = "ç‹—è›‹"
girl = "ç¿ èŠ±"

# æ ¼å¼åŒ–æ¶ˆæ¯
message = prompt.format(county=county, boy=boy, girl=girl)

# è¿è¡Œå¹¶æ‰“å°ç»“æœ
res = chain.invoke({"county": county, "boy": boy, "girl": girl})
print(res)  # åº”è¯¥è¾“å‡ºä¸€ä¸ªåˆ—è¡¨

# å°è¯•æ‰“å°message
print(message)

# ç›´æ¥è°ƒç”¨llmçš„é¢„æµ‹
strs = llm.predict(message)
parsed_output = parser.parse(strs)
print(parsed_output)
```

![](./image/1.8.png)

é‚£ä¹ˆ,ç¬¬ä¸€ç« å°±åˆ°è¿™é‡Œ,æœ‰é—®é¢˜çš„å¯ä»¥åœ¨ä¸‹é¢çš„è¯„è®ºåŒºè¯„è®º,æˆ‘çœ‹åä¼šå°½åŠ›å¸®ä½ è§£å†³.

ç„¶å,è¿™ä¸ªæ–‡ç« å°šæœªå®Œç»“,åé¢å‘ç°æœ‰ä»€ä¹ˆé—®é¢˜ä¼šè¿›è¡Œè¡¥å…….

