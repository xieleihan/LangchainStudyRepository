# Langchain

ä½œè€…:`@xieleihan`[ç‚¹å‡»è®¿é—®](https://github.com/xieleihan)

æœ¬æ–‡éµå®ˆGPL3.0å¼€æºåè®®

# å®ç°ä¸€ä¸ªèŠå¤©æœºå™¨äºº

## Agents

#### ä»‹ç»

> ![](./image/4.1.png)

- æ— éœ€ä¸ºä¸åŒä»»åŠ¡ä½¿ç”¨å•ç‹¬è½¯ä»¶
- ä½¿ç”¨æ—¥å¸¸è¯­è¨€æ¥å‘½ä»¤ä½ çš„è®¾å¤‡
- ä»£ç†æ˜¯äººå·¥æ™ºèƒ½çš„é«˜çº§å½¢å¼
- æœªæ¥äº”å¹´å°†æˆä¸ºç°å®
- äººäººéƒ½æœ‰çš„ç§äººåŠ©ç†Agnet
- åº”ç”¨åœ¨åƒè¡Œç™¾ä¸šä¹‹ä¸­(åŒ»ç–—,æ•™è‚²,å¨±ä¹...)
- ç”Ÿäº§åŠ›çš„æ”¹å˜
- ç»§PC,IOS,Androidåä¸‹ä¸€ä¸ªå¹³å° 

![](./image/4.2.png)

## Langchainä¸­çš„Agentså¦‚ä½•å®ç°

1. æå‡ºéœ€æ±‚
2. é—®é¢˜+promptç»„åˆ
3. React Loop
4. æŸ¥æ‰¾Memory
5. æŸ¥æ‰¾å¯ç”¨å·¥å…·
6. æ‰§è¡Œå·¥å…·å¹¶è§‚å¯Ÿç»“æœ
7. å¾—åˆ°æœ€ç»ˆçš„ç»“æœ

### å®ç°ä¸€ä¸ªæœ€ç®€å•çš„Agents

#### è®¾è®¡ä¸¤ä¸ªä»»åŠ¡

- ä¼šåšæ•°å­¦é¢˜
- ä¸çŸ¥é“ç­”æ¡ˆçš„æ—¶å€™å¯ä»¥æœç´¢

#### å®ç°

```python
# å¯¼å…¥æ¨¡å—
from dotenv import find_dotenv, load_dotenv
import os
# åŠ è½½ API key
load_dotenv(find_dotenv())
api_key = os.getenv("DASHSCOPE_API_KEY")

# é¦–å…ˆä¾æ—§å¯¼å…¥æ¨¡å—
from langchain_community.chat_models import ChatTongyi
import os

llm = ChatTongyi(
    dashscope_api_key = api_key,
    model = "Qwen-max",
    temperature = 0
)

# æ­å»ºå·¥å…·
# æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªå·¥å…·,serpaiæ˜¯ä¸€ä¸ªèšåˆæœç´¢å¼•æ“,éœ€è¦å®‰è£…è°·æ­Œæœç´¢åŒ…å’Œç”³è¯·apikey
# https://serpapi.com/dashboard
# llm-math æ˜¯ä¸€ä¸ªå°è£…å¥½çš„æ•°å­¦è®¡ç®—é“¾
# é¦–å…ˆæˆ‘ä»¬éœ€è¦å®‰è£…è°·æ­Œæœç´¢åŒ…
```

```python
! pip install google-search-results
```

```python
# å¯¼å…¥æ¨¡å—
from dotenv import find_dotenv, load_dotenv
import os
# åŠ è½½ API key
load_dotenv(find_dotenv())
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")

# é¦–å…ˆä¾æ—§å¯¼å…¥æ¨¡å—
from langchain_community.chat_models import ChatTongyi
import os

llm = ChatTongyi(
    dashscope_api_key = dashscope_api_key,
    model = "qwen-vl-max",
    temperature = 0
)

from langchain.agents import load_tools
# æ­å»ºå·¥å…·
tools = load_tools(
    ["serpapi", "llm-math"],
    llm=llm,
    serpapi_api_key=serpapi_api_key
)

# å®šä¹‰agentsä½¿ç”¨å°æ ·æœ¬å¢å¼º
from langchain.agents import initialize_agent
from langchain.agents import AgentType

# å®šä¹‰å·¥å…·
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,# è¿™é‡Œæœ‰ä¸åŒçš„ç±»å‹
    verbose=True
)

agent.run("è‹±å›½å‰ä»»å¥³ç‹çš„åå­—å«ä»€ä¹ˆ,å¥¹çš„å¹´é¾„çš„å¹³æ–¹æ˜¯å¤šå°‘?")
```

![](./image/4.3.png)

### å‡ ç§å†…ç½®çš„ä¸»è¦Agentç±»å‹

- openai_functions OpenAIå‡½æ•°è°ƒç”¨å‹
- zero_short_react_description é›¶æ ·æœ¬å¢å¼ºç”Ÿæˆå‹
- chat_zero_shot_react_description é›¶æ ·æœ¬å¢å¼ºå¯¹è¯å‹
- conversational_react_description å¯¹è¯å¢å¼ºç”Ÿæˆå‹
- chat_conversational_react_description å¯¹è¯å¢å¼ºç»“æ„åŒ–
- structued_chat_zero_short_react_description é›¶æ ·æœ¬å¢å¼ºç»“æ„åŒ–å¯¹è¯å‹

#### ZERO_SHOT_REACT_DESCRIPTION

é›¶æ ·æœ¬å¢å¼ºç”Ÿæˆ,æ—¢åœ¨æ²¡æœ‰ç¤ºä¾‹çš„æƒ…å†µä¸‹,å¯ä»¥è‡ªä¸»è¿›è¡Œå¯¹è¯çš„ç±»å‹[é›¶æ ·æœ¬,å•æ ·æœ¬,å°‘æ ·æœ¬](https://blog.csdn.net/zcyzcyjava/article/details/127006287)

```python
from langchain.llms import Tongyi
from langchain.agents import (
    load_tools,
    initialize_agent,
    AgentType
)
import os
from dotenv import find_dotenv, load_dotenv
import os
# åŠ è½½ API key
load_dotenv(find_dotenv())
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")

llm = Tongyi(
    dashscope_api_key = dashscope_api_key,
    model = 'Qwen-max',
    temperature =0
)

tools = load_tools(["serpapi", "llm-math"], llm=llm, serpapi_api_key=serpapi_api_key)
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

agent.run('ä¸Šä¸€ä»»æ–°è¥¿å…°å¥³ç‹æ˜¯è°?å¥¹å¹´é¾„é™¤ä»¥2æ˜¯å¤šå°‘?')
```

![](./image/4.4.png)

#### CHAT_ZERO_SHOT_REACT_DESCRIPTION

å…¶å®è·Ÿä¸Šé¢çš„æ²¡ä»€ä¹ˆåŒºåˆ«,ä¸»è¦æ˜¯æŠŠ`llm`æ¢æˆäº†`chatModel`

```python
# from langchain.llms import Tongyi
from langchain_community.chat_models import ChatTongyi
from langchain.agents import (
    load_tools,
    initialize_agent,
    AgentType
)
import os
from dotenv import find_dotenv, load_dotenv
import os
# åŠ è½½ API key
load_dotenv(find_dotenv())
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")

llm = ChatTongyi(
    dashscope_api_key = dashscope_api_key,
    model_name = 'qwen-vl-max',
    temperature =0
)

tools = load_tools(["serpapi", "llm-math"], llm=llm, serpapi_api_key=serpapi_api_key)
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

agent.run('ä¸–ç•Œç¬¬ä¸‰ææ˜¯ä»€ä¹ˆ?å®ƒçš„é«˜åº¦ä¹˜2æ˜¯å¤šå°‘?')
```

![](./image/4.5.png)

#### CONVERSATIONAL_REACT_DESCRIPTION

ä¸€ä¸ªå¯¹è¯å‹çš„agent,è¿™ä¸ªagentè¦æ±‚ä¸memoryä¸€èµ·ä½¿ç”¨

```python
from langchain.llms import Tongyi
from langchain.agents import(
    load_tools,
    initialize_agent,
    AgentType
)
from langchain.memory import ConversationBufferMemory
import os
from dotenv import find_dotenv, load_dotenv
# åŠ è½½ API key
load_dotenv(find_dotenv())
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")

# è®°å¿†ç»„ä»¶
memory = ConversationBufferMemory(
    memory_key="chat_history"
)

llm = Tongyi(
    dashscope_api_key = dashscope_api_key,
    model = "Qwen-max",
    temperature = 0,
)

tools = load_tools(["serpapi", "llm-math"], llm=llm, serpapi_api_key=serpapi_api_key)
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
    verbose=True,
    memory=memory # è®°å¿†ç»„ä»¶
)

print(agent)
# çœ‹ä¸‹æ¨¡ç‰ˆ
print(agent.agent.llm_chain.prompt.template)
```

æˆ‘ä»¬æ¥çœ‹ä¸‹æ¨¡ç‰ˆæç¤ºè¯

````text
memory=ConversationBufferMemory(memory_key='chat_history') verbose=True tags=['conversational-react-description'] agent=ConversationalAgent(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input'], template='Assistant is a large language model trained by OpenAI.\n\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n\nOverall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n\nTOOLS:\n------\n\nAssistant has access to the following tools:\n\n> Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n> Calculator: Useful for when you need to answer questions about math.\n\nTo use a tool, please use the following format:\n\n```\nThought: Do I need to use a tool? Yes\nAction: the action to take, should be one of [Search, Calculator]\nAction Input: the input to the action\nObservation: the result of the action\n```\n\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n\n```\nThought: Do I need to use a tool? No\nAI: [your response here]\n```\n\nBegin!\n\nPrevious conversation history:\n{chat_history}\n\nNew input: {input}\n{agent_scratchpad}'), llm=Tongyi(client=<class 'dashscope.aigc.generation.Generation'>, dashscope_api_key='sk-2a9e44d9621f4fd1b5f9f2c081779215')), output_parser=ConvoOutputParser(), allowed_tools=['Search', 'Calculator'], ai_prefix='AI') tools=[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>), Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\'s numexpr library. Use the output of running this code to answer the question.\n\nQuestion: ${{Question with math problem.}}\n```text\n${{single line mathematical expression that solves the problem}}\n```\n...numexpr.evaluate(text)...\n```output\n${{Output of running the code}}\n```\nAnswer: ${{Answer}}\n\nBegin.\n\nQuestion: What is 37593 * 67?\n```text\n37593 * 67\n```\n...numexpr.evaluate("37593 * 67")...\n```output\n2518731\n```\nAnswer: 2518731\n\nQuestion: 37593^(1/5)\n```text\n37593**(1/5)\n```\n...numexpr.evaluate("37593**(1/5)")...\n```output\n8.222831614237718\n```\nAnswer: 8.222831614237718\n\nQuestion: {question}\n'), llm=Tongyi(client=<class 'dashscope.aigc.generation.Generation'>, dashscope_api_key='sk-2a9e44d9621f4fd1b5f9f2c081779215')))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\'s numexpr library. Use the output of running this code to answer the question.\n\nQuestion: ${{Question with math problem.}}\n```text\n${{single line mathematical expression that solves the problem}}\n```\n...numexpr.evaluate(text)...\n```output\n${{Output of running the code}}\n```\nAnswer: ${{Answer}}\n\nBegin.\n\nQuestion: What is 37593 * 67?\n```text\n37593 * 67\n```\n...numexpr.evaluate("37593 * 67")...\n```output\n2518731\n```\nAnswer: 2518731\n\nQuestion: 37593^(1/5)\n```text\n37593**(1/5)\n```\n...numexpr.evaluate("37593**(1/5)")...\n```output\n8.222831614237718\n```\nAnswer: 8.222831614237718\n\nQuestion: {question}\n'), llm=Tongyi(client=<class 'dashscope.aigc.generation.Generation'>, dashscope_api_key='sk-2a9e44d9621f4fd1b5f9f2c081779215')))>)]
Assistant is a large language model trained by OpenAI.

Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.

Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.

Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.

TOOLS:
------

Assistant has access to the following tools:

> Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.
> Calculator: Useful for when you need to answer questions about math.

To use a tool, please use the following format:

```
Thought: Do I need to use a tool? Yes
Action: the action to take, should be one of [Search, Calculator]
Action Input: the input to the action
Observation: the result of the action
```

When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:

```
Thought: Do I need to use a tool? No
AI: [your response here]
```

Begin!

Previous conversation history:
{chat_history}

New input: {input}
{agent_scratchpad}

````

OK,è®©æˆ‘ä»¬æå‡ºé—®é¢˜,é—®ç­”AI

```python
agent.run("hi, i am SouthAki,what is your name?")
```

![](./image/4.6.png)

```python
agent.run("é¦™æ¸¯æœ‰å“ªé‡Œæ¯”è¾ƒå¥½ç©çš„å—?")
```

![](./image/4.7.png)

```python
agent.run("æˆ‘è¿˜æ²¡ç©è¿‡,ä½ çŸ¥é“æˆ‘åå­—åä¸‰ä¸ªå­—æ¯æ˜¯ä»€ä¹ˆå—?")
```

![](./image/4.8.png)

```python
agent.run("ä¸­å›½å¹¿ä¸œçœå¹¿å·å¸‚ç°åœ¨çš„æ°”æ¸©æ˜¯å¤šå°‘æ¥ç€?")
```

![](./image/4.9.png)

```python
agent.run("æˆªæ­¢åˆ°ç°åœ¨æˆ‘ä»¬é—®äº†å¤šå°‘é—®é¢˜?")
```

![](./image/4.10.png)

#### CHAT_CONVERSATIONAL_REACT_DESCRIPTION

è·Ÿä¸Šé¢ä¸€æ ·å·®ä¸å¤š

```python
from langchain_community.chat_models import ChatTongyi
from langchain.agents import(
    load_tools,
    initialize_agent,
    AgentType
)
from langchain.memory import ConversationBufferMemory
import os
from dotenv import find_dotenv, load_dotenv
# åŠ è½½ API key
load_dotenv(find_dotenv())
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")

# è®°å¿†ç»„ä»¶
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages= True
)

llm = ChatTongyi(
    dashscope_api_key = dashscope_api_key,
    model_name = "qwen-vl-max",
    temperature = 0,
)

tools = load_tools(["serpapi", "llm-math"], llm=llm, serpapi_api_key=serpapi_api_key)
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,
    verbose=True,
    memory=memory # è®°å¿†ç»„ä»¶
)

print(agent)
# çœ‹ä¸‹æ¨¡ç‰ˆ
print(agent.agent.llm_chain.prompt.template)
```

æ¥çœ‹çœ‹é—®é¢˜çš„ç­”æ¡ˆå§

```python
agent.run("hi, i am å—ç§‹SouthAki,what is your name?")
```

![](./image/4.11.png)

```python
agent.run("é¦™æ¸¯æœ‰ä»€ä¹ˆæ¯”è¾ƒå¥½åƒçš„ç¾é£Ÿ?")
```

![](./image/4.12.png)

```python
agent.run("æˆ‘è¿˜æ²¡åƒè¿‡,ä¸è¿‡ä½ è¿˜çŸ¥é“æˆ‘åå­—çš„æœ€åä¸€ä¸ªå­—æ¯æ˜¯ä»€ä¹ˆå—?ä¸­å›½æ¾³é—¨ç°åœ¨çš„æ°”æ¸©æ˜¯å¤šå°‘æ¥ç€?")
```

![](./image/4.13.png)

```python
agent.run("æˆªæ­¢åˆ°ç°åœ¨æˆ‘ä»¬é—®äº†å¤šå°‘é—®é¢˜?")
```

![](./image/4.14.png)

> ğŸš§:æ¥ä¸‹æ¥,æˆ‘ä»¬æ¥è®²ä¸€ä¸‹openai_functions ä½¿ç”¨åˆ°äº†openaiçš„å‡½æ•°è°ƒç”¨æ¥å®ç°çš„,åªæ”¯æŒOpenAIæ¨¡å‹
>
> æ‰€ä»¥ä¸‹é¢çš„æ¼”ç¤º,æˆ‘ç›´æ¥ä»¥ä»£ç çš„å½¢å¼è®²è§£,ä¸ä¼šå»è¿è¡Œ

#### OPENAI_FUNCTIONS

```python
# å¯¼å…¥æ¨¡å—
from langchain.chat_models import ChatOpenAI
from langchain.agents import(
    load_tools,
    initialize_agent,
    AgentType
)
from langchain.memory import ConversationBufferMemory
import os

os.environ["OPENAI_API_KEY"] = "sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
os.environ["SERPAPI_API_KEY"] = ""

# è®°å¿†ç»„ä»¶
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)

llm = ChatOpenAI(
    temperature = 0,
    model = 'gpt-4-0613'
)
tools = load_tools(
    ["serpapi", "llm-math"],
    llm = llm
)
agent = initialize_agent(
    tools = tools,
    llm = llm,
    agent = AgentType.OPENAI_FUNCTIONS,
    verbose = True,
    memory = memory
)
print(agent)
print(agent.agent.prompt.messages)

# ç„¶ååç»­åªéœ€è¦è¿è¡Œagent.run(input = ""),å°±è¡Œ
```

#### STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION

å¯¹è¾“å‡ºçš„ç»“æ„åŒ–å¤„ç†

```python
from langchain_community.chat_models import ChatTongyi
from langchain.agents import(
    load_tools,
    initialize_agent,
    AgentType
)
from langchain.memory import ConversationBufferMemory
import os
from dotenv import find_dotenv, load_dotenv
# åŠ è½½ API key
load_dotenv(find_dotenv())
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")

# è®°å¿†ç»„ä»¶
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages= True
)

llm = ChatTongyi(
    dashscope_api_key = dashscope_api_key,
    model_name = "qwen-vl-max",
    temperature = 0,
)

tools = load_tools(["serpapi", "llm-math"], llm=llm, serpapi_api_key=serpapi_api_key)
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True,
    memory=memory # è®°å¿†ç»„ä»¶
)

print(agent)
# çœ‹ä¸‹æ¨¡ç‰ˆ
print(agent.agent.llm_chain.prompt.messages[0].prompt.template)
```

å¯ä»¥çœ‹ä¸‹æç¤ºè¯æ¨¡ç‰ˆ

````text
memory=ConversationBufferMemory(return_messages=True, memory_key='chat_history') verbose=True tags=['structured-chat-zero-shot-react-description'] agent=StructuredChatAgent(llm_chain=LLMChain(prompt=ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n\nSearch: A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {{\'tool_input\': {{\'type\': \'string\'}}}}\nCalculator: Useful for when you need to answer questions about math., args: {{\'tool_input\': {{\'type\': \'string\'}}}}\n\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n\nValid "action" values: "Final Answer" or Search, Calculator\n\nProvide only ONE action per $JSON_BLOB, as shown:\n\n```\n{{\n  "action": $TOOL_NAME,\n  "action_input": $INPUT\n}}\n```\n\nFollow this format:\n\nQuestion: input question to answer\nThought: consider previous and subsequent steps\nAction:\n```\n$JSON_BLOB\n```\nObservation: action result\n... (repeat Thought/Action/Observation N times)\nThought: I know what to respond\nAction:\n```\n{{\n  "action": "Final Answer",\n  "action_input": "Final response to human"\n}}\n```\n\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\nThought:')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], template='{input}\n\n{agent_scratchpad}'))]), llm=ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********'))), output_parser=StructuredChatOutputParserWithRetries(output_fixing_parser=OutputFixingParser(parser=StructuredChatOutputParser(), retry_chain=PromptTemplate(input_variables=['completion', 'error', 'instructions'], template='Instructions:\n--------------\n{instructions}\n--------------\nCompletion:\n--------------\n{completion}\n--------------\n\nAbove, the Completion did not satisfy the constraints given in the Instructions.\nError:\n--------------\n{error}\n--------------\n\nPlease try again. Please only respond with an answer that satisfies the constraints laid out in the Instructions:')
| ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********')))), allowed_tools=['Search', 'Calculator']) tools=[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>), Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\'s numexpr library. Use the output of running this code to answer the question.\n\nQuestion: ${{Question with math problem.}}\n```text\n${{single line mathematical expression that solves the problem}}\n```\n...numexpr.evaluate(text)...\n```output\n${{Output of running the code}}\n```\nAnswer: ${{Answer}}\n\nBegin.\n\nQuestion: What is 37593 * 67?\n```text\n37593 * 67\n```\n...numexpr.evaluate("37593 * 67")...\n```output\n2518731\n```\nAnswer: 2518731\n\nQuestion: 37593^(1/5)\n```text\n37593**(1/5)\n```\n...numexpr.evaluate("37593**(1/5)")...\n```output\n8.222831614237718\n```\nAnswer: 8.222831614237718\n\nQuestion: {question}\n'), llm=ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********'))))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\'s numexpr library. Use the output of running this code to answer the question.\n\nQuestion: ${{Question with math problem.}}\n```text\n${{single line mathematical expression that solves the problem}}\n```\n...numexpr.evaluate(text)...\n```output\n${{Output of running the code}}\n```\nAnswer: ${{Answer}}\n\nBegin.\n\nQuestion: What is 37593 * 67?\n```text\n37593 * 67\n```\n...numexpr.evaluate("37593 * 67")...\n```output\n2518731\n```\nAnswer: 2518731\n\nQuestion: 37593^(1/5)\n```text\n37593**(1/5)\n```\n...numexpr.evaluate("37593**(1/5)")...\n```output\n8.222831614237718\n```\nAnswer: 8.222831614237718\n\nQuestion: {question}\n'), llm=ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********'))))>)]
Respond to the human as helpfully and accurately as possible. You have access to the following tools:

Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {{'tool_input': {{'type': 'string'}}}}
Calculator: Useful for when you need to answer questions about math., args: {{'tool_input': {{'type': 'string'}}}}

Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).

Valid "action" values: "Final Answer" or Search, Calculator

Provide only ONE action per $JSON_BLOB, as shown:

```
{{
  "action": $TOOL_NAME,
  "action_input": $INPUT
}}
```

Follow this format:

Question: input question to answer
Thought: consider previous and subsequent steps
Action:
```
$JSON_BLOB
```
Observation: action result
... (repeat Thought/Action/Observation N times)
Thought: I know what to respond
Action:
```
{{
  "action": "Final Answer",
  "action_input": "Final response to human"
}}
```

Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.
Thought:

````

æå‡ºé—®ç­”è¯•è¯•

```python
agent.invoke({"input":"what is langchain?"})
```

![](./image/4.15.png)

### å®ç°åŸç†

å¦‚ä½•ç»™Agentæ­£ç¡®çš„æ·»åŠ Memory

- å°†memoryæ’å…¥æç¤ºè¯æ¨¡ç‰ˆé‡Œ
- æ·»åŠ memoryç»„ä»¶
- å®šä¹‰agent

ç»™å‡ºç¤ºä¾‹:

```python
# å¯¼å…¥æ¨¡å—
from langchain.agents import (
    load_agent,
    initialize_agent,
    AgentType,
    Tool,
    load_tools
)
from langchain.memory import ConversationBufferMemory
from langchain_community.chat_models import ChatTongyi
from langchain.utilities import SerpAPIWrapper
from langchain.prompts import MessagesPlaceholder
from langchain.chains import LLMMathChain
import os
from dotenv import find_dotenv, load_dotenv
# åŠ è½½ API key
load_dotenv(find_dotenv())
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")

# å®šä¹‰å¤§æ¨¡å‹
llm = ChatTongyi(
    model_name= 'qwen-vl-max',
    temperature= 0,
    dashscope_api_key = dashscope_api_key
)
# åŠ è½½å·¥å…·
tools = load_tools(["serpapi", "llm-math"], llm=llm, serpapi_api_key=serpapi_api_key)
print(tools)
```

è¾“å‡ºçš„ç»“æœæ˜¯è¿™æ ·çš„

```text
[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>), Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\'s numexpr library. Use the output of running this code to answer the question.\n\nQuestion: ${{Question with math problem.}}\n```text\n${{single line mathematical expression that solves the problem}}\n```\n...numexpr.evaluate(text)...\n```output\n${{Output of running the code}}\n```\nAnswer: ${{Answer}}\n\nBegin.\n\nQuestion: What is 37593 * 67?\n```text\n37593 * 67\n```\n...numexpr.evaluate("37593 * 67")...\n```output\n2518731\n```\nAnswer: 2518731\n\nQuestion: 37593^(1/5)\n```text\n37593**(1/5)\n```\n...numexpr.evaluate("37593**(1/5)")...\n```output\n8.222831614237718\n```\nAnswer: 8.222831614237718\n\nQuestion: {question}\n'), llm=ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********'))))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\'s numexpr library. Use the output of running this code to answer the question.\n\nQuestion: ${{Question with math problem.}}\n```text\n${{single line mathematical expression that solves the problem}}\n```\n...numexpr.evaluate(text)...\n```output\n${{Output of running the code}}\n```\nAnswer: ${{Answer}}\n\nBegin.\n\nQuestion: What is 37593 * 67?\n```text\n37593 * 67\n```\n...numexpr.evaluate("37593 * 67")...\n```output\n2518731\n```\nAnswer: 2518731\n\nQuestion: 37593^(1/5)\n```text\n37593**(1/5)\n```\n...numexpr.evaluate("37593**(1/5)")...\n```output\n8.222831614237718\n```\nAnswer: 8.222831614237718\n\nQuestion: {question}\n'), llm=ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********'))))>)]

```

ç„¶åæˆ‘ä»¬æ·»åŠ `Memory`ç»„ä»¶

```python
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)
```

å®šä¹‰`agent`

```python
agent_chain = initialize_agent(
    tools,
    llm,
    agent = AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,
    verbose = True,
    memory = memory
)
```

æ‰“å°ä¸€ä¸‹è¿™ä¸ª`agent_chain`æ˜¯ä»€ä¹ˆå†…å®¹çœ‹çœ‹

```python
print(agent_chain)
```

è¾“å‡ºç»“æœæ˜¯è¿™æ ·çš„

```text
memory=ConversationBufferMemory(return_messages=True, memory_key='chat_history') verbose=True tags=['chat-conversational-react-description'] agent=ConversationalChatAgent(llm_chain=LLMChain(prompt=ChatPromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Assistant is a large language model trained by OpenAI.\n\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='TOOLS\n------\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n\n> Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n> Calculator: Useful for when you need to answer questions about math.\n\nRESPONSE FORMAT INSTRUCTIONS\n----------------------------\n\nWhen responding to me, please output a response in one of two formats:\n\n**Option 1:**\nUse this if you want the human to use a tool.\nMarkdown code snippet formatted in the following schema:\n\n```json\n{{\n    "action": string, \\\\ The action to take. Must be one of Search, Calculator\n    "action_input": string \\\\ The input to the action\n}}\n```\n\n**Option #2:**\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\n\n```json\n{{\n    "action": "Final Answer",\n    "action_input": string \\\\ You should put what you want to return to use here\n}}\n```\n\nUSER\'S INPUT\n--------------------\nHere is the user\'s input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\n\n{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')]), llm=ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********'))), output_parser=ConvoOutputParser(), allowed_tools=['Search', 'Calculator'], template_tool_response="TOOL RESPONSE: \n---------------------\n{observation}\n\nUSER'S INPUT\n--------------------\n\nOkay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.") tools=[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>), Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\'s numexpr library. Use the output of running this code to answer the question.\n\nQuestion: ${{Question with math problem.}}\n```text\n${{single line mathematical expression that solves the problem}}\n```\n...numexpr.evaluate(text)...\n```output\n${{Output of running the code}}\n```\nAnswer: ${{Answer}}\n\nBegin.\n\nQuestion: What is 37593 * 67?\n```text\n37593 * 67\n```\n...numexpr.evaluate("37593 * 67")...\n```output\n2518731\n```\nAnswer: 2518731\n\nQuestion: 37593^(1/5)\n```text\n37593**(1/5)\n```\n...numexpr.evaluate("37593**(1/5)")...\n```output\n8.222831614237718\n```\nAnswer: 8.222831614237718\n\nQuestion: {question}\n'), llm=ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********'))))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\'s numexpr library. Use the output of running this code to answer the question.\n\nQuestion: ${{Question with math problem.}}\n```text\n${{single line mathematical expression that solves the problem}}\n```\n...numexpr.evaluate(text)...\n```output\n${{Output of running the code}}\n```\nAnswer: ${{Answer}}\n\nBegin.\n\nQuestion: What is 37593 * 67?\n```text\n37593 * 67\n```\n...numexpr.evaluate("37593 * 67")...\n```output\n2518731\n```\nAnswer: 2518731\n\nQuestion: 37593^(1/5)\n```text\n37593**(1/5)\n```\n...numexpr.evaluate("37593**(1/5)")...\n```output\n8.222831614237718\n```\nAnswer: 8.222831614237718\n\nQuestion: {question}\n'), llm=ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********'))))>)]

```

å†æ¯”å¦‚æˆ‘ä»¬æƒ³çœ‹åˆ°æ¨¡ç‰ˆçš„å†…å®¹

```python
print(agent_chain.agent.llm_chain.prompt.messages)
```

```text
[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n\nSearch: A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {{\'tool_input\': {{\'type\': \'string\'}}}}\nCalculator: Useful for when you need to answer questions about math., args: {{\'tool_input\': {{\'type\': \'string\'}}}}\n\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n\nValid "action" values: "Final Answer" or Search, Calculator\n\nProvide only ONE action per $JSON_BLOB, as shown:\n\n```\n{{\n  "action": $TOOL_NAME,\n  "action_input": $INPUT\n}}\n```\n\nFollow this format:\n\nQuestion: input question to answer\nThought: consider previous and subsequent steps\nAction:\n```\n$JSON_BLOB\n```\nObservation: action result\n... (repeat Thought/Action/Observation N times)\nThought: I know what to respond\nAction:\n```\n{{\n  "action": "Final Answer",\n  "action_input": "Final response to human"\n}}\n```\n\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\nThought:')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], template='{input}\n\n{agent_scratchpad}'))]

```

å°è¯•è¿è¡Œ

```python
agent_chain.run("æˆ‘å«SouthAki")
agent_chain.run("æˆ‘å–œæ¬¢å¬å¹¿æ’­å‰§,ä½ å–œæ¬¢å¬å—?")
agent_chain.run("æˆ‘å«ä»€ä¹ˆåå­—?")
```

![](./image/4.16.png)

å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„`memory`æ²¡æœ‰èµ·ä½œç”¨,æ‰€ä»¥è¿™é‡Œè¦åŠ å…¥ä¸€ä¸ªå‚æ•°

`agent_kwargs`ä¼ é€’å‚æ•°,æŠŠ`memory key`ä¼ å…¥åˆ°æç¤ºè¯

```python
agent_chain = initialize_agent(
    tools,
    llm,
    agent = AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,
    verbose = True,
    # åœ¨è¿™é‡Œåšå‡ºä¿®æ”¹
    agent_kwargs={
        "extra_prom_messages":[
            MessagesPlaceholder(variable_name= "chat_history"),
            MessagesPlaceholder(variable_name= "agent_scratchpad")
        ]
    },
    memory = memory
)
```

ç»§ç»­æˆ‘ä»¬çš„é—®é¢˜

```python
agent_chain.run("æˆ‘å«SouthAki")
agent_chain.run("æˆ‘å–œæ¬¢å¬å¹¿æ’­å‰§,ä½ å–œæ¬¢å¬å—?")
agent_chain.run("æˆ‘å«ä»€ä¹ˆåå­—?")
```

![](./image/4.17.png)

## åœ¨agentå’Œtoolsä¹‹é—´å…±äº«è®°å¿†

- è‡ªå®šä¹‰ä¸€ä¸ªå·¥å…·ç”¨æ¥LLMChainæ¥æ€»ç»“å†…å®¹

- ä½¿ç”¨readonlymemoryæ¥å…±äº«è®°å¿†

- è§‚å¯Ÿå…±äº«å’Œä¸å…±äº«çš„åŒºåˆ«

æˆ‘ä»¬æ¥å®ç°ä¸€ä¸‹

```python
import os
from dotenv import find_dotenv, load_dotenv
# åŠ è½½ API key
load_dotenv(find_dotenv())
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")

# å¯¼å…¥æ¨¡å—
from langchain.agents import (
    load_agent,
    initialize_agent,
    AgentType,
    Tool
)
from langchain.memory import ConversationBufferMemory,ReadOnlySharedMemory
from langchain.llms import Tongyi
from langchain.chains import LLMChain
from  langchain.prompts import PromptTemplate,MessagesPlaceholder
from langchain.utilities import SerpAPIWrapper

# åˆ›å»ºllm
llm= Tongyi(
    dashscope_api_key= dashscope_api_key,
    model= "Qwen-max",
    temperature = 0
)
```

åˆ›å»ºä¸€æ¡é“¾æ¥æ€»ç»“å¯¹è¯

```python
# é—®é¢˜
template= """
    ä»¥ä¸‹æ˜¯ä¸€æ®µAIæœºå™¨äººå’Œäººç±»çš„å¯¹è¯:
    {chat_history}
    æ ¹æ®è¾“å…¥å’Œä¸Šé¢çš„å¯¹è¯è®°å½•å†™ä¸€ä»½å¯¹è¯æ€»ç»“.
    è¾“å…¥:{input}
"""
# æç¤ºè¯æ¨¡ç‰ˆ
prompt = PromptTemplate(
    # è¾“å…¥éªŒè¯å™¨
    input_variables=["chat_history", "input"],
    template=template,
)
# åˆ›å»ºè®°å¿†
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages= True    
)

# å…³é”®ä¸€æ­¥,å¦‚ä½•è®©æˆ‘ä»¬çš„Agentå’ŒToolå…±äº«è®°å¿†
readonlymemory = ReadOnlySharedMemory(memory= memory)

# æ„å»ºchain
summary_chain = LLMChain(
    llm = llm,
    prompt= prompt,
    verbose= True,
    memory= readonlymemory
)
```

æ¥ä¸‹æ¥æ„å»ºå·¥å…·

```python
# æœç´¢å·¥å…·
search = SerpAPIWrapper(
    serpapi_api_key= serpapi_api_key,
    params={
        "engine": "google"
    }
)
# æ€»ç»“å·¥å…·(è‡ªå®šä¹‰)
def SummaryChainFun(history):
    print("\n====================æ€»ç»“chainå¼€å§‹è¿è¡Œ==========================")
    print("è¾“å…¥å†å²:",history)
    summary_chain.run(history)

tools= [
    Tool(
        name= "Search",
        func= search.run,
        description= "å½“éœ€è¦äº†è§£å®æ—¶ä¿¡æ¯æˆ–è€…ä½ ä¸çŸ¥é“çš„äº‹æƒ…çš„æ—¶å€™æ‰å¯ä»¥ä½¿ç”¨æœç´¢å·¥å…·"
    ),
    Tool(
        name= "Summary",
        func= SummaryChainFun,
        description= "å½“ä½ è¢«è¦æ±‚æ€»ç»“ä¸€æ®µå¯¹è¯çš„æ—¶å€™æ‰å¯ä»¥ä½¿ç”¨è¿™ä¸ªå·¥å…·,å·¥å…·è¾“å…¥å¿…é¡»ä¸ºå­—ç¬¦ä¸²,åªåœ¨å¿…è¦çš„æ—¶å€™ä½¿ç”¨"
    )
]

# æˆ‘ä»¬çœ‹ä¸‹å†…å®¹
print(tools)
```

çœ‹ä¸‹è¾“å‡ºç»“æœ

```text
[Tool(name='Search', description='å½“éœ€è¦äº†è§£å®æ—¶ä¿¡æ¯æˆ–è€…ä½ ä¸çŸ¥é“çš„äº‹æƒ…çš„æ—¶å€™æ‰å¯ä»¥ä½¿ç”¨æœç´¢å·¥å…·', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>), Tool(name='Summary', description='å½“ä½ è¢«è¦æ±‚æ€»ç»“ä¸€æ®µå¯¹è¯çš„æ—¶å€™æ‰å¯ä»¥ä½¿ç”¨è¿™ä¸ªå·¥å…·,å·¥å…·è¾“å…¥å¿…é¡»ä¸ºå­—ç¬¦ä¸²,åªåœ¨å¿…è¦çš„æ—¶å€™ä½¿ç”¨', func=<function SummaryChainFun at 0x0000020DF5BFE3E0>)]

```

æ¥ä¸‹æ¥,æˆ‘ä»¬åˆ›å»ºAgent

```python
agent_chain = initialize_agent(
    tools,
    llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True,
    handle_parsing_errors=True,
    memory = memory
)
# éªŒè¯ä¸€ä¸‹
print(agent_chain.agent.llm_chain.prompt.template)
```

çœ‹ä¸‹è¾“å‡ºç»“æœ

```text
Answer the following questions as best you can. You have access to the following tools:

Search(query: str, **kwargs: Any) -> str - å½“éœ€è¦äº†è§£å®æ—¶ä¿¡æ¯æˆ–è€…ä½ ä¸çŸ¥é“çš„äº‹æƒ…çš„æ—¶å€™æ‰å¯ä»¥ä½¿ç”¨æœç´¢å·¥å…·
Summary(history) - å½“ä½ è¢«è¦æ±‚æ€»ç»“ä¸€æ®µå¯¹è¯çš„æ—¶å€™æ‰å¯ä»¥ä½¿ç”¨è¿™ä¸ªå·¥å…·,å·¥å…·è¾“å…¥å¿…é¡»ä¸ºå­—ç¬¦ä¸²,åªåœ¨å¿…è¦çš„æ—¶å€™ä½¿ç”¨

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [Search, Summary]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

Question: {input}
Thought:{agent_scratchpad}
c:\Users\xiele\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\_api\deprecation.py:139: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.
  warn_deprecated(

```

ok,è¿™é‡Œå¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„æ¨¡ç‰ˆ,ä½†æ˜¯ä¸çŸ¥é“å¤§å®¶æœ‰æ²¡æœ‰å‘ç°,å°±æ˜¯ä¸Šé¢çš„å†…å®¹ä¸­,å¹¶æ²¡æœ‰æˆ‘ä»¬å…³äºè®°å¿†çš„éƒ¨åˆ†,ä¹Ÿå°±æ˜¯æˆ‘ä»¬å®šä¹‰çš„`chat_history`

é‚£ä¹ˆæ€ä¹ˆåŠå‘¢

è¿™é‡Œå¯ä»¥çœ‹ä¸€ä¸‹ä¸Šé¢çš„éƒ¨åˆ†,å°±æ˜¯ä¸Šé¢éƒ¨åˆ†æˆ‘ä»¬å¯ä»¥åˆ†æˆä¸‰ä¸ªéƒ¨åˆ†

åˆ†åˆ«æ˜¯: ***`å‰ç¼€`,`å†…å®¹`,`åç¼€`***

å…¶ä¸­å‰ç¼€åç¼€éƒ½æ˜¯å¯ä»¥ç”±æˆ‘ä»¬è‡ªå®šä¹‰,é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥ä¿®æ”¹ä¸Šé¢çš„å‰åç¼€,åŠ å…¥æˆ‘ä»¬çš„è®°å¿†`chat_history`,æ¥å®ç°

```python
# ä¿®æ”¹ä»£ç 
prefix = """
    Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:
    Search: Use this tool to search for information.
    Summary: Use this tool to summarize conversations.
"""
suffix = """
    Begin!"
    {chat_history}
    Question: {input}
    {agent_scratchpad}
"""

agent_chain = initialize_agent(
    tools,
    llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True,
    handle_parsing_errors= True,
    agent_kwargs={
        "prefix": prefix,
        "suffix": suffix,
        "agent_scratchpad": MessagesPlaceholder("agent_scratchpad"),
        "chat_history": MessagesPlaceholder("chat_history"),
        "input": MessagesPlaceholder("input")
    },
    memory = memory
)
# æ¥çœ‹ä¸‹æˆ‘ä»¬ä¿®æ”¹åçš„ç»“æœ
print(agent_chain.agent.llm_chain.prompt.template)
```

çœ‹ä¸‹

```text

    Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:
    Search: Use this tool to search for information.
    Summary: Use this tool to summarize conversations.


Search(query: str, **kwargs: Any) -> str - å½“éœ€è¦äº†è§£å®æ—¶ä¿¡æ¯æˆ–è€…ä½ ä¸çŸ¥é“çš„äº‹æƒ…çš„æ—¶å€™æ‰å¯ä»¥ä½¿ç”¨æœç´¢å·¥å…·
Summary(history) - å½“ä½ è¢«è¦æ±‚æ€»ç»“ä¸€æ®µå¯¹è¯çš„æ—¶å€™æ‰å¯ä»¥ä½¿ç”¨è¿™ä¸ªå·¥å…·,å·¥å…·è¾“å…¥å¿…é¡»ä¸ºå­—ç¬¦ä¸²,åªåœ¨å¿…è¦çš„æ—¶å€™ä½¿ç”¨

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [Search, Summary]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question


    Begin!"
    {chat_history}
    Question: {input}
    {agent_scratchpad}

```

ok,æˆ‘ä»¬çœ‹åˆ°æˆ‘ä»¬ä¿®æ”¹äº†å‰åç¼€å·²ç»æˆåŠŸäº†,æ¥è¯•è¯•çœ‹

```python
agent_chain.run(input = "ç¾å›½ç¬¬45ä»»æ€»ç»Ÿæ˜¯è°?")
```

![](./image/4.18.png)

```python
agent_chain.run(input = "ä»–çš„å¤«äººå«ä»€ä¹ˆåå­—?")
```

![](./image/4.19.png)

```python
# æˆ‘ä»¬çœ‹ä¸‹å¯¹è¯çš„è®°å¿†çš„
print(agent_chain.memory.buffer)
```

```text
[HumanMessage(content='ç¾å›½ç¬¬45ä»»æ€»ç»Ÿæ˜¯è°?'), AIMessage(content='ç¾å›½çš„ç¬¬45ä»»æ€»ç»Ÿæ˜¯å”çº³å¾·Â·ç‰¹æœ—æ™®ï¼ˆDonald Trumpï¼‰ã€‚'), HumanMessage(content='ä»–çš„å¤«äººå«ä»€ä¹ˆåå­—?'), AIMessage(content='å”çº³å¾·Â·ç‰¹æœ—æ™®çš„å¤«äººå«æ¢…æ‹‰å°¼å¨…Â·ç‰¹æœ—æ™®ï¼ˆMelania Trumpï¼‰ã€‚')]

```

```python
agent_chain.run(input= "æˆ‘ä»¬éƒ½èŠäº†ä»€ä¹ˆ?")
```

![](./image/4.20.png)

```python
agent_chain.run(input= "ä¸­å›½æœ€æ–°çš„å—æç§‘è€ƒç«™æ˜¯ä»€ä¹ˆ?å“ªä¸€å¹´å¼€ç«™å±•å¼€ç§‘å­¦è€ƒå¯Ÿ?")
```

![](./image/4.21.png)

```python
agent_chain.run(input="å¸®æˆ‘æ€»ç»“ä¸‹ç›®å‰çš„å¯¹è¯å†…å®¹ï¼Œç»™æˆ‘5å²çš„å„¿å­çœ‹çœ‹")
```

![](./image/4.22.png)

## Toolå’ŒToolKit

### ä»‹ç»

![](./image/4.23.png)

### å¦‚ä½•åŠ è½½ä½¿ç”¨tool

- åŠ è½½é¢„åˆ¶toolçš„æ–¹æ³•
- å‡ ç§toolçš„ä½¿ç”¨æ–¹å¼

langchainé¢„åˆ¶äº†å¤§é‡çš„toolsï¼ŒåŸºæœ¬è¿™äº›å·¥å…·èƒ½æ»¡è¶³å¤§éƒ¨åˆ†éœ€æ±‚ï¼Œå®˜æ–¹å¯ä»¥æŸ¥åˆ°[ç‚¹å‡»è®¿é—®](https://github.com/langchain-ai/langchain/tree/v0.0.352/docs/docs/integrations/tools)

å¦‚ä½•ä½¿ç”¨æˆ‘ä»¬çš„Tool,ä¸‹é¢æ˜¯æˆ‘ä»¬çš„æ¨¡ç‰ˆ

```python
#æ·»åŠ é¢„åˆ¶å·¥å…·çš„æ–¹æ³•å¾ˆç®€å•
from langchain.agents import load_tools
tool_names = [...]
tools = load_tools(tool_names) #ä½¿ç”¨loadæ–¹æ³•
#æœ‰äº›tooléœ€è¦å•ç‹¬è®¾ç½®llm
from langchain.agents import load_tools
tool_names = [...]
llm = ...
tools = load_tools(tool_names, llm=llm) #åœ¨loadçš„æ—¶å€™æŒ‡å®šllm
```

æ¥ä¸‹æ¥ä¼šè®²å‡ ä¸ªå¸¸ç”¨çš„tool

#### Serp API

> ç¬¬ä¸€ä¸ªæ˜¯serp Api
>
> æœ€å¸¸è§çš„èšåˆæœç´¢å¼•æ“ https://serper.dev/dashboard

```python
# å¯¼å…¥æ¨¡å—
import os
from dotenv import find_dotenv, load_dotenv
# åŠ è½½ API key
load_dotenv(find_dotenv())
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")
from langchain.utilities import SerpAPIWrapper
import os
search = SerpAPIWrapper(
    serpapi_api_key=serpapi_api_key
)
search.run("åŠ æ‹¿å¤§å¥³ç‹æ˜¯è°?")
```

![](./image/4.24.png)

> æŸ¥å°”æ–¯è¢«é»‘å¾—æœ€æƒ¨çš„ä¸€æ¬¡

æ”¯æŒè‡ªå®šä¹‰å‚æ•°ï¼Œæ¯”å¦‚å°†å¼•æ“åˆ‡æ¢åˆ°bingï¼Œè®¾ç½®æœç´¢è¯­è¨€ç­‰

```python
params = {
    "engine": "bing",
    "gl": "us",
    "hl": "en",
}
search = SerpAPIWrapper(params=params)
```

![](./image/4.25.png)

#### Dall-E

Dall-Eæ˜¯OpenAIå‡ºå“çš„æ–‡åˆ°å›¾AIå¤§æ¨¡å‹

é¦–å…ˆæˆ‘ä»¬éœ€è¦å®‰è£…ä¸€ä¸ªåŒ…

```python
! pip install opencv-python scikit-image
```

```python
# è¿™é‡Œå¯èƒ½éœ€è¦ç”¨åˆ°OpenAIçš„,ä½†æ˜¯åé¢æˆ‘ä¼šå°è¯•ä½¿ç”¨é€šä¹‰
# å…ˆå±•ç¤ºä¸€ä¸‹å°±æ˜¯OpenAIçš„å†™æ³•
from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(
    temperature=0,
    # è¿™é‡Œè¦æ³¨æ„,å°±æ˜¯ä½¿ç”¨çš„æ¨¡å‹ä¸€å®šè¦æ˜¯æœ€æ–°çš„
    model= "gpt-4"
)

from langchain.agents import(
    initialize_agent,
    load_tools
)

tools = load_tools(["dalle-image-generator"])
agent = initialize_agent(
    tools,
    llm,
    agent="zero-shot-react-description",
    verbose=True
)
output = agent.run("Generate an image of a cat")
```

å¥½çš„,è¿™é‡Œæ²¡æœ‰æ¼”ç¤ºçš„å“ˆ

ä½†æ˜¯æˆ‘è½¬è¯‘è¯•è¯•çœ‹

```python
# è½¬è¯‘Tongyi
import os
from dotenv import find_dotenv, load_dotenv
# åŠ è½½ API key
load_dotenv(find_dotenv())
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")
from langchain_community.chat_models import ChatTongyi
llm = ChatTongyi(
    model_name = "qwen-vl-max",
    temperature = 0,
    dashscope_api_key = dashscope_api_key
)
from langchain.agents import initialize_agent, load_tools

tools = load_tools(["dalle-image-generator"])
agent = initialize_agent(
    tools,
    llm,
    agent="zero-shot-react-description",
    verbose=True
)
output = agent.run("Create an image of a halloween night at a haunted museum")
```

![](./image/4.26.png)

çœ‹æ¥æ˜¯ä¸å¯ä»¥çš„,æ²¡å…³ç³»,è·³è¿‡å°±è¡Œ,åç»­è¡¥å…… to do

#### Eleven Labs Text2Speech

`ElevenLabs` æ˜¯éå¸¸ä¼˜ç§€çš„`TTS`åˆæˆAPI

ä¸‹é¢éœ€è¦å®‰è£…ä¸€äº›åŒ…

```python
! pip install elevenlabs
```

```python
import os
from dotenv import find_dotenv, load_dotenv
# åŠ è½½ API key
load_dotenv(find_dotenv())
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")
eleven_api_key = os.getenv("ELEVEN_API_KEY")

# å·¥å…·ä½¿ç”¨
from langchain.tools import ElevenLabsText2SpeechTool
import elevenlabs
elevenlabs.api_key = eleven_api_key
text_to_speak = "Hello! ä½ å¥½! Hola! à¤¨à¤®à¤¸à¥à¤¤à¥‡! Bonjour! ã“ã‚“ã«ã¡ã¯! Ù…Ø±Ø­Ø¨Ø§! ì•ˆë…•í•˜ì„¸ìš”! Ciao! CzeÅ›Ä‡! ĞŸÑ€Ğ¸Ğ²Ñ–Ñ‚! à®µà®£à®•à¯à®•à®®à¯!"
tts = ElevenLabsText2SpeechTool(
    voice = "Bella",
    text_to_speak = text_to_speak,
    verbose = True
)
# æµ‹è¯•æ˜¯å¦å¯ç”¨
tts.name
```

![](./image/4.27.png)

å°è¯•æ’­æ”¾,å…ˆç¼“å­˜åœ¨æˆ‘ä»¬æœ¬åœ°ä¸Šå§

```python
# ç¼“å­˜åˆ°æœ¬åœ°
speech_file = tts.run(text_to_speak)
# ç­‰åˆ°åŠ è½½å®Œå†æ‰§è¡Œæ’­æ”¾
tts.play(tts.run(text_to_speak))
# è¾¹ç”Ÿæˆè¾¹æ’­æ”¾
tts.stream_speech(text_to_speak)
```

OK,ä½ ä»¬åœ¨è¿™ä¸ªé¡¹ç›®çš„ä»“åº“å°±å¯ä»¥å¬å¬çœ‹è¿™ä¸ªTTSäº†

`temp.wav`

#### GraphQL

å…ˆå®‰è£…å‡ ä¸ªåŒ…

```python
! pip install httpx gql > /dev/null
! pip install gql
! pip install requests_toolbelt
```

```python
from langchain_community.chat_models import ChatTongyi
from langchain.agents import load_tools, initialize_agent, AgentType
from langchain.utilities import GraphQLAPIWrapper

import os
from dotenv import find_dotenv, load_dotenv
# åŠ è½½ API key
load_dotenv(find_dotenv())
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")
eleven_api_key = os.getenv("ELEVEN_API_KEY")

llm = ChatTongyi(
    model_name = "qwen-vl-max",
    temperature = 0,
    dashscope_api_key = dashscope_api_key
)
tools = load_tools(
    ["graphql"],
    graphql_endpoint="https://swapi-graphql.netlify.app/.netlify/functions/index",
)

agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True,
    return_intermediate_steps=True
)

graphql_fields = """
allFilms {
    films {
        title
        director
        releaseDate
        speciesConnection {
            species {
                name
                classification
                homeworld {
                    name
                }
            }
        }
    }


"""

suffix = "Search for the titles of all the stawars films stored in the graphql database that has this schema,and answer in chinese:"


result = agent({"input": suffix + graphql_fields})
print(result["output"])
```

![](./image/4.28.png)

### å¦‚ä½•åŠ è½½ä½¿ç”¨ToolKit

> tookitæ˜¯langchainå·²ç»å°è£…å¥½çš„ä¸€ç³»åˆ—å·¥å…·ï¼Œä¸€ä¸ªå·¥å…·åŒ…æ˜¯ä¸€ç»„å·¥å…·æ¥ç»„åˆå®Œæˆç‰¹å®šçš„ä»»åŠ¡

#### Azureè®¤çŸ¥æœåŠ¡

å®˜æ–¹åœ°å€:[ç‚¹å‡»è®¿é—®](https://portal.azure.com/#allservices)

æˆ‘ä»¬è¿™é‡Œå®ç°çš„æ˜¯,æ–‡æœ¬è½¬äººç±»è‡ªç„¶è¯­è¨€çš„è¿‡ç¨‹

è¿™ä¸ª`Azureè®¤çŸ¥æœåŠ¡`çš„`ToolKit`é‡Œé¢æœ‰è¿™å‡ ä¸ªåŠŸèƒ½

- AzureCogsFormRecognizerToolï¼šä»æ–‡æ¡£é‡Œæå–æ–‡æœ¬

- AzureCogsSpeech2TextToolï¼šè¯­éŸ³åˆ°æ–‡æœ¬

- AzureCogsText2SpeechToolï¼šæ–‡æœ¬åˆ°è¯­éŸ³

æˆ‘ä»¬è¦å®ç°å®ƒ,éœ€è¦å…ˆå®‰è£…å‡ ä¸ªåŒ…

```python
! pip install azure-ai-formrecognizer
! pip install azure-cognitiveservices-speech
! pip install azure-ai-textanalytics
```

ç„¶åçš„è¯,éœ€è¦ç”³è¯·`Microsoft Azure API_KEY`

ç„¶åæ ¼å¼æ˜¯è¿™æ ·çš„

```python
import os

# è¿™é‡Œçš„éƒ¨åˆ†éœ€è¦ä½ å»ç”³è¯·å¾®è½¯AzureæœåŠ¡,éœ€è¦ä¿¡ç”¨å¡
os.environ["AZURE_COGS_KEY"] = "c10"
os.environ["AZURE_COGS_ENDPOINT"] = "https://eastus.api.cognitive.microsoft.com/"
os.environ["AZURE_COGS_REGION"] = "eastus"
```

> <font color= "red">**è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯,éœ€è¦æœ‰å¯¹åº”è´¦å•åœ°å€çš„å›½å®¶ä¿¡ç”¨å¡,é¢„ä»˜å¡å’Œå€Ÿè®°å¡æ— æ³•ç”³è¯·.å¦‚æœä½ æ²¡æœ‰ä¿¡ç”¨å¡,è¯·è·³æ‰è¿™ä¸€éƒ¨åˆ†çš„ToolKit**</font>

```python
# åˆ›å»ºtoolkit
from langchain.agents.agent_toolkits import AzureCognitiveServicesToolkit
toolkit = AzureCognitiveServicesToolkit()
[tool.name for tool in toolkit.get_tools()]
```

```python
# agentä½¿ç”¨
from langchain_community.chat_models import ChatTongyi
from langchain.agents import initialize_agent, AgentType
# å®šä¹‰llm
llm = ChatTongyi(
    dashscope_api_key = dashscope_api_key,
    model_name = "qwen-vl-max",
    temperature = 0
)
agent = initialize_agent(
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    llm=llm,
    verbose=True,
    return_intermediate_steps=True,
    tools= toolkit.get_tools()
)
audio_file = agent.run("Tell me a joke and read it out for me.")
print(audio_file)
```

è¿™é‡Œçš„è¯,å°±ä¸æ”¾è¿è¡Œçš„æˆªå›¾,æœ‰èƒ½åŠ›éªŒè¯çš„å°±å¯ä»¥è‡ªå·±å»éªŒè¯ä¸€ä¸‹

#### Python ä»£ç æœºå™¨äºº

> æ¥ä¸‹æ¥å®ç°çš„æ˜¯ä¸€ä¸ªPythonä»£ç æœºå™¨äºº,ä¹Ÿæ˜¯å±äºlangchainå®šä¹‰toolkitä¹‹ä¸­
>
> æ¥ç”¨ä¸‹çœ‹çœ‹

```python
# é¦–å…ˆéœ€è¦å®‰è£…ä¸€ä¸ªåŒ…
! pip install langchain_experimental
```

```python
# OK,æˆ‘ä»¬æ¥ç€å®ç°
# é¦–å…ˆå¯¼å…¥æ¨¡å—
import os
from dotenv import find_dotenv, load_dotenv
# åŠ è½½ API key
load_dotenv(find_dotenv())
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")
eleven_api_key = os.getenv("ELEVEN_API_KEY")

from langchain_experimental.agents.agent_toolkits import create_python_agent
from langchain_experimental.tools import PythonREPLTool
from langchain.agents.agent_types import AgentType
from langchain_community.llms.tongyi import Tongyi
from langchain_community.chat_models import ChatTongyi
from langchain_core.utils.init import pre_init

agent_executor = create_python_agent(
    llm= ChatTongyi(
        dashscope_api_key = dashscope_api_key,
        temperature = 0,
        model_name = "qwen-vl-max"
    ),
    tool= PythonREPLTool(),
    agent_type= AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose= True,
    # agent_executor_kwargs= {"handle_parsing_errors": True}
)

agent_executor.run("What is the 10th fibonacci number?")
```

![](./image/4.29.png)

#### SQL Database

ä½¿ç”¨`SQLDatabaseChain`æ„å»ºçš„`agent`ï¼Œç”¨æ¥æ ¹æ®æ•°æ®åº“å›ç­”ä¸€èˆ¬è¡ŒåŠ¨é—®é—®é¢˜

é¦–å…ˆå¯¼å…¥æ¨¡å—

```python
from langchain.agents import create_sql_agent
from langchain.agents.agent_toolkits import SQLDatabaseToolkit
from langchain.sql_database import SQLDatabase
from langchain_community.llms.tongyi import Tongyi
from langchain.agents import AgentExecutor
from langchain.agents.agent_types import AgentType
from langchain_community.chat_models import ChatTongyi
```

```python
import os
from dotenv import find_dotenv, load_dotenv
# åŠ è½½ API key
load_dotenv(find_dotenv())
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")
eleven_api_key = os.getenv("ELEVEN_API_KEY")
db = SQLDatabase.from_uri("sqlite:///Chinook.db")
toolkit = SQLDatabaseToolkit(db=db, llm= Tongyi(temperature = 0, model= "Qwen-max", dashscope_api_key= dashscope_api_key))

agent_executor = create_sql_agent(
    llm= ChatTongyi(
        temperature = 0,
        model_name= "qwen-vl-max",
        dashscope_api_key= dashscope_api_key
    ),
    toolkit= toolkit,
    verbose= True,
    agent_type= AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    handle_parsing_errors=True
)

agent_executor.run("Describe the playlisttrack table")
```

```python
# æˆ‘ä»¬ä¹Ÿå¯ä»¥ç”¨è‡ªç„¶è¯­è¨€æè¿°ä¸€ä¸ªæ•°æ®åº“è¡¨
agent_executor.run("Describe the playlist table")
```

```python
# ç”¨è‡ªç„¶è¯­è¨€è·‘SQLæŸ¥è¯¢è¯­å¥
agent_executor.run(
    "Show the total number of tranks in each playlist name should be included in the result."
)
```

```python
# agentå¯ä»¥è‡ªåŠ¨ä¿®å¤ä¸å­˜åœ¨çš„é”®å€¼
agent_executor.run("Who are the top 3 best selling artists?")
```

##  LECL: langchainè¡¨è¾¾å¼è¯­è¨€

### ä»‹ç»

> ä¸€ç§åœ¨langchainä¹‹ä¸Šå°è£…çš„é«˜çº§è§£é‡Šè¯­è¨€,ç®€åŒ–é“¾æ¡å¼€å‘,æ”¯æŒçœŸå®ç”Ÿäº§ç¯å¢ƒè€Œå‘æ˜
>
> æœ‰è¿™ä¸‹é¢çš„ç‰¹ç‚¹:
>
> - æ›´å¥½çš„æµå¼æ”¯æŒ
>
> - æ›´å¥½çš„å¼‚æ­¥æ”¯æŒ
>
> - ä¼˜åŒ–æ‰§è¡Œæ—¶é—´
>
> - æ”¯æŒé‡è¯•å’Œåé¦ˆ
>
> - è½»æ¾è·å–ä¸­é—´æ­¥éª¤
>
> - è¾“å…¥è¾“å‡ºå¼ºéªŒè¯
>
> - æ— ç¼è¿½è¸ªé›†æˆ
>
> - æ— ç¼éƒ¨ç½²é›†æˆ
>
> > å®˜æ–¹ä»‹ç»:***LangChainè¡¨è¾¾å¼è¯­è¨€ï¼Œæˆ–è€…LCELï¼Œæ˜¯ä¸€ç§å£°æ˜å¼çš„æ–¹å¼ï¼Œå¯ä»¥è½»æ¾åœ°å°†é“¾æ¡ç»„åˆåœ¨ä¸€èµ·ã€‚ LCELä»ç¬¬ä¸€å¤©å¼€å§‹å°±è¢«è®¾è®¡ä¸ºæ”¯æŒå°†åŸå‹æ”¾å…¥ç”Ÿäº§ä¸­ï¼Œä¸éœ€è¦æ”¹å˜ä»»ä½•ä»£ç ï¼Œä»æœ€ç®€å•çš„â€œæç¤º+LLMâ€é“¾åˆ°æœ€å¤æ‚çš„é“¾(æˆ‘ä»¬å·²ç»çœ‹åˆ°äººä»¬æˆåŠŸåœ°åœ¨ç”Ÿäº§ä¸­è¿è¡Œäº†åŒ…å«æ•°ç™¾æ­¥çš„LCELé“¾)ã€‚***
>
> ![](./image/4.30.png)
>
> ![](./image/4.31.png)
>
> ![](./image/4.32.png)
>
> ```python
> import os
> from dotenv import find_dotenv, load_dotenv
> # åŠ è½½ API key
> load_dotenv(find_dotenv())
> dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
> serpapi_api_key = os.getenv("SERPAPI_API_KEY")
> eleven_api_key = os.getenv("ELEVEN_API_KEY")
> ```
>
> 



OK,æˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªæ¯”è¾ƒç®€å•çš„ç¤ºä¾‹

```python
# é¦–å…ˆå¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—,è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯,æœ€æ–°ç‰ˆçš„langchainä¸­,å…¶å®å·²ç»å°†ä¸€äº›ä¸œè¥¿æ‹†åˆ†å‡ºæ¥äº†
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.chat_models import ChatTongyi

prompt = ChatPromptTemplate.from_template("ç»™æˆ‘è®²ä¸€ä¸ªå…³äº{topic}çš„ç¬‘è¯")
model = ChatTongyi(temperature=0,model_name = "qwen-vl-max",dashscope_api_key = dashscope_api_key)
output_parser = StrOutputParser()
chain = prompt | model | output_parser
chain.invoke({"topic": "å†°æ·‡æ·‹"})
```

![](./image/4.33.png)

æˆ‘ä»¬ä¹Ÿå¯ä»¥çœ‹ä¸‹å°±æ˜¯promptåœ¨æ–°ç‰ˆçš„LCELä¸­çš„å˜åŒ–

```python
prompt_value = prompt.invoke({"topic": "é•¿é¢ˆé¹¿"})
prompt_value
# è¿™é‡Œå¯ä»¥çœ‹åˆ°æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯chatModelçš„æ–¹å¼,äºæ˜¯å°±æ˜¯ä¸€ä¸ªäººç±»é—®ç­”çš„messages
```

![](./image/4.34.png)

```python
# æˆ‘ä»¬ä¹Ÿå¯ä»¥å•ç‹¬çš„æ‰“å°å‡ºæ¥æˆ‘ä»¬çš„message
prompt_value.to_messages()
```

![](./image/4.35.png)

```python
# ä¹Ÿå¯ä»¥æŠŠé‡Œé¢çš„å†…å®¹æ‰“å°æˆå­—ç¬¦ä¸²
prompt_value.to_string()
```

![](./image/4.36.png)

ä¸‹é¢æ˜¯å…³äº`Model`

```python
message = model.invoke(prompt_value)
message
```

![](./image/4.37.png)

ä½¿ç”¨llmåŒºåˆ«

```python
from langchain_community.llms.tongyi import Tongyi
llm = Tongyi(
    dashscope_api_key= dashscope_api_key,
    model= "Qwen-max",
    temperature= 0
)
llm.invoke(prompt_value)
```

![](./image/4.38.png)

`Output parser`

```python
output_parser.invoke(message)
```

![](./image/4.39.png)

### RAG Search Exampl

- å»ºç«‹å‘é‡æ•°æ®

- ä½¿ç”¨RAGå¢å¼º

```python
from operator import itemgetter
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_community.chat_models import ChatTongyi
from langchain.embeddings import HuggingFaceEmbeddings

# å¯¹ä¸€æ®µæ–‡æœ¬è¿›è¡Œå‘é‡åŒ–
vectorstore = FAISS.from_texts(
    ["harrison worked at kensho"], embedding=HuggingFaceEmbeddings()
)
retriever = vectorstore.as_retriever()

# è®¾ç½®æç¤ºè¯æ¨¡ç‰ˆ
template = """
    Answer the question based only on the following context:
    {context}
    Question:{question}
"""
prompt = ChatPromptTemplate.from_template(template)

model = ChatTongyi(
    model_name= "qwen-vl-max",
    dashscope_api_key= dashscope_api_key,
    temperature = 0
)

# æ„é€ æˆ‘ä»¬çš„é“¾
chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | model
    | StrOutputParser()
)
```
![](./image/4.40.png)

```python
# å±•å¼€æé—®
chain.invoke("Where did harrison work?")
```

![](./image/4.41.png)

è‡ªå®šä¹‰ä¹Ÿéå¸¸ç®€å•,æ¯”å¦‚æˆ‘ä»¬æ¥å®ç°ä¸€ä¸ªè®©å®ƒå›ç­”çš„æ—¶å€™ä½¿ç”¨ä¸­æ–‡

```python
# ä¾æ—§æ˜¯ä¸Šé¢çš„æ¨¡ç‰ˆ
template = """
    Answer the question based only on the following context:
    {context}
    Question:{question}
    Answer in the following language:{language}
"""

prompt = ChatPromptTemplate.from_template(template)

chain = (
    {
        # è¿™é‡Œç¬¬ä¸€æ­¥å°±æ˜¯å…ˆæŠŠé—®é¢˜æ‹¿å»å‘é‡åŒ–
        "context": itemgetter("question") | retriever,
        "question": itemgetter("question"),
        "language": itemgetter("language"),
    } 
    | prompt
    | llm
    | StrOutputParser()
)

# æˆ‘ä»¬å°è¯•ä¸€ä¸‹æ˜¯å¦ç”Ÿæ•ˆ
chain.invoke({"question": "where did harrison work?", "language": "chinese"})
```

![](./image/4.42.png)

### LCELæ¥å£

- è¾“å…¥æ ¼å¼
- è¾“å‡ºæ ¼å¼
- 8ç§ä¸åŒçš„æ¥å£æ–¹å¼

é¦–å…ˆéœ€è¦å¯¼å…¥å˜é‡

```python
import os
from dotenv import find_dotenv, load_dotenv
# åŠ è½½ API key
load_dotenv(find_dotenv())
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")
eleven_api_key = os.getenv("ELEVEN_API_KEY")
```

ç„¶å,éœ€è¦æˆ‘ä»¬å…ˆæ‰“é€ ä¸€ä¸ªæ¨¡ç‰ˆ

```python
# æ‰“é€ ä¸€ä¸ªæ¨¡ç‰ˆ
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.chat_models import ChatTongyi
model = ChatTongyi(
    dashscope_api_key = dashscope_api_key,
    model_name = "qwen-vl-max",
    temperature = 0
)
prompt = ChatPromptTemplate.from_template("ç»™æˆ‘è®²ä¸€ä¸ªå…³äº{topic}çš„ç¬‘è¯")
chain = prompt | model
```

æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹è¾“å…¥çš„æ ¼å¼

#### `input schema`

çœ‹ä¸‹prompt

```python
# prompt
chain.input_schema.schema()
```

![](./image/4.43.png)

```python
prompt.input_schema.schema()
```

![](./image/4.44.png)

```python
model.input_schema.schema()
```

```text
output:
{'title': 'ChatTongyiInput',
 'anyOf': [{'type': 'string'},
  {'$ref': '#/definitions/StringPromptValue'},
  {'$ref': '#/definitions/ChatPromptValueConcrete'},
  {'type': 'array',
   'items': {'anyOf': [{'$ref': '#/definitions/AIMessage'},
     {'$ref': '#/definitions/HumanMessage'},
     {'$ref': '#/definitions/ChatMessage'},
     {'$ref': '#/definitions/SystemMessage'},
     {'$ref': '#/definitions/FunctionMessage'},
     {'$ref': '#/definitions/ToolMessage'}]}}],
 'definitions': {'StringPromptValue': {'title': 'StringPromptValue',
   'description': 'String prompt value.',
   'type': 'object',
   'properties': {'text': {'title': 'Text', 'type': 'string'},
    'type': {'title': 'Type',
     'default': 'StringPromptValue',
     'enum': ['StringPromptValue'],
     'type': 'string'}},
   'required': ['text']},
  'ToolCall': {'title': 'ToolCall',
   'type': 'object',
   'properties': {'name': {'title': 'Name', 'type': 'string'},
    'args': {'title': 'Args', 'type': 'object'},
    'id': {'title': 'Id', 'type': 'string'}},
   'required': ['name', 'args', 'id']},
  'InvalidToolCall': {'title': 'InvalidToolCall',
   'type': 'object',
   'properties': {'name': {'title': 'Name', 'type': 'string'},
    'args': {'title': 'Args', 'type': 'string'},
    'id': {'title': 'Id', 'type': 'string'},
    'error': {'title': 'Error', 'type': 'string'}},
   'required': ['name', 'args', 'id', 'error']},
  'UsageMetadata': {'title': 'UsageMetadata',
   'type': 'object',
   'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'},
    'output_tokens': {'title': 'Output Tokens', 'type': 'integer'},
    'total_tokens': {'title': 'Total Tokens', 'type': 'integer'}},
   'required': ['input_tokens', 'output_tokens', 'total_tokens']},
  'AIMessage': {'title': 'AIMessage',
   'description': 'Message from an AI.\n\nAIMessage is returned from a chat model as a response to a prompt.\n\nThis message represents the output of the model and consists of both\nthe raw output as returned by the model together standardized fields\n(e.g., tool calls, usage metadata) added by the LangChain framework.',
   'type': 'object',
   'properties': {'content': {'title': 'Content',
     'anyOf': [{'type': 'string'},
      {'type': 'array',
       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},
    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},
    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},
    'type': {'title': 'Type',
     'default': 'ai',
     'enum': ['ai'],
     'type': 'string'},
    'name': {'title': 'Name', 'type': 'string'},
    'id': {'title': 'Id', 'type': 'string'},
    'example': {'title': 'Example', 'default': False, 'type': 'boolean'},
    'tool_calls': {'title': 'Tool Calls',
     'default': [],
     'type': 'array',
     'items': {'$ref': '#/definitions/ToolCall'}},
    'invalid_tool_calls': {'title': 'Invalid Tool Calls',
     'default': [],
     'type': 'array',
     'items': {'$ref': '#/definitions/InvalidToolCall'}},
    'usage_metadata': {'$ref': '#/definitions/UsageMetadata'}},
   'required': ['content']},
  'HumanMessage': {'title': 'HumanMessage',
   'description': 'Message from a human.\n\nHumanMessages are messages that are passed in from a human to the model.\n\nExample:\n\n    .. code-block:: python\n\n        from langchain_core.messages import HumanMessage, SystemMessage\n\n        messages = [\n            SystemMessage(\n                content="You are a helpful assistant! Your name is Bob."\n            ),\n            HumanMessage(\n                content="What is your name?"\n            )\n        ]\n\n        # Instantiate a chat model and invoke it with the messages\n        model = ...\n        print(model.invoke(messages))',
   'type': 'object',
   'properties': {'content': {'title': 'Content',
     'anyOf': [{'type': 'string'},
      {'type': 'array',
       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},
    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},
    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},
    'type': {'title': 'Type',
     'default': 'human',
     'enum': ['human'],
     'type': 'string'},
    'name': {'title': 'Name', 'type': 'string'},
    'id': {'title': 'Id', 'type': 'string'},
    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},
   'required': ['content']},
  'ChatMessage': {'title': 'ChatMessage',
   'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',
   'type': 'object',
   'properties': {'content': {'title': 'Content',
     'anyOf': [{'type': 'string'},
      {'type': 'array',
       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},
    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},
    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},
    'type': {'title': 'Type',
     'default': 'chat',
     'enum': ['chat'],
     'type': 'string'},
    'name': {'title': 'Name', 'type': 'string'},
    'id': {'title': 'Id', 'type': 'string'},
    'role': {'title': 'Role', 'type': 'string'}},
   'required': ['content', 'role']},
  'SystemMessage': {'title': 'SystemMessage',
   'description': 'Message for priming AI behavior.\n\nThe system message is usually passed in as the first of a sequence\nof input messages.\n\nExample:\n\n    .. code-block:: python\n\n        from langchain_core.messages import HumanMessage, SystemMessage\n\n        messages = [\n            SystemMessage(\n                content="You are a helpful assistant! Your name is Bob."\n            ),\n            HumanMessage(\n                content="What is your name?"\n            )\n        ]\n\n        # Define a chat model and invoke it with the messages\n        print(model.invoke(messages))',
   'type': 'object',
   'properties': {'content': {'title': 'Content',
     'anyOf': [{'type': 'string'},
      {'type': 'array',
       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},
    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},
    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},
    'type': {'title': 'Type',
     'default': 'system',
     'enum': ['system'],
     'type': 'string'},
    'name': {'title': 'Name', 'type': 'string'},
    'id': {'title': 'Id', 'type': 'string'}},
   'required': ['content']},
  'FunctionMessage': {'title': 'FunctionMessage',
   'description': 'Message for passing the result of executing a tool back to a model.\n\nFunctionMessage are an older version of the ToolMessage schema, and\ndo not contain the tool_call_id field.\n\nThe tool_call_id field is used to associate the tool call request with the\ntool call response. This is useful in situations where a chat model is able\nto request multiple tool calls in parallel.',
   'type': 'object',
   'properties': {'content': {'title': 'Content',
     'anyOf': [{'type': 'string'},
      {'type': 'array',
       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},
    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},
    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},
    'type': {'title': 'Type',
     'default': 'function',
     'enum': ['function'],
     'type': 'string'},
    'name': {'title': 'Name', 'type': 'string'},
    'id': {'title': 'Id', 'type': 'string'}},
   'required': ['content', 'name']},
  'ToolMessage': {'title': 'ToolMessage',
   'description': "Message for passing the result of executing a tool back to a model.\n\nToolMessages contain the result of a tool invocation. Typically, the result\nis encoded inside the `content` field.\n\nExample: A TooMessage representing a result of 42 from a tool call with id\n\n    .. code-block:: python\n\n        from langchain_core.messages import ToolMessage\n\n        ToolMessage(content='42', tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL')\n\nThe tool_call_id field is used to associate the tool call request with the\ntool call response. This is useful in situations where a chat model is able\nto request multiple tool calls in parallel.",
   'type': 'object',
   'properties': {'content': {'title': 'Content',
     'anyOf': [{'type': 'string'},
      {'type': 'array',
       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},
    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},
    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},
    'type': {'title': 'Type',
     'default': 'tool',
     'enum': ['tool'],
     'type': 'string'},
    'name': {'title': 'Name', 'type': 'string'},
    'id': {'title': 'Id', 'type': 'string'},
    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'}},
   'required': ['content', 'tool_call_id']},
  'ChatPromptValueConcrete': {'title': 'ChatPromptValueConcrete',
   'description': 'Chat prompt value which explicitly lists out the message types it accepts.\nFor use in external schemas.',
   'type': 'object',
   'properties': {'messages': {'title': 'Messages',
     'type': 'array',
     'items': {'anyOf': [{'$ref': '#/definitions/AIMessage'},
       {'$ref': '#/definitions/HumanMessage'},
       {'$ref': '#/definitions/ChatMessage'},
       {'$ref': '#/definitions/SystemMessage'},
       {'$ref': '#/definitions/FunctionMessage'},
       {'$ref': '#/definitions/ToolMessage'}]}},
    'type': {'title': 'Type',
     'default': 'ChatPromptValueConcrete',
     'enum': ['ChatPromptValueConcrete'],
     'type': 'string'}},
   'required': ['messages']}}}
```

#### `output schema`

```python
chain.output_schema.schema()
```

```text
output:
{'title': 'ChatTongyiOutput',
 'anyOf': [{'$ref': '#/definitions/AIMessage'},
  {'$ref': '#/definitions/HumanMessage'},
  {'$ref': '#/definitions/ChatMessage'},
  {'$ref': '#/definitions/SystemMessage'},
  {'$ref': '#/definitions/FunctionMessage'},
  {'$ref': '#/definitions/ToolMessage'}],
 'definitions': {'ToolCall': {'title': 'ToolCall',
   'type': 'object',
   'properties': {'name': {'title': 'Name', 'type': 'string'},
    'args': {'title': 'Args', 'type': 'object'},
    'id': {'title': 'Id', 'type': 'string'}},
   'required': ['name', 'args', 'id']},
  'InvalidToolCall': {'title': 'InvalidToolCall',
   'type': 'object',
   'properties': {'name': {'title': 'Name', 'type': 'string'},
    'args': {'title': 'Args', 'type': 'string'},
    'id': {'title': 'Id', 'type': 'string'},
    'error': {'title': 'Error', 'type': 'string'}},
   'required': ['name', 'args', 'id', 'error']},
  'UsageMetadata': {'title': 'UsageMetadata',
   'type': 'object',
   'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'},
    'output_tokens': {'title': 'Output Tokens', 'type': 'integer'},
    'total_tokens': {'title': 'Total Tokens', 'type': 'integer'}},
   'required': ['input_tokens', 'output_tokens', 'total_tokens']},
  'AIMessage': {'title': 'AIMessage',
   'description': 'Message from an AI.\n\nAIMessage is returned from a chat model as a response to a prompt.\n\nThis message represents the output of the model and consists of both\nthe raw output as returned by the model together standardized fields\n(e.g., tool calls, usage metadata) added by the LangChain framework.',
   'type': 'object',
   'properties': {'content': {'title': 'Content',
     'anyOf': [{'type': 'string'},
      {'type': 'array',
       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},
    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},
    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},
    'type': {'title': 'Type',
     'default': 'ai',
     'enum': ['ai'],
     'type': 'string'},
    'name': {'title': 'Name', 'type': 'string'},
    'id': {'title': 'Id', 'type': 'string'},
    'example': {'title': 'Example', 'default': False, 'type': 'boolean'},
    'tool_calls': {'title': 'Tool Calls',
     'default': [],
     'type': 'array',
     'items': {'$ref': '#/definitions/ToolCall'}},
    'invalid_tool_calls': {'title': 'Invalid Tool Calls',
     'default': [],
     'type': 'array',
     'items': {'$ref': '#/definitions/InvalidToolCall'}},
    'usage_metadata': {'$ref': '#/definitions/UsageMetadata'}},
   'required': ['content']},
  'HumanMessage': {'title': 'HumanMessage',
   'description': 'Message from a human.\n\nHumanMessages are messages that are passed in from a human to the model.\n\nExample:\n\n    .. code-block:: python\n\n        from langchain_core.messages import HumanMessage, SystemMessage\n\n        messages = [\n            SystemMessage(\n                content="You are a helpful assistant! Your name is Bob."\n            ),\n            HumanMessage(\n                content="What is your name?"\n            )\n        ]\n\n        # Instantiate a chat model and invoke it with the messages\n        model = ...\n        print(model.invoke(messages))',
   'type': 'object',
   'properties': {'content': {'title': 'Content',
     'anyOf': [{'type': 'string'},
      {'type': 'array',
       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},
    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},
    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},
    'type': {'title': 'Type',
     'default': 'human',
     'enum': ['human'],
     'type': 'string'},
    'name': {'title': 'Name', 'type': 'string'},
    'id': {'title': 'Id', 'type': 'string'},
    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},
   'required': ['content']},
  'ChatMessage': {'title': 'ChatMessage',
   'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',
   'type': 'object',
   'properties': {'content': {'title': 'Content',
     'anyOf': [{'type': 'string'},
      {'type': 'array',
       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},
    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},
    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},
    'type': {'title': 'Type',
     'default': 'chat',
     'enum': ['chat'],
     'type': 'string'},
    'name': {'title': 'Name', 'type': 'string'},
    'id': {'title': 'Id', 'type': 'string'},
    'role': {'title': 'Role', 'type': 'string'}},
   'required': ['content', 'role']},
  'SystemMessage': {'title': 'SystemMessage',
   'description': 'Message for priming AI behavior.\n\nThe system message is usually passed in as the first of a sequence\nof input messages.\n\nExample:\n\n    .. code-block:: python\n\n        from langchain_core.messages import HumanMessage, SystemMessage\n\n        messages = [\n            SystemMessage(\n                content="You are a helpful assistant! Your name is Bob."\n            ),\n            HumanMessage(\n                content="What is your name?"\n            )\n        ]\n\n        # Define a chat model and invoke it with the messages\n        print(model.invoke(messages))',
   'type': 'object',
   'properties': {'content': {'title': 'Content',
     'anyOf': [{'type': 'string'},
      {'type': 'array',
       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},
    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},
    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},
    'type': {'title': 'Type',
     'default': 'system',
     'enum': ['system'],
     'type': 'string'},
    'name': {'title': 'Name', 'type': 'string'},
    'id': {'title': 'Id', 'type': 'string'}},
   'required': ['content']},
  'FunctionMessage': {'title': 'FunctionMessage',
   'description': 'Message for passing the result of executing a tool back to a model.\n\nFunctionMessage are an older version of the ToolMessage schema, and\ndo not contain the tool_call_id field.\n\nThe tool_call_id field is used to associate the tool call request with the\ntool call response. This is useful in situations where a chat model is able\nto request multiple tool calls in parallel.',
   'type': 'object',
   'properties': {'content': {'title': 'Content',
     'anyOf': [{'type': 'string'},
      {'type': 'array',
       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},
    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},
    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},
    'type': {'title': 'Type',
     'default': 'function',
     'enum': ['function'],
     'type': 'string'},
    'name': {'title': 'Name', 'type': 'string'},
    'id': {'title': 'Id', 'type': 'string'}},
   'required': ['content', 'name']},
  'ToolMessage': {'title': 'ToolMessage',
   'description': "Message for passing the result of executing a tool back to a model.\n\nToolMessages contain the result of a tool invocation. Typically, the result\nis encoded inside the `content` field.\n\nExample: A TooMessage representing a result of 42 from a tool call with id\n\n    .. code-block:: python\n\n        from langchain_core.messages import ToolMessage\n\n        ToolMessage(content='42', tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL')\n\nThe tool_call_id field is used to associate the tool call request with the\ntool call response. This is useful in situations where a chat model is able\nto request multiple tool calls in parallel.",
   'type': 'object',
   'properties': {'content': {'title': 'Content',
     'anyOf': [{'type': 'string'},
      {'type': 'array',
       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},
    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},
    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},
    'type': {'title': 'Type',
     'default': 'tool',
     'enum': ['tool'],
     'type': 'string'},
    'name': {'title': 'Name', 'type': 'string'},
    'id': {'title': 'Id', 'type': 'string'},
    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'}},
   'required': ['content', 'tool_call_id']}}}
```

**Stream(æµå¼)**

```python
for s in chain.stream({"topic": "ç‹—"}):
    print(s.content, end='',flush= True)
```

![](./image/4.45.png)

**invoke**

> è¿™ä¸ªæ˜¯ç›´æ¥ç­‰å¾…ç”Ÿæˆå®Œæ¯•åæ‰è¾“å‡º

```python
chain.invoke({"topic": "ç‹—"})
```

![](./image/4.46.png)

**Batch(å¹¶è¡Œ)**

```python
chain.batch([{"topic": "ç‹—"},{"topic": "çŒ«"}])
```

![](./image/4.47.png)

max_concurrency å¯ä»¥æ§åˆ¶å¹¶å‘æ•°

```python
chain.batch([{"topic": "ç‹—"}, {"topic": "çŒ«"}, {"topic": "é¸­"}], config={"max_concurrency": 2})
```

![](./image/4.48.png)

**Async Steamå¼‚æ­¥**

```python
async for s in chain.astream({"topic": "é€šä¹‰"}):
    print(s.content, end= '',flush= True)
```

![](./image/4.49.png)

**Async invoke**

```python
await chain.ainvoke({"topic": "OpenAI"})
```

![](./image/4.50.png)

**Async Batch**

```python
await chain.abatch([{"topic": "é¸¡"},{"topic": "é¸­"},{"topic": "é¹…"}])
```

![](./image/4.51.png)

å¼‚æ­¥è·å–ä¸­é—´çš„æ­¥éª¤

```python
# é¦–å…ˆå¯¼å…¥æ¨¡å—
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_community.chat_models import ChatTongyi
from langchain.embeddings import HuggingFaceEmbeddings

template = """
    åŸºäºä¸‹é¢çš„ä¸Šä¸‹æ–‡æ¥å›ç­”é—®é¢˜:
    {context}

    Question:{question}
"""

prompt = ChatPromptTemplate.from_template(template)

vectorstore = FAISS.from_texts(
    ["å¾·ç‰§æ˜¯æˆ‘æœ€å–œæ¬¢çš„çŠ¬ç§,æ˜¯ç‰§ç¾ŠçŠ¬"], embedding=HuggingFaceEmbeddings()
)
retriever = vectorstore.as_retriever()

retriever_chain = (
    {
        "context": retriever.with_config(run_name = "Docs"),
        "question": RunnablePassthrough()
    }
    | prompt
    | model
    | StrOutputParser()
)

async for chunk in retriever_chain.astream_log(
    "å¾·ç‰§æ˜¯ä»€ä¹ˆ?", include_names=["Docs"]
):
    print("-"*40)
    print(chunk)
    print("-"*40)
```

```text
----------------------------------------
RunLogPatch({'op': 'replace',
  'path': '',
  'value': {'final_output': None,
            'id': '3885c1b0-dcdb-4046-a402-32e1621f82b8',
            'logs': {},
            'name': 'RunnableSequence',
            'streamed_output': [],
            'type': 'chain'}})
----------------------------------------
----------------------------------------
RunLogPatch({'op': 'add',
  'path': '/logs/Docs',
  'value': {'end_time': None,
            'final_output': None,
            'id': '096bd683-987e-4368-a570-78bf2c3347d8',
            'metadata': {},
            'name': 'Docs',
            'start_time': '2024-07-09T12:11:35.857+00:00',
            'streamed_output': [],
            'streamed_output_str': [],
            'tags': ['map:key:context', 'FAISS', 'HuggingFaceEmbeddings'],
            'type': 'retriever'}})
----------------------------------------
----------------------------------------
RunLogPatch({'op': 'add',
  'path': '/logs/Docs/final_output',
  'value': {'documents': [Document(page_content='å¾·ç‰§æ˜¯æˆ‘æœ€å–œæ¬¢çš„çŠ¬ç§,æ˜¯ç‰§ç¾ŠçŠ¬')]}},
 {'op': 'add',
  'path': '/logs/Docs/end_time',
  'value': '2024-07-09T12:11:35.941+00:00'})
----------------------------------------
----------------------------------------
RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'æ–‡æ¡£'},
 {'op': 'replace', 'path': '/final_output', 'value': 'æ–‡æ¡£'})
----------------------------------------
----------------------------------------
RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'ä¸­'},
 {'op': 'replace', 'path': '/final_output', 'value': 'æ–‡æ¡£ä¸­'})
----------------------------------------
----------------------------------------
RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'æåˆ°'},
 {'op': 'replace', 'path': '/final_output', 'value': 'æ–‡æ¡£ä¸­æåˆ°'})
----------------------------------------
----------------------------------------
RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'ï¼Œå¾·ç‰§æ˜¯ä¸€ç§ç‰§'},
 {'op': 'replace', 'path': '/final_output', 'value': 'æ–‡æ¡£ä¸­æåˆ°ï¼Œå¾·ç‰§æ˜¯ä¸€ç§ç‰§'})
----------------------------------------
----------------------------------------
RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'ç¾ŠçŠ¬ã€‚'},
 {'op': 'replace', 'path': '/final_output', 'value': 'æ–‡æ¡£ä¸­æåˆ°ï¼Œå¾·ç‰§æ˜¯ä¸€ç§ç‰§ç¾ŠçŠ¬ã€‚'})
----------------------------------------

```

```python
# åªçœ‹çŠ¶æ€å€¼çš„è¯æ˜¯è¿™æ ·çš„
async for chunk in retriever_chain.astream_log(
    "å¾·ç‰§æ˜¯ä»€ä¹ˆ?", include_names=["Docs"], diff= False
):
    print("-"*40)
    print(chunk)
    print("-"*40)
```

```text
output:
----------------------------------------
RunLog({'final_output': None,
 'id': '2e076ead-c41f-444f-972c-b74c4230d467',
 'logs': {},
 'name': 'RunnableSequence',
 'streamed_output': [],
 'type': 'chain'})
----------------------------------------
----------------------------------------
RunLog({'final_output': None,
 'id': '2e076ead-c41f-444f-972c-b74c4230d467',
 'logs': {'Docs': {'end_time': None,
                   'final_output': None,
                   'id': '4ac1fd4b-e8d2-4d96-8686-c91a295787bc',
                   'metadata': {},
                   'name': 'Docs',
                   'start_time': '2024-07-09T12:14:09.029+00:00',
                   'streamed_output': [],
                   'streamed_output_str': [],
                   'tags': ['map:key:context',
                            'FAISS',
                            'HuggingFaceEmbeddings'],
                   'type': 'retriever'}},
 'name': 'RunnableSequence',
 'streamed_output': [],
 'type': 'chain'})
----------------------------------------
----------------------------------------
RunLog({'final_output': None,
 'id': '2e076ead-c41f-444f-972c-b74c4230d467',
 'logs': {'Docs': {'end_time': '2024-07-09T12:14:09.109+00:00',
                   'final_output': {'documents': [Document(page_content='å¾·ç‰§æ˜¯æˆ‘æœ€å–œæ¬¢çš„çŠ¬ç§,æ˜¯ç‰§ç¾ŠçŠ¬')]},
                   'id': '4ac1fd4b-e8d2-4d96-8686-c91a295787bc',
                   'metadata': {},
                   'name': 'Docs',
                   'start_time': '2024-07-09T12:14:09.029+00:00',
                   'streamed_output': [],
                   'streamed_output_str': [],
                   'tags': ['map:key:context',
                            'FAISS',
                            'HuggingFaceEmbeddings'],
                   'type': 'retriever'}},
 'name': 'RunnableSequence',
 'streamed_output': [],
 'type': 'chain'})
----------------------------------------
----------------------------------------
RunLog({'final_output': 'æ–‡æ¡£',
 'id': '2e076ead-c41f-444f-972c-b74c4230d467',
 'logs': {'Docs': {'end_time': '2024-07-09T12:14:09.109+00:00',
                   'final_output': {'documents': [Document(page_content='å¾·ç‰§æ˜¯æˆ‘æœ€å–œæ¬¢çš„çŠ¬ç§,æ˜¯ç‰§ç¾ŠçŠ¬')]},
                   'id': '4ac1fd4b-e8d2-4d96-8686-c91a295787bc',
                   'metadata': {},
                   'name': 'Docs',
                   'start_time': '2024-07-09T12:14:09.029+00:00',
                   'streamed_output': [],
                   'streamed_output_str': [],
                   'tags': ['map:key:context',
                            'FAISS',
                            'HuggingFaceEmbeddings'],
                   'type': 'retriever'}},
 'name': 'RunnableSequence',
 'streamed_output': ['æ–‡æ¡£'],
 'type': 'chain'})
----------------------------------------
----------------------------------------
RunLog({'final_output': 'æ–‡æ¡£ä¸­',
 'id': '2e076ead-c41f-444f-972c-b74c4230d467',
 'logs': {'Docs': {'end_time': '2024-07-09T12:14:09.109+00:00',
                   'final_output': {'documents': [Document(page_content='å¾·ç‰§æ˜¯æˆ‘æœ€å–œæ¬¢çš„çŠ¬ç§,æ˜¯ç‰§ç¾ŠçŠ¬')]},
                   'id': '4ac1fd4b-e8d2-4d96-8686-c91a295787bc',
                   'metadata': {},
                   'name': 'Docs',
                   'start_time': '2024-07-09T12:14:09.029+00:00',
                   'streamed_output': [],
                   'streamed_output_str': [],
                   'tags': ['map:key:context',
                            'FAISS',
                            'HuggingFaceEmbeddings'],
                   'type': 'retriever'}},
 'name': 'RunnableSequence',
 'streamed_output': ['æ–‡æ¡£', 'ä¸­'],
 'type': 'chain'})
----------------------------------------
----------------------------------------
RunLog({'final_output': 'æ–‡æ¡£ä¸­æåˆ°',
 'id': '2e076ead-c41f-444f-972c-b74c4230d467',
 'logs': {'Docs': {'end_time': '2024-07-09T12:14:09.109+00:00',
                   'final_output': {'documents': [Document(page_content='å¾·ç‰§æ˜¯æˆ‘æœ€å–œæ¬¢çš„çŠ¬ç§,æ˜¯ç‰§ç¾ŠçŠ¬')]},
                   'id': '4ac1fd4b-e8d2-4d96-8686-c91a295787bc',
                   'metadata': {},
                   'name': 'Docs',
                   'start_time': '2024-07-09T12:14:09.029+00:00',
                   'streamed_output': [],
                   'streamed_output_str': [],
                   'tags': ['map:key:context',
                            'FAISS',
                            'HuggingFaceEmbeddings'],
                   'type': 'retriever'}},
 'name': 'RunnableSequence',
 'streamed_output': ['æ–‡æ¡£', 'ä¸­', 'æåˆ°'],
 'type': 'chain'})
----------------------------------------
----------------------------------------
RunLog({'final_output': 'æ–‡æ¡£ä¸­æåˆ°ï¼Œå¾·ç‰§æ˜¯ä¸€ç§ç‰§',
 'id': '2e076ead-c41f-444f-972c-b74c4230d467',
 'logs': {'Docs': {'end_time': '2024-07-09T12:14:09.109+00:00',
                   'final_output': {'documents': [Document(page_content='å¾·ç‰§æ˜¯æˆ‘æœ€å–œæ¬¢çš„çŠ¬ç§,æ˜¯ç‰§ç¾ŠçŠ¬')]},
                   'id': '4ac1fd4b-e8d2-4d96-8686-c91a295787bc',
                   'metadata': {},
                   'name': 'Docs',
                   'start_time': '2024-07-09T12:14:09.029+00:00',
                   'streamed_output': [],
                   'streamed_output_str': [],
                   'tags': ['map:key:context',
                            'FAISS',
                            'HuggingFaceEmbeddings'],
                   'type': 'retriever'}},
 'name': 'RunnableSequence',
 'streamed_output': ['æ–‡æ¡£', 'ä¸­', 'æåˆ°', 'ï¼Œå¾·ç‰§æ˜¯ä¸€ç§ç‰§'],
 'type': 'chain'})
----------------------------------------
----------------------------------------
RunLog({'final_output': 'æ–‡æ¡£ä¸­æåˆ°ï¼Œå¾·ç‰§æ˜¯ä¸€ç§ç‰§ç¾ŠçŠ¬ã€‚',
 'id': '2e076ead-c41f-444f-972c-b74c4230d467',
 'logs': {'Docs': {'end_time': '2024-07-09T12:14:09.109+00:00',
                   'final_output': {'documents': [Document(page_content='å¾·ç‰§æ˜¯æˆ‘æœ€å–œæ¬¢çš„çŠ¬ç§,æ˜¯ç‰§ç¾ŠçŠ¬')]},
                   'id': '4ac1fd4b-e8d2-4d96-8686-c91a295787bc',
                   'metadata': {},
                   'name': 'Docs',
                   'start_time': '2024-07-09T12:14:09.029+00:00',
                   'streamed_output': [],
                   'streamed_output_str': [],
                   'tags': ['map:key:context',
                            'FAISS',
                            'HuggingFaceEmbeddings'],
                   'type': 'retriever'}},
 'name': 'RunnableSequence',
 'streamed_output': ['æ–‡æ¡£', 'ä¸­', 'æåˆ°', 'ï¼Œå¾·ç‰§æ˜¯ä¸€ç§ç‰§', 'ç¾ŠçŠ¬ã€‚'],
 'type': 'chain'})
----------------------------------------

```

**å¹¶è¡Œæ”¯æŒ**

```python
from langchain_core.runnables import RunnableParallel

chain1 = ChatPromptTemplate.from_template("ç»™æˆ‘è®²ä¸€ä¸ªå…³äº{topic}çš„å”è¯—") | model
chain2 = (
    ChatPromptTemplate.from_template("å†™ä¸¤è¡Œå…³äº{topic}çš„å®‹è¯")
    | model
)
combined = RunnableParallel(joke=chain1, poem=chain2)
```

```python
# å…ˆæ¥çœ‹å•ç‹¬è¿è¡Œçš„æ—¶é—´
# %%time
for s in chain1.stream({"topic": "æç™½"}):
    print(s.content, end='',flush= True)
```

![](./image/4.52.png)

```python
for s in chain2.stream({"topic": "è‹è½¼"}):
    print(s.content, end= '', flush= True)
```

![](./image/4.53.png)

```python
# å¹¶è¡Œæ‰§è¡Œ
combined.invoke({"topic": "æç™½æˆ–è€…è‹è½¼"})
```

![](./image/4.54.png)

**å¹¶è¡Œæ‰¹å¤„ç†,é€‚ç”¨å¤§é‡ç”Ÿæˆ**

```python
chain1.batch([{"topic": "æç™½"}, {"topic": "æœç‰§"}])
```

![](./image/4.55.png)

```python
chain2.batch([{"topic": "æç™½"}, {"topic": "æœç‰§"}])
```

å¹¶è¡Œå¤„ç†

```python
# å¹¶è¡Œå¤„ç†
combined.batch([{"topic": "æç™½"}, {"topic": "æœç‰§"}])
```

![](./image/4.56.png)

# åç»­

è¿™ä¸€éƒ¨åˆ†å°±å…ˆåˆ°è¿™é‡Œ,ç¯‡å¹…åŸå› å†å¼€ä¸€ç¯‡

***2024.07 --SouthAki ***
