# Langchain

‰ΩúËÄÖ:`@xieleihan`[ÁÇπÂáªËÆøÈóÆ](https://github.com/xieleihan)

Êú¨ÊñáÈÅµÂÆàGPL3.0ÂºÄÊ∫êÂçèËÆÆ

# ÂÆûÁé∞‰∏Ä‰∏™ËÅäÂ§©Êú∫Âô®‰∫∫

## Agents

#### ‰ªãÁªç

> ![](./image/4.1.png)

- Êó†ÈúÄ‰∏∫‰∏çÂêå‰ªªÂä°‰ΩøÁî®ÂçïÁã¨ËΩØ‰ª∂
- ‰ΩøÁî®Êó•Â∏∏ËØ≠Ë®ÄÊù•ÂëΩ‰ª§‰Ω†ÁöÑËÆæÂ§á
- ‰ª£ÁêÜÊòØ‰∫∫Â∑•Êô∫ËÉΩÁöÑÈ´òÁ∫ßÂΩ¢Âºè
- Êú™Êù•‰∫îÂπ¥Â∞ÜÊàê‰∏∫Áé∞ÂÆû
- ‰∫∫‰∫∫ÈÉΩÊúâÁöÑÁßÅ‰∫∫Âä©ÁêÜAgnet
- Â∫îÁî®Âú®ÂçÉË°åÁôæ‰∏ö‰πã‰∏≠(ÂåªÁñó,ÊïôËÇ≤,Â®±‰πê...)
- Áîü‰∫ßÂäõÁöÑÊîπÂèò
- ÁªßPC,IOS,AndroidÂêé‰∏ã‰∏Ä‰∏™Âπ≥Âè∞ 

![](./image/4.2.png)

## Langchain‰∏≠ÁöÑAgentsÂ¶Ç‰ΩïÂÆûÁé∞

1. ÊèêÂá∫ÈúÄÊ±Ç
2. ÈóÆÈ¢ò+promptÁªÑÂêà
3. React Loop
4. Êü•ÊâæMemory
5. Êü•ÊâæÂèØÁî®Â∑•ÂÖ∑
6. ÊâßË°åÂ∑•ÂÖ∑Âπ∂ËßÇÂØüÁªìÊûú
7. ÂæóÂà∞ÊúÄÁªàÁöÑÁªìÊûú

### ÂÆûÁé∞‰∏Ä‰∏™ÊúÄÁÆÄÂçïÁöÑAgents

#### ËÆæËÆ°‰∏§‰∏™‰ªªÂä°

- ‰ºöÂÅöÊï∞Â≠¶È¢ò
- ‰∏çÁü•ÈÅìÁ≠îÊ°àÁöÑÊó∂ÂÄôÂèØ‰ª•ÊêúÁ¥¢

#### ÂÆûÁé∞

```python
# ÂØºÂÖ•Ê®°Âùó
from dotenv import find_dotenv, load_dotenv
import os
# Âä†ËΩΩ API key
load_dotenv(find_dotenv())
api_key = os.getenv("DASHSCOPE_API_KEY")

# È¶ñÂÖà‰æùÊóßÂØºÂÖ•Ê®°Âùó
from langchain_community.chat_models import ChatTongyi
import os

llm = ChatTongyi(
    dashscope_api_key = api_key,
    model = "Qwen-max",
    temperature = 0
)

# Êê≠Âª∫Â∑•ÂÖ∑
# Êàë‰ª¨‰ΩøÁî®‰∏Ä‰∏™Â∑•ÂÖ∑,serpaiÊòØ‰∏Ä‰∏™ËÅöÂêàÊêúÁ¥¢ÂºïÊìé,ÈúÄË¶ÅÂÆâË£ÖË∞∑Ê≠åÊêúÁ¥¢ÂåÖÂíåÁî≥ËØ∑apikey
# https://serpapi.com/dashboard
# llm-math ÊòØ‰∏Ä‰∏™Â∞ÅË£ÖÂ•ΩÁöÑÊï∞Â≠¶ËÆ°ÁÆóÈìæ
# È¶ñÂÖàÊàë‰ª¨ÈúÄË¶ÅÂÆâË£ÖË∞∑Ê≠åÊêúÁ¥¢ÂåÖ
```

```python
! pip install google-search-results
```

```python
# ÂØºÂÖ•Ê®°Âùó
from dotenv import find_dotenv, load_dotenv
import os
# Âä†ËΩΩ API key
load_dotenv(find_dotenv())
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")

# È¶ñÂÖà‰æùÊóßÂØºÂÖ•Ê®°Âùó
from langchain_community.chat_models import ChatTongyi
import os

llm = ChatTongyi(
    dashscope_api_key = dashscope_api_key,
    model = "qwen-vl-max",
    temperature = 0
)

from langchain.agents import load_tools
# Êê≠Âª∫Â∑•ÂÖ∑
tools = load_tools(
    ["serpapi", "llm-math"],
    llm=llm,
    serpapi_api_key=serpapi_api_key
)

# ÂÆö‰πâagents‰ΩøÁî®Â∞èÊ†∑Êú¨Â¢ûÂº∫
from langchain.agents import initialize_agent
from langchain.agents import AgentType

# ÂÆö‰πâÂ∑•ÂÖ∑
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,# ËøôÈáåÊúâ‰∏çÂêåÁöÑÁ±ªÂûã
    verbose=True
)

agent.run("Ëã±ÂõΩÂâç‰ªªÂ•≥ÁéãÁöÑÂêçÂ≠óÂè´‰ªÄ‰πà,Â•πÁöÑÂπ¥ÈæÑÁöÑÂπ≥ÊñπÊòØÂ§öÂ∞ë?")
```

![](./image/4.3.png)

### Âá†ÁßçÂÜÖÁΩÆÁöÑ‰∏ªË¶ÅAgentÁ±ªÂûã

- openai_functions OpenAIÂáΩÊï∞Ë∞ÉÁî®Âûã
- zero_short_react_description Èõ∂Ê†∑Êú¨Â¢ûÂº∫ÁîüÊàêÂûã
- chat_zero_shot_react_description Èõ∂Ê†∑Êú¨Â¢ûÂº∫ÂØπËØùÂûã
- conversational_react_description ÂØπËØùÂ¢ûÂº∫ÁîüÊàêÂûã
- chat_conversational_react_description ÂØπËØùÂ¢ûÂº∫ÁªìÊûÑÂåñ
- structued_chat_zero_short_react_description Èõ∂Ê†∑Êú¨Â¢ûÂº∫ÁªìÊûÑÂåñÂØπËØùÂûã

#### ZERO_SHOT_REACT_DESCRIPTION

Èõ∂Ê†∑Êú¨Â¢ûÂº∫ÁîüÊàê,Êó¢Âú®Ê≤°ÊúâÁ§∫‰æãÁöÑÊÉÖÂÜµ‰∏ã,ÂèØ‰ª•Ëá™‰∏ªËøõË°åÂØπËØùÁöÑÁ±ªÂûã[Èõ∂Ê†∑Êú¨,ÂçïÊ†∑Êú¨,Â∞ëÊ†∑Êú¨](https://blog.csdn.net/zcyzcyjava/article/details/127006287)

```python
from langchain.llms import Tongyi
from langchain.agents import (
    load_tools,
    initialize_agent,
    AgentType
)
import os
from dotenv import find_dotenv, load_dotenv
import os
# Âä†ËΩΩ API key
load_dotenv(find_dotenv())
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")

llm = Tongyi(
    dashscope_api_key = dashscope_api_key,
    model = 'Qwen-max',
    temperature =0
)

tools = load_tools(["serpapi", "llm-math"], llm=llm, serpapi_api_key=serpapi_api_key)
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

agent.run('‰∏ä‰∏Ä‰ªªÊñ∞Ë•øÂÖ∞Â•≥ÁéãÊòØË∞Å?Â•πÂπ¥ÈæÑÈô§‰ª•2ÊòØÂ§öÂ∞ë?')
```

![](./image/4.4.png)

#### CHAT_ZERO_SHOT_REACT_DESCRIPTION

ÂÖ∂ÂÆûË∑ü‰∏äÈù¢ÁöÑÊ≤°‰ªÄ‰πàÂå∫Âà´,‰∏ªË¶ÅÊòØÊää`llm`Êç¢Êàê‰∫Ü`chatModel`

```python
# from langchain.llms import Tongyi
from langchain_community.chat_models import ChatTongyi
from langchain.agents import (
    load_tools,
    initialize_agent,
    AgentType
)
import os
from dotenv import find_dotenv, load_dotenv
import os
# Âä†ËΩΩ API key
load_dotenv(find_dotenv())
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")

llm = ChatTongyi(
    dashscope_api_key = dashscope_api_key,
    model_name = 'qwen-vl-max',
    temperature =0
)

tools = load_tools(["serpapi", "llm-math"], llm=llm, serpapi_api_key=serpapi_api_key)
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

agent.run('‰∏ñÁïåÁ¨¨‰∏âÊûÅÊòØ‰ªÄ‰πà?ÂÆÉÁöÑÈ´òÂ∫¶‰πò2ÊòØÂ§öÂ∞ë?')
```

![](./image/4.5.png)

#### CONVERSATIONAL_REACT_DESCRIPTION

‰∏Ä‰∏™ÂØπËØùÂûãÁöÑagent,Ëøô‰∏™agentË¶ÅÊ±Ç‰∏émemory‰∏ÄËµ∑‰ΩøÁî®

```python
from langchain.llms import Tongyi
from langchain.agents import(
    load_tools,
    initialize_agent,
    AgentType
)
from langchain.memory import ConversationBufferMemory
import os
from dotenv import find_dotenv, load_dotenv
# Âä†ËΩΩ API key
load_dotenv(find_dotenv())
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")

# ËÆ∞ÂøÜÁªÑ‰ª∂
memory = ConversationBufferMemory(
    memory_key="chat_history"
)

llm = Tongyi(
    dashscope_api_key = dashscope_api_key,
    model = "Qwen-max",
    temperature = 0,
)

tools = load_tools(["serpapi", "llm-math"], llm=llm, serpapi_api_key=serpapi_api_key)
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
    verbose=True,
    memory=memory # ËÆ∞ÂøÜÁªÑ‰ª∂
)

print(agent)
# Áúã‰∏ãÊ®°Áâà
print(agent.agent.llm_chain.prompt.template)
```

Êàë‰ª¨Êù•Áúã‰∏ãÊ®°ÁâàÊèêÁ§∫ËØç

````text
memory=ConversationBufferMemory(memory_key='chat_history') verbose=True tags=['conversational-react-description'] agent=ConversationalAgent(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input'], template='Assistant is a large language model trained by OpenAI.\n\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n\nOverall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n\nTOOLS:\n------\n\nAssistant has access to the following tools:\n\n> Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n> Calculator: Useful for when you need to answer questions about math.\n\nTo use a tool, please use the following format:\n\n```\nThought: Do I need to use a tool? Yes\nAction: the action to take, should be one of [Search, Calculator]\nAction Input: the input to the action\nObservation: the result of the action\n```\n\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n\n```\nThought: Do I need to use a tool? No\nAI: [your response here]\n```\n\nBegin!\n\nPrevious conversation history:\n{chat_history}\n\nNew input: {input}\n{agent_scratchpad}'), llm=Tongyi(client=<class 'dashscope.aigc.generation.Generation'>, dashscope_api_key='sk-2a9e44d9621f4fd1b5f9f2c081779215')), output_parser=ConvoOutputParser(), allowed_tools=['Search', 'Calculator'], ai_prefix='AI') tools=[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>), Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\'s numexpr library. Use the output of running this code to answer the question.\n\nQuestion: ${{Question with math problem.}}\n```text\n${{single line mathematical expression that solves the problem}}\n```\n...numexpr.evaluate(text)...\n```output\n${{Output of running the code}}\n```\nAnswer: ${{Answer}}\n\nBegin.\n\nQuestion: What is 37593 * 67?\n```text\n37593 * 67\n```\n...numexpr.evaluate("37593 * 67")...\n```output\n2518731\n```\nAnswer: 2518731\n\nQuestion: 37593^(1/5)\n```text\n37593**(1/5)\n```\n...numexpr.evaluate("37593**(1/5)")...\n```output\n8.222831614237718\n```\nAnswer: 8.222831614237718\n\nQuestion: {question}\n'), llm=Tongyi(client=<class 'dashscope.aigc.generation.Generation'>, dashscope_api_key='sk-2a9e44d9621f4fd1b5f9f2c081779215')))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\'s numexpr library. Use the output of running this code to answer the question.\n\nQuestion: ${{Question with math problem.}}\n```text\n${{single line mathematical expression that solves the problem}}\n```\n...numexpr.evaluate(text)...\n```output\n${{Output of running the code}}\n```\nAnswer: ${{Answer}}\n\nBegin.\n\nQuestion: What is 37593 * 67?\n```text\n37593 * 67\n```\n...numexpr.evaluate("37593 * 67")...\n```output\n2518731\n```\nAnswer: 2518731\n\nQuestion: 37593^(1/5)\n```text\n37593**(1/5)\n```\n...numexpr.evaluate("37593**(1/5)")...\n```output\n8.222831614237718\n```\nAnswer: 8.222831614237718\n\nQuestion: {question}\n'), llm=Tongyi(client=<class 'dashscope.aigc.generation.Generation'>, dashscope_api_key='sk-2a9e44d9621f4fd1b5f9f2c081779215')))>)]
Assistant is a large language model trained by OpenAI.

Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.

Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.

Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.

TOOLS:
------

Assistant has access to the following tools:

> Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.
> Calculator: Useful for when you need to answer questions about math.

To use a tool, please use the following format:

```
Thought: Do I need to use a tool? Yes
Action: the action to take, should be one of [Search, Calculator]
Action Input: the input to the action
Observation: the result of the action
```

When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:

```
Thought: Do I need to use a tool? No
AI: [your response here]
```

Begin!

Previous conversation history:
{chat_history}

New input: {input}
{agent_scratchpad}

````

OK,ËÆ©Êàë‰ª¨ÊèêÂá∫ÈóÆÈ¢ò,ÈóÆÁ≠îAI

```python
agent.run("hi, i am SouthAki,what is your name?")
```

![](./image/4.6.png)

```python
agent.run("È¶ôÊ∏ØÊúâÂì™ÈáåÊØîËæÉÂ•ΩÁé©ÁöÑÂêó?")
```

![](./image/4.7.png)

```python
agent.run("ÊàëËøòÊ≤°Áé©Ëøá,‰Ω†Áü•ÈÅìÊàëÂêçÂ≠óÂêé‰∏â‰∏™Â≠óÊØçÊòØ‰ªÄ‰πàÂêó?")
```

![](./image/4.8.png)

```python
agent.run("‰∏≠ÂõΩÂπø‰∏úÁúÅÂπøÂ∑ûÂ∏ÇÁé∞Âú®ÁöÑÊ∞îÊ∏©ÊòØÂ§öÂ∞ëÊù•ÁùÄ?")
```

![](./image/4.9.png)

```python
agent.run("Êà™Ê≠¢Âà∞Áé∞Âú®Êàë‰ª¨ÈóÆ‰∫ÜÂ§öÂ∞ëÈóÆÈ¢ò?")
```

![](./image/4.10.png)

#### CHAT_CONVERSATIONAL_REACT_DESCRIPTION

Ë∑ü‰∏äÈù¢‰∏ÄÊ†∑Â∑Æ‰∏çÂ§ö

```python
from langchain_community.chat_models import ChatTongyi
from langchain.agents import(
    load_tools,
    initialize_agent,
    AgentType
)
from langchain.memory import ConversationBufferMemory
import os
from dotenv import find_dotenv, load_dotenv
# Âä†ËΩΩ API key
load_dotenv(find_dotenv())
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")

# ËÆ∞ÂøÜÁªÑ‰ª∂
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages= True
)

llm = ChatTongyi(
    dashscope_api_key = dashscope_api_key,
    model_name = "qwen-vl-max",
    temperature = 0,
)

tools = load_tools(["serpapi", "llm-math"], llm=llm, serpapi_api_key=serpapi_api_key)
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,
    verbose=True,
    memory=memory # ËÆ∞ÂøÜÁªÑ‰ª∂
)

print(agent)
# Áúã‰∏ãÊ®°Áâà
print(agent.agent.llm_chain.prompt.template)
```

Êù•ÁúãÁúãÈóÆÈ¢òÁöÑÁ≠îÊ°àÂêß

```python
agent.run("hi, i am ÂçóÁßãSouthAki,what is your name?")
```

![](./image/4.11.png)

```python
agent.run("È¶ôÊ∏ØÊúâ‰ªÄ‰πàÊØîËæÉÂ•ΩÂêÉÁöÑÁæéÈ£ü?")
```

![](./image/4.12.png)

```python
agent.run("ÊàëËøòÊ≤°ÂêÉËøá,‰∏çËøá‰Ω†ËøòÁü•ÈÅìÊàëÂêçÂ≠óÁöÑÊúÄÂêé‰∏Ä‰∏™Â≠óÊØçÊòØ‰ªÄ‰πàÂêó?‰∏≠ÂõΩÊæ≥Èó®Áé∞Âú®ÁöÑÊ∞îÊ∏©ÊòØÂ§öÂ∞ëÊù•ÁùÄ?")
```

![](./image/4.13.png)

```python
agent.run("Êà™Ê≠¢Âà∞Áé∞Âú®Êàë‰ª¨ÈóÆ‰∫ÜÂ§öÂ∞ëÈóÆÈ¢ò?")
```

![](./image/4.14.png)

> üöß:Êé•‰∏ãÊù•,Êàë‰ª¨Êù•ËÆ≤‰∏Ä‰∏ãopenai_functions ‰ΩøÁî®Âà∞‰∫ÜopenaiÁöÑÂáΩÊï∞Ë∞ÉÁî®Êù•ÂÆûÁé∞ÁöÑ,Âè™ÊîØÊåÅOpenAIÊ®°Âûã
>
> ÊâÄ‰ª•‰∏ãÈù¢ÁöÑÊºîÁ§∫,ÊàëÁõ¥Êé•‰ª•‰ª£Á†ÅÁöÑÂΩ¢ÂºèËÆ≤Ëß£,‰∏ç‰ºöÂéªËøêË°å

#### OPENAI_FUNCTIONS

```python
# ÂØºÂÖ•Ê®°Âùó
from langchain.chat_models import ChatOpenAI
from langchain.agents import(
    load_tools,
    initialize_agent,
    AgentType
)
from langchain.memory import ConversationBufferMemory
import os

os.environ["OPENAI_API_KEY"] = "sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
os.environ["SERPAPI_API_KEY"] = ""

# ËÆ∞ÂøÜÁªÑ‰ª∂
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)

llm = ChatOpenAI(
    temperature = 0,
    model = 'gpt-4-0613'
)
tools = load_tools(
    ["serpapi", "llm-math"],
    llm = llm
)
agent = initialize_agent(
    tools = tools,
    llm = llm,
    agent = AgentType.OPENAI_FUNCTIONS,
    verbose = True,
    memory = memory
)
print(agent)
print(agent.agent.prompt.messages)

# ÁÑ∂ÂêéÂêéÁª≠Âè™ÈúÄË¶ÅËøêË°åagent.run(input = ""),Â∞±Ë°å
```

#### STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION

ÂØπËæìÂá∫ÁöÑÁªìÊûÑÂåñÂ§ÑÁêÜ

```python
from langchain_community.chat_models import ChatTongyi
from langchain.agents import(
    load_tools,
    initialize_agent,
    AgentType
)
from langchain.memory import ConversationBufferMemory
import os
from dotenv import find_dotenv, load_dotenv
# Âä†ËΩΩ API key
load_dotenv(find_dotenv())
dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")

# ËÆ∞ÂøÜÁªÑ‰ª∂
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages= True
)

llm = ChatTongyi(
    dashscope_api_key = dashscope_api_key,
    model_name = "qwen-vl-max",
    temperature = 0,
)

tools = load_tools(["serpapi", "llm-math"], llm=llm, serpapi_api_key=serpapi_api_key)
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True,
    memory=memory # ËÆ∞ÂøÜÁªÑ‰ª∂
)

print(agent)
# Áúã‰∏ãÊ®°Áâà
print(agent.agent.llm_chain.prompt.messages[0].prompt.template)
```

ÂèØ‰ª•Áúã‰∏ãÊèêÁ§∫ËØçÊ®°Áâà

````text
memory=ConversationBufferMemory(return_messages=True, memory_key='chat_history') verbose=True tags=['structured-chat-zero-shot-react-description'] agent=StructuredChatAgent(llm_chain=LLMChain(prompt=ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n\nSearch: A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {{\'tool_input\': {{\'type\': \'string\'}}}}\nCalculator: Useful for when you need to answer questions about math., args: {{\'tool_input\': {{\'type\': \'string\'}}}}\n\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n\nValid "action" values: "Final Answer" or Search, Calculator\n\nProvide only ONE action per $JSON_BLOB, as shown:\n\n```\n{{\n  "action": $TOOL_NAME,\n  "action_input": $INPUT\n}}\n```\n\nFollow this format:\n\nQuestion: input question to answer\nThought: consider previous and subsequent steps\nAction:\n```\n$JSON_BLOB\n```\nObservation: action result\n... (repeat Thought/Action/Observation N times)\nThought: I know what to respond\nAction:\n```\n{{\n  "action": "Final Answer",\n  "action_input": "Final response to human"\n}}\n```\n\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\nThought:')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], template='{input}\n\n{agent_scratchpad}'))]), llm=ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********'))), output_parser=StructuredChatOutputParserWithRetries(output_fixing_parser=OutputFixingParser(parser=StructuredChatOutputParser(), retry_chain=PromptTemplate(input_variables=['completion', 'error', 'instructions'], template='Instructions:\n--------------\n{instructions}\n--------------\nCompletion:\n--------------\n{completion}\n--------------\n\nAbove, the Completion did not satisfy the constraints given in the Instructions.\nError:\n--------------\n{error}\n--------------\n\nPlease try again. Please only respond with an answer that satisfies the constraints laid out in the Instructions:')
| ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********')))), allowed_tools=['Search', 'Calculator']) tools=[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='ebcc8130fff3a121b7029d6db2bd880991535ffa5ce8df722ba3d4aa1a892f73', aiosession=None)>), Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\'s numexpr library. Use the output of running this code to answer the question.\n\nQuestion: ${{Question with math problem.}}\n```text\n${{single line mathematical expression that solves the problem}}\n```\n...numexpr.evaluate(text)...\n```output\n${{Output of running the code}}\n```\nAnswer: ${{Answer}}\n\nBegin.\n\nQuestion: What is 37593 * 67?\n```text\n37593 * 67\n```\n...numexpr.evaluate("37593 * 67")...\n```output\n2518731\n```\nAnswer: 2518731\n\nQuestion: 37593^(1/5)\n```text\n37593**(1/5)\n```\n...numexpr.evaluate("37593**(1/5)")...\n```output\n8.222831614237718\n```\nAnswer: 8.222831614237718\n\nQuestion: {question}\n'), llm=ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********'))))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\'s numexpr library. Use the output of running this code to answer the question.\n\nQuestion: ${{Question with math problem.}}\n```text\n${{single line mathematical expression that solves the problem}}\n```\n...numexpr.evaluate(text)...\n```output\n${{Output of running the code}}\n```\nAnswer: ${{Answer}}\n\nBegin.\n\nQuestion: What is 37593 * 67?\n```text\n37593 * 67\n```\n...numexpr.evaluate("37593 * 67")...\n```output\n2518731\n```\nAnswer: 2518731\n\nQuestion: 37593^(1/5)\n```text\n37593**(1/5)\n```\n...numexpr.evaluate("37593**(1/5)")...\n```output\n8.222831614237718\n```\nAnswer: 8.222831614237718\n\nQuestion: {question}\n'), llm=ChatTongyi(client=<class 'dashscope.aigc.multimodal_conversation.MultiModalConversation'>, model_name='qwen-vl-max', dashscope_api_key=SecretStr('**********'))))>)]
Respond to the human as helpfully and accurately as possible. You have access to the following tools:

Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {{'tool_input': {{'type': 'string'}}}}
Calculator: Useful for when you need to answer questions about math., args: {{'tool_input': {{'type': 'string'}}}}

Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).

Valid "action" values: "Final Answer" or Search, Calculator

Provide only ONE action per $JSON_BLOB, as shown:

```
{{
  "action": $TOOL_NAME,
  "action_input": $INPUT
}}
```

Follow this format:

Question: input question to answer
Thought: consider previous and subsequent steps
Action:
```
$JSON_BLOB
```
Observation: action result
... (repeat Thought/Action/Observation N times)
Thought: I know what to respond
Action:
```
{{
  "action": "Final Answer",
  "action_input": "Final response to human"
}}
```

Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.
Thought:

````

ÊèêÂá∫ÈóÆÁ≠îËØïËØï

```python
agent.invoke({"input":"what is langchain?"})
```

![](./image/4.15.png)
